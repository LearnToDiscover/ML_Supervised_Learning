<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<title>Machine Learning - Supervised: All in One View</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" type="text/css" href="assets/styles.css">
<script src="assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
<link rel="manifest" href="site.webmanifest">
<link rel="mask-icon" href="safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">
</head>
<body>
    <header id="top" class="navbar navbar-expand-md navbar-light bg-white top-nav l2d"><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-6">
      <div class="large-logo">
        <img alt="l2d" src="assets/images/l2d-logo.svg">
</div>
    </div>
    <div class="selector-container">


      <div class="dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Learner View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1">
<li><button class="dropdown-item" type="button" onclick="window.location.href='instructor/aio.html';">Instructor View</button></li>
        </ul>
</div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl navbar-light bg-white bottom-nav l2d" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="l2d" src="assets/images/l2d-logo-sm.svg">
</div>
    <div class="lesson-title-md">
      Machine Learning - Supervised
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="Search the All In One page" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0">
<li class="nav-item">
          <span class="lesson-title">
            Machine Learning - Supervised
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="reference.html#glossary">Glossary</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="profiles.html">Learner Profiles</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown"></ul>
</li>
      </ul>
</div>
    <!--
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
      <input class="form-control me-2 searchbox" type="search" placeholder="" aria-label="">
        <button class="btn btn-outline-success tablet-search-button"  type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="Search the All In One page"></i>
        </button>
      </fieldset>
    </form>
    -->
    <a class="btn btn-primary" href="aio.html" role="button" aria-label="Search the All In One page">Search the All In One page</a>
  </div>
<!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Machine Learning - Supervised
</div>

<aside class="col-md-12 lesson-progress"><div style="width: %" class="percentage">
    %
  </div>
  <div class="progress l2d">
    <div class="progress-bar l2d" role="progressbar" style="width: %" aria-valuenow="" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar" style="display: flex">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle sticky-top" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner sticky-top">
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Learner View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="instructor/aio.html">Instructor View</a>
                      </div>
                    </div>
                  </div>
<!--/div.accordion-item-->
                </div>
<!--/div.accordion-flush-->
              </div>
<!--div.sidenav-view-selector -->
            </div>
<!--/div.col -->

            <hr>
</div>
<!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Setup</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="01-classification_intro.html">1. Classification</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="02-improvement.html">2. Improvement</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="03-refinement.html">3. Refinement</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width">
<div class="accordion accordion-flush resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul>
<li>
                        <a href="key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="reference.html#glossary">Glossary</a>
                      </li>
                      <li>
                        <a href="profiles.html">Learner Profiles</a>
                      </li>

                    </ul>
</div>
                </div>
              </div>
            </div>
            <hr class="half-width resources">
<a href="aio.html">See all in one page</a>


            <hr class="d-none d-sm-block d-md-none">
<div class="d-grid gap-1">

            </div>
          </div>
<!-- /div.accordion -->
        </div>
<!-- /div.sidebar-inner -->
      </nav>
</div>
<!-- /div.sidebar -->
  </div>
<!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-extra.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <main id="main-content" class="main-content"><div class="container lesson-content">
        
        
<section id="aio-01-classification_intro"><p>Content from <a href="01-classification_intro.html">Classification</a></p>
<hr>
<p>Last updated on 2025-03-31 |

        <a href="https://github.com/carpentries/workbench-template-md/edit/main/episodes/01-classification_intro.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<p><a href="https://drive.usercontent.google.com/u/1/uc?id=16T85vbrDYu4Z62ryFA5xVHpwrl7okIvy&amp;export=download" class="external-link"><strong>Download
Chapter notebook (ipynb)</strong></a></p>
<p><a href="https://drive.usercontent.google.com/u/1/uc?id=1nb6HmNUYC4RXMHv3bVY0NvLBikw_cH0m&amp;export=download" class="external-link"><strong>Download
Chapter PDF</strong></a></p>
<p><a href="https://docs.google.com/forms/d/e/1FAIpQLSdr0capF7jloJhPH3Pki1B3LZoKOG16poOpuVJ7SL2LkwLHQA/viewform?pli=1" class="external-link"><span style="color: rgb(255, 0, 0);"><strong>Mandatory Lesson Feedback
Survey</strong></span></a></p>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How to prepare data for classification?</li>
<li>Why do we need to train a model?</li>
<li>What does a state space plot represent?</li>
<li>How to obtain prediction probabilities?</li>
<li>What are the important features?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Understanding the classification challenge.</li>
<li>Training a classifier model.</li>
<li>Understanding the state space plot of model predictions.</li>
<li>Obtaining prediction probabilities.</li>
<li>Finding important features.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div id="prereq1" class="callout prereq">
<div class="callout-square">
<i class="callout-icon" data-feather="check"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Prerequisite</h3>
<div class="callout-content">
<ul>
<li><a href="https://learntodiscover.github.io/Data_Handling/" class="external-link">Data
Handling</a></li>
<li><a href="index.html#numpy">Numpy arrays (see accompanying
tutorial)</a></li>
<li><a href="https://matplotlib.org" class="external-link">Basic Matplotlib plotting</a></li>
</ul>
</div>
</div>
</div>
<p align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/NIU1JO26Jgk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
</p>
<br><p align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/3f627wXK6z0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
</p>
<br><p align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/EUrxpMr5bG4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
</p>
<p><br></p>
<div class="section level3">
<h3 id="import-functions">
<strong>Import functions</strong><a class="anchor" aria-label="anchor" href="#import-functions"></a>
</h3>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">from</span> pandas <span class="im">import</span> read_csv</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> arange, asarray, linspace, c_, meshgrid, zeros, ones</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="im">from</span> numpy.random <span class="im">import</span> uniform, seed</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="im">from</span> matplotlib.pyplot <span class="im">import</span> subplots, scatter, xlabel, ylabel, xticks, show</span></code></pre>
</div>
</div>
<section><h2 class="section-heading" id="example-visual-classification">Example: Visual Classification<a class="anchor" aria-label="anchor" href="#example-visual-classification"></a>
</h2>
<hr class="half-width">
<p>Import the ‘patients_data’ toy dataset and scatter the data for
Height and Weight.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="co"># Please adjust your path to the file</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>df <span class="op">=</span> read_csv(<span class="st">'data/patients_data.csv'</span>)</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a><span class="bu">print</span>(df.shape)</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a><span class="co"># Convert inches to cm and pounds to kg:</span></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>df[<span class="st">'Height'</span>] <span class="op">=</span> <span class="fl">2.540</span><span class="op">*</span>df[<span class="st">'Height'</span>]</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>df[<span class="st">'Weight'</span>] <span class="op">=</span> <span class="fl">0.454</span><span class="op">*</span>df[<span class="st">'Weight'</span>]</span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a>df.head(<span class="dv">10</span>)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>(100, 8)
   Age  Height  Weight  Systolic  Diastolic  Smoker  Gender  Peak Flow
0   38  180.34  79.904       124         93       1    Male        200
1   43  175.26  74.002       109         77       0    Male        615
2   38  162.56  59.474       125         83       0  Female        642
3   40  170.18  60.382       117         75       0  Female        511
4   49  162.56  54.026       122         80       0  Female        497
5   46  172.72  64.468       121         70       0  Female        528
6   33  162.56  64.468       130         88       1  Female        269
7   40  172.72  81.720       115         82       0    Male        324
8   28  172.72  83.082       115         78       0    Male        501
9   31  167.64  59.928       118         86       0  Female        723</code></pre>
</div>
<p style="text-align: justify;">
Note that data in the first five columns are either integers (age) or
real numbers (floating point). The classes (categorical data) in the
last two columns come as binary (0/1) for ‘smokers/non-smokers’ and as
strings for ‘male/female’. Both can be used for classification.
</p>
<div id="the-classification-challenge" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="the-classification-challenge" class="callout-inner">
<h3 class="callout-title">The classification challenge</h3>
<div class="callout-content">
<p style="text-align: justify;">
I am given a set of data from a single subject and feed them to a
computational model. The model then predicts to what (predefined)
<em>class</em> this subject belongs. Example: given height and weight
data, the model might try to predict whether the subject is a smoker or
a non-smoker. A naive model will, of course, not be able to predict
reasonably. The <em>supervised</em> approach in machine learning is to
provide the model with a set of data where the class has been verified
beforehand and the model can test its (initially random) predictions
against the provided class. An optimisation algorithm is then run to
adjust the (internal) model setting such that the predictions improve as
much as possible. When no further improvement is achieved, the algorithm
stops. The model is then <em>trained</em> and ready to predict.
</p>
</div>
</div>
</div>
<p style="text-align: justify;">
The act of classification is to assign labels to unlabelled data after
model exposure to previously labelled data (e.g. based on medical
knowledge in the case of disease data).
</p>
<p style="text-align: justify;">
In contrast, in <em>unsupervised machine learning</em> the assignment is
done based on exposure to unlabelled data following a search for
distinctive features or ‘structure’ in the data.
</p>
<p style="text-align: justify;">
We can first check if we are able to distinguish classes visually. For
this, we scatter the data of two columns of a dataframe using the column
names. That is, we look at the distribution of points in a plane. Then
we use the class <strong>label</strong> to color each point in the plane
according to the class it belongs to. String labels like ‘male’ /
‘female’ first need to be converted to Boolean (binary). 0/1 labels as
in the ‘smokers/non-smokers’ column can be used directly.
</p>
<p>Let us plot the height-weight data and label them for both cases.</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots(figsize<span class="op">=</span>(<span class="dv">12</span>,<span class="dv">6</span>),ncols<span class="op">=</span><span class="dv">2</span>,nrows<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>gender_boolean <span class="op">=</span> df[<span class="st">'Gender'</span>] <span class="op">==</span> <span class="st">'Female'</span></span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a>ax[<span class="dv">0</span>].scatter(df[<span class="st">'Height'</span>], df[<span class="st">'Weight'</span>], c<span class="op">=</span>gender_boolean, cmap<span class="op">=</span><span class="st">'bwr'</span>)</span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a>ax[<span class="dv">0</span>].set_xlabel(<span class="st">'Height'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>ax[<span class="dv">0</span>].set_ylabel(<span class="st">'Weight'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>ax[<span class="dv">0</span>].set_title(<span class="st">'Female (red), Male (blue)'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a>ax[<span class="dv">1</span>].scatter(df[<span class="st">'Height'</span>], df[<span class="st">'Weight'</span>], c<span class="op">=</span>df[<span class="st">'Smoker'</span>], cmap<span class="op">=</span><span class="st">'bwr'</span>)</span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a>ax[<span class="dv">1</span>].set_xlabel(<span class="st">'Height'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a>ax[<span class="dv">1</span>].set_ylabel(<span class="st">'Weight'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a>ax[<span class="dv">1</span>].set_title(<span class="st">'Smoker (red), Non-Smoker (blue)'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)<span class="op">;</span></span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" tabindex="-1"></a>show()</span></code></pre>
</div>
<figure><img src="fig/01-classification_intro-rendered-unnamed-chunk-3-1.png" width="1152" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p style="text-align: justify;">
It appears from these graphs that based on height and weight data it is
possible to distinguish male and female. Based on visual inspection one
could conclude that everybody with a weight lower than 70kg is female
and everybody with a weight above 70kg is male. That would be a
classification based on the weight alone. It also appears that the data
points classified as ‘male’ are taller on average, so it might be
helpful to have the height recorded as well. E.g it could improve the
prediction of gender for new subjects with a weight around 70 kg. But it
would not be the best choice if only a single quantity was used. Thus, a
second conclusion is that based on these data the weight is more
important for the classification than the height.
</p>
<p style="text-align: justify;">
On the other hand, based on the smoker / non-smoker data it will not be
possible to distinguish smokers from non-smokers. Red dots and blue dots
are scattered throughout the graph. The conclusion is that height and
weight cannot be used to predict whether a subject is a smoker.
</p>
</section><section><h2 class="section-heading" id="supervised-learning-training-a-model">Supervised Learning: Training a Model<a class="anchor" aria-label="anchor" href="#supervised-learning-training-a-model"></a>
</h2>
<hr class="half-width">
<p style="text-align: justify;">
This lesson deals with labelled data. Labelled data are numerical data
with an extra column of a <strong>label</strong> for each sample. A
sample can consist of any number of individual observations but must be
at least two.
</p>
Examples of labels include ‘control group / test group’; ‘male /
female’; ‘healthy / diseased’; ‘before treatment / after treatment’.
<p style="text-align: justify;">
The task in Supervised Machine Learning is to fit (train) a model to
distinguish between the groups by ‘learning’ from so-called training
data. After training, the optimised model automatically labels incoming
(unlabeled) data. The better the model, the better the labelling
(prediction).
</p>
<p style="text-align: justify;">
The model itself is a black box. It has set default parameters to start
with and thus performs badly in the beginning. Essentially, it starts by
predicting a label at random. The process of training consists in
repeatedly changing the model parameters such that the performance
improves. After the training, the model parameters are supposed to be
optimal. Of course, the model cannot be expected to reveal anything
about the mechanism or cause that underlies the distinction between the
labels.
</p>
<p>The performance of the model is tested by splitting a dataset with
labels into:</p>
<ul>
<li><p>the <code>train data</code>, those that will be used for model
fitting, and</p></li>
<li><p>the <code>test data</code>, those that will be used to check how
well the model predicts.</p></li>
</ul>
<p style="text-align: justify;">
The result of the model fitting is then assessed by checking how many of
the (withheld) labels in the test data were correctly predicted by the
trained model. We can also retrieve the confidence of the model
prediction, i.e. the probability that the assigned label is correct.
</p>
<p style="text-align: justify;">
As an additional result, the procedure will generate the so-called
feature importances: similar to how we concluded above that weight is
more important than height for gender prediction, the feature importance
informs to which degree each of the data columns actually contributes to
the predictions.
</p>
</section><section><h2 class="section-heading" id="scikit-learn">Scikit Learn<a class="anchor" aria-label="anchor" href="#scikit-learn"></a>
</h2>
<hr class="half-width">
<p>We will import our machine learning functionality from the <a href="https://scikit-learn.org/stable/" class="external-link">SciKit Learn library</a>.</p>
<div id="scikit-learn-1" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="scikit-learn-1" class="callout-inner">
<h3 class="callout-title">SciKit Learn</h3>
<div class="callout-content">
<p style="text-align: justify;">
SciKit Learn is a renowned open source application programming interface
(API) for machine learning. It enjoys a vibrant community and is well
maintained. It is always beneficial to use the official documentations
for every API. SciKit Learn provides an exceptional documentation with
detailed explanations and examples at every level.
</p>
</div>
</div>
</div>
<p style="text-align: justify;">
The implementation of algorithms in SciKit Learn follows a very specific
protocol. First and foremost, it uses a programming paradigm known as
object-oriented programming (OOP). Thanks to Python, this does not mean
that you as the user are also forced to use OOP. But you need to follow
a specific protocol to use the tools that are provided by SciKit Learn.
</p>
<p style="text-align: justify;">
Unlike functions that perform a specific task and return the results, in
OOP, we use <em>classes</em> to encapsulate interconnected components
and functionalities. In accordance with the convention of best practices
for Python programming (also known as PEP8), classes are implemented
with camel-case characters; e.g. <code>RandomForestClassifier</code>. In
contrast, functions should be implemented using lower-case characters
only; e.g. <code>min</code> or <code>round</code>.
</p>
</section><section><h2 class="section-heading" id="classification">Classification<a class="anchor" aria-label="anchor" href="#classification"></a>
</h2>
<hr class="half-width">
<div class="section level3">
<h3 id="prepare-data-with-labels">
<strong>Prepare data with labels</strong><a class="anchor" aria-label="anchor" href="#prepare-data-with-labels"></a>
</h3>
<p style="text-align: justify;">
The terminology that is widely used in Machine Learning (including
Scikit Learn) refers to data points as <strong>samples</strong>, and the
different types of recordings(columns in our case) are referred to as
<strong>features</strong>. In <code>Numpy</code> notation, samples are
organised in rows, features in columns.
</p>
<p style="text-align: justify;">
We can use the function <code>uniform</code> from numpy.random to
generate uniformly distributed random data. Here we create 100 samples
of two features (as in the visualisation above). We decide to have
values distributed between 0 and 100.
</p>
<p style="text-align: justify;">
The convention in machine learning is to call the training data ‘X’.
This array must be <strong>two dimensional</strong>, where rows are the
samples and columns are the features.
</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>low  <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>high <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>n_samples, m_features <span class="op">=</span> <span class="dv">100</span>, <span class="dv">2</span></span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>RANDOM_SEED  <span class="op">=</span> <span class="dv">1234</span></span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a>seed(RANDOM_SEED)</span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>random_numbers <span class="op">=</span> uniform(low<span class="op">=</span>low, high<span class="op">=</span>high, size<span class="op">=</span>(n_samples, m_features))</span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a></span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a>X <span class="op">=</span> random_numbers.<span class="bu">round</span>(<span class="dv">3</span>)</span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Dimensions of training data'</span>)</span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a><span class="bu">print</span>(<span class="st">''</span>)</span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Number of samples:  '</span>, X.shape[<span class="dv">0</span>])</span>
<span id="cb5-17"><a href="#cb5-17" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Number of features: '</span>, X.shape[<span class="dv">1</span>])</span>
<span id="cb5-18"><a href="#cb5-18" tabindex="-1"></a><span class="bu">print</span>(<span class="st">''</span>)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Dimensions of training data

Number of samples:   100
Number of features:  2</code></pre>
</div>
<div id="note" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="note" class="callout-inner">
<h3 class="callout-title">Note</h3>
<div class="callout-content">
<p style="text-align: justify;">
This code uses a <strong>random number generator</strong>. The output of
a random number generator is different each time it is run. On the one
hand, this is good because it allows us to create many realisations of
samples drawn from a fixed distribution. On the other hand, when testing
and sharing code this prevents exact reproduction of results. We
therefore use the <code>seed</code> function to reset the generator such
that with a given number for the seed (the parameter called
<code>RANDOM_SEED</code>) the same numbers are produced.
</p>
</div>
</div>
</div>
<p>Let us check the histograms of both features:</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots()</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>ax.hist(X, bins<span class="op">=</span><span class="dv">10</span>)<span class="op">;</span></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>show()</span></code></pre>
</div>
<figure><img src="fig/01-classification_intro-rendered-unnamed-chunk-5-3.png" width="672" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p style="text-align: justify;">
We find that both features are distributed over the selected range of
values. Due to the small number of samples, the distribution is not very
even.
</p>
<p style="text-align: justify;">
The categorical data used to distinguish between different classes are
called <strong>labels</strong>. Let us create an artificial set of
labels for our first classification task.
</p>
<p style="text-align: justify;">
We pick an arbitrary threshold and call all values <code>True</code> if
the values in both the first and the second feature are above the
threshold. The resulting labels <code>True</code> and <code>False</code>
can be viewed as 0/1 using the method <code>astype</code> with argument
<code>int</code>.
</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a>threshold <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>y <span class="op">=</span> (X[:,<span class="dv">0</span>] <span class="op">&gt;</span> threshold) <span class="op">&amp;</span> (X[:,<span class="dv">1</span>] <span class="op">&gt;</span> threshold)</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a>y.astype(<span class="bu">int</span>)</span></code></pre>
</div>
<p>array([0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,
0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,
0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,
0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,
0, 0, 0, 0, 0, 0, 1])</p>
<p>If both features (columns) were risk factors, this might be
interpreted as: only if both risk factors are above the threshold, a
subject is classified as ‘at risk’, meaning it gets label ‘True’ or
‘1’.</p>
<p>Labels must be <strong>one-dimensional</strong>. You can check this
by printing the <code>shape</code>. The output should be a single
number:</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Number of labels:'</span>, y.shape)</span></code></pre>
</div>
<p>Number of labels: (100,)</p>
</div>
<div class="section level3">
<h3 id="the-random-forest-classifier">
<strong>The Random Forest Classifier</strong><a class="anchor" aria-label="anchor" href="#the-random-forest-classifier"></a>
</h3>
<p>To start with our learning algorithm, we import one of the many
classifiers from Scikit Learn: it is called Random Forest.</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span></code></pre>
</div>
<p>The Random Forest is a member of the ensemble learning family, whose
objective is to combine the predictions of several optimisations to
improve their performance, generalisability, and robustness.</p>
<p>Ensemble methods are often divided into two different categories:</p>
<ol style="list-style-type: decimal">
<li><p>Averaging methods: Build several estimators independently, and
average their predictions. In general, the combined estimator tends to
perform better than any single estimator due to the reduction in
variance. Examples: Random Forest and Decision Tree.</p></li>
<li><p>Boosting methods: Build the estimators sequentially, and attempt
to reduce the bias of the combined estimator. Although the performance
of individual estimators may be weak, upon combination, they amount to a
powerful ensemble. Examples: Gradient Boosting and AdaBoost.</p></li>
</ol>
<p style="text-align: justify;">
We now train a model using the Python class for the Random Forest
classifier. Unlike a function (which we can use out of the box) a class
needs to be <em>instantiated</em> before it can be used. In Python, we
instantiate a class as follows:
</p>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>clf <span class="op">=</span> RandomForestClassifier(random_state<span class="op">=</span>RANDOM_SEED)</span></code></pre>
</div>
<p style="text-align: justify;">
where <code>clf</code> now represents an <em>instance</em> of class
<code>RandomForestClassifier</code>. Note that we have set the keyword
argument <code>random_state</code> to a number. This is to assure
reproducibility of the results. (It does not have to be the same as
above, pick any integer).
</p>
<p>The instance of a class is typically referred to as an object, whose
type is the class that it represents:</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Type of clf:'</span>, <span class="bu">type</span>(clf))</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a><span class="bu">print</span>(<span class="st">''</span>)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Type of clf: &lt;class 'sklearn.ensemble._forest.RandomForestClassifier'&gt;</code></pre>
</div>
<p style="text-align: justify;">
Once instantiated, we can use this object, <code>clf</code>, to access
the methods that are associated with that class. Methods are essentially
functions that are encapsulated inside a class.
</p>
<p style="text-align: justify;">
In SciKit Learn all classes have a <code>.fit()</code> method. Its
function is to receive the training data and perform the training of the
model.
</p>
</div>
<div class="section level3">
<h3 id="train-a-model">Train a model<a class="anchor" aria-label="anchor" href="#train-a-model"></a>
</h3>
<p>To train a model, we apply the fit method to the training data,
labelled ‘X’, given the corresponding labels ‘y’:</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a>clf.fit(X, y)</span></code></pre>
</div>
<style>#sk-container-id-1 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: #000;
  --sklearn-color-text-muted: #666;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-1 {
  color: var(--sklearn-color-text);
}

#sk-container-id-1 pre {
  padding: 0;
}

#sk-container-id-1 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-1 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-1 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-1 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-1 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-1 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-1 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-1 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-1 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-1 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-1 label.sk-toggleable__label {
  cursor: pointer;
  display: flex;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
  align-items: start;
  justify-content: space-between;
  gap: 0.5em;
}

#sk-container-id-1 label.sk-toggleable__label .caption {
  font-size: 0.6rem;
  font-weight: lighter;
  color: var(--sklearn-color-text-muted);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-1 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-1 div.sk-label label.sk-toggleable__label,
#sk-container-id-1 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-1 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-1 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-1 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-1 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 0.5em;
  text-align: center;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-1 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-1 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-1 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-1 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style>
<div id="sk-container-id-1" class="sk-top-container">
<div class="sk-text-repr-fallback">
<pre>RandomForestClassifier(random_state=1234)</pre>
<b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b>
</div>
<div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator fitted sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>RandomForestClassifier</div></div>
<div>
<a class="external-link sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html">?<span>Documentation for RandomForestClassifier</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span>
</div></label><div class="sk-toggleable__content fitted"><pre>RandomForestClassifier(random_state=1234)</pre></div> </div></div></div>
</div>
<p>And that’s it. All the machine learning magic done. <code>clf</code>
is now a trained model with optimised parameters which we can use to
predict new data.</p>
</div>
<div class="section level3">
<h3 id="predict-test-data">
<strong>Predict Test Data</strong><a class="anchor" aria-label="anchor" href="#predict-test-data"></a>
</h3>
</div>
<div class="section level3">
<h3 id="categorical-prediction">Categorical Prediction<a class="anchor" aria-label="anchor" href="#categorical-prediction"></a>
</h3>
<p style="text-align: justify;">
We start by creating a number of test data in the same way as we created
the training data. Note that the number of test samples is arbitrary.
You can create any number of samples. However, you must provide the same
number of features (columns) used in the training of the classifier. In
our case that is 2.
</p>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a>RANDOM_SEED_2 <span class="op">=</span> <span class="dv">123</span></span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a>seed(RANDOM_SEED_2)</span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a>new_samples <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a>features <span class="op">=</span> X.shape[<span class="dv">1</span>]</span>
<span id="cb15-8"><a href="#cb15-8" tabindex="-1"></a></span>
<span id="cb15-9"><a href="#cb15-9" tabindex="-1"></a>new_data <span class="op">=</span> uniform(low<span class="op">=</span>low, high<span class="op">=</span>high, size<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">2</span>))</span>
<span id="cb15-10"><a href="#cb15-10" tabindex="-1"></a></span>
<span id="cb15-11"><a href="#cb15-11" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Shape of new data'</span>, new_data.shape)</span>
<span id="cb15-12"><a href="#cb15-12" tabindex="-1"></a><span class="bu">print</span>(<span class="st">''</span>)</span>
<span id="cb15-13"><a href="#cb15-13" tabindex="-1"></a><span class="bu">print</span>(new_data)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Shape of new data (10, 2)

[[69.64691856 28.6139335 ]
 [22.68514536 55.13147691]
 [71.94689698 42.31064601]
 [98.07641984 68.48297386]
 [48.09319015 39.21175182]
 [34.31780162 72.90497074]
 [43.85722447  5.96778966]
 [39.80442553 73.79954057]
 [18.24917305 17.54517561]
 [53.15513738 53.18275871]]</code></pre>
</div>
<p style="text-align: justify;">
There are 10 randomly created pairs of numbers in the same range as the
training data. They represent ‘unlabelled’ incoming data which we offer
to the trained model.
</p>
<p>The method <code>.predict()</code> helps us to find out what the
model claims these data to be:</p>
<div class="codewrapper sourceCode" id="cb17">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a>predictions <span class="op">=</span> clf.predict(new_data)</span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Predictions: '</span>, predictions)</span></code></pre>
</div>
<p>Predictions: [False False False True False False False False False
True]</p>
<p>They can also be viewed as zeros and ones:</p>
<div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a>predictions.astype(<span class="bu">int</span>)</span></code></pre>
</div>
<p>array([0, 0, 0, 1, 0, 0, 0, 0, 0, 1])</p>
<p>According to the model, data points with indices 3, and 9 are in
class <code>True</code> (or <code>1</code>).</p>
<p style="text-align: justify;">
Predicting individual samples is fine, but does not tell us whether the
classifier was able to create a good model of the class distinction. To
check the training result systematically, we create a state space grid
over the state space. This is the same as creating a coordinate system
of data points (as in a scatter plot), in our case with values from 0 to
100 in each feature.
</p>
<p>Here we use a resolution of 100, ie. we create a 100 by 100 grid:</p>
<div class="codewrapper sourceCode" id="cb19">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a>resolution <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" tabindex="-1"></a>vec_a <span class="op">=</span> linspace(low, high, resolution)</span>
<span id="cb19-4"><a href="#cb19-4" tabindex="-1"></a>vec_b <span class="op">=</span> vec_a</span>
<span id="cb19-5"><a href="#cb19-5" tabindex="-1"></a></span>
<span id="cb19-6"><a href="#cb19-6" tabindex="-1"></a>grid_a, grid_b <span class="op">=</span> meshgrid(vec_a, vec_b)</span>
<span id="cb19-7"><a href="#cb19-7" tabindex="-1"></a></span>
<span id="cb19-8"><a href="#cb19-8" tabindex="-1"></a>grid_a_flat <span class="op">=</span> grid_a.ravel()</span>
<span id="cb19-9"><a href="#cb19-9" tabindex="-1"></a>grid_b_flat <span class="op">=</span> grid_b.ravel()</span>
<span id="cb19-10"><a href="#cb19-10" tabindex="-1"></a></span>
<span id="cb19-11"><a href="#cb19-11" tabindex="-1"></a>XY_statespace <span class="op">=</span> c_[grid_a_flat, grid_b_flat]</span>
<span id="cb19-12"><a href="#cb19-12" tabindex="-1"></a></span>
<span id="cb19-13"><a href="#cb19-13" tabindex="-1"></a><span class="bu">print</span>(XY_statespace.shape)</span></code></pre>
</div>
<p>(10000, 2)</p>
<p style="text-align: justify;">
Now we can offer the grid of the X-Y state space as ‘new data’ to the
classifier and obtain the predictions. We can then plot the grid points
and colour them according to the labels assigned by the trained model.
</p>
<div class="codewrapper sourceCode" id="cb20">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a>predictions <span class="op">=</span> clf.predict(XY_statespace)</span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" tabindex="-1"></a>predictions.shape</span></code></pre>
</div>
<p>(10000,)</p>
<p>We obtain 10,000 predictions, one for each point on the grid.</p>
<p>To compare the data with the original thresholds and the model
predictions we can use plots of the state space:</p>
<div class="codewrapper sourceCode" id="cb21">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a>feature_1, feature_2 <span class="op">=</span> <span class="dv">0</span>, <span class="dv">1</span></span>
<span id="cb21-2"><a href="#cb21-2" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots(ncols<span class="op">=</span><span class="dv">2</span>, nrows<span class="op">=</span><span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb21-4"><a href="#cb21-4" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" tabindex="-1"></a>ax[<span class="dv">0</span>].scatter(X[:, feature_1], X[:, feature_2], c<span class="op">=</span>y, s<span class="op">=</span><span class="dv">4</span>, cmap<span class="op">=</span><span class="st">'bwr'</span>)<span class="op">;</span></span>
<span id="cb21-6"><a href="#cb21-6" tabindex="-1"></a>ax[<span class="dv">1</span>].scatter(XY_statespace[:, feature_1], XY_statespace[:, feature_2], c<span class="op">=</span>predictions, s<span class="op">=</span><span class="dv">1</span>, cmap<span class="op">=</span><span class="st">'bwr'</span>)<span class="op">;</span></span>
<span id="cb21-7"><a href="#cb21-7" tabindex="-1"></a></span>
<span id="cb21-8"><a href="#cb21-8" tabindex="-1"></a>p1, p2 <span class="op">=</span> [threshold, threshold], [<span class="dv">100</span>, threshold]</span>
<span id="cb21-9"><a href="#cb21-9" tabindex="-1"></a>p3, p4 <span class="op">=</span> [threshold, <span class="dv">100</span>], [threshold, threshold]</span>
<span id="cb21-10"><a href="#cb21-10" tabindex="-1"></a></span>
<span id="cb21-11"><a href="#cb21-11" tabindex="-1"></a>ax[<span class="dv">0</span>].plot(p1, p2, c<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb21-12"><a href="#cb21-12" tabindex="-1"></a>ax[<span class="dv">0</span>].plot(p3, p4, c<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb21-13"><a href="#cb21-13" tabindex="-1"></a></span>
<span id="cb21-14"><a href="#cb21-14" tabindex="-1"></a>ax[<span class="dv">0</span>].set_xlabel(<span class="st">'Feature 1'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb21-15"><a href="#cb21-15" tabindex="-1"></a>ax[<span class="dv">0</span>].set_ylabel(<span class="st">'Feature 2'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)<span class="op">;</span></span>
<span id="cb21-16"><a href="#cb21-16" tabindex="-1"></a>ax[<span class="dv">1</span>].set_xlabel(<span class="st">'Feature 1'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)<span class="op">;</span></span>
<span id="cb21-17"><a href="#cb21-17" tabindex="-1"></a></span>
<span id="cb21-18"><a href="#cb21-18" tabindex="-1"></a>show()</span></code></pre>
</div>
<figure><img src="fig/01-classification_intro-rendered-unnamed-chunk-17-5.png" width="960" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p style="text-align: justify;">
Left is a scatter plot of the data points used for training. They are
coloured according to their labels. The black lines indicate the
threshold boundaries that we introduced to distinguish the two classes.
On the right hand side are the predictions for the coordinate grid.
Label 0 is blue, label 1 is red.
</p>
<p style="text-align: justify;">
Based on the training samples (left), a good classification can be
achieved with the model (right). But some problems persist. In
particular, the boundaries are not sharp.
</p>
</div>
<div class="section level3">
<h3 id="probability-prediction">Probability Prediction<a class="anchor" aria-label="anchor" href="#probability-prediction"></a>
</h3>
<p style="text-align: justify;">
Let us pick a sample near the boundary. We can get its predicted label.
In addition, using <code>.predict_proba()</code> we can get the
probability of this prediction. This reflects the confidence in the
prediction. 50% probability means, the prediction is at chance level,
i.e. equivalent to a coin toss.
</p>
<div class="codewrapper sourceCode" id="cb22">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" tabindex="-1"></a>pos <span class="op">=</span> <span class="dv">55</span></span>
<span id="cb22-2"><a href="#cb22-2" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" tabindex="-1"></a>test_sample <span class="op">=</span> [[pos, pos]]</span>
<span id="cb22-4"><a href="#cb22-4" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" tabindex="-1"></a>test_sample_label <span class="op">=</span> clf.predict(test_sample)</span>
<span id="cb22-6"><a href="#cb22-6" tabindex="-1"></a></span>
<span id="cb22-7"><a href="#cb22-7" tabindex="-1"></a>test_sample_proba <span class="op">=</span> clf.predict_proba(test_sample)</span>
<span id="cb22-8"><a href="#cb22-8" tabindex="-1"></a></span>
<span id="cb22-9"><a href="#cb22-9" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Prediction:'</span>, test_sample_label)</span>
<span id="cb22-10"><a href="#cb22-10" tabindex="-1"></a><span class="bu">print</span>(clf.classes_, test_sample_proba)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Prediction: [False]
[False  True] [[0.57 0.43]]</code></pre>
</div>
<div class="codewrapper sourceCode" id="cb24">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" tabindex="-1"></a>bins <span class="op">=</span> arange(test_sample_proba.shape[<span class="dv">1</span>])</span>
<span id="cb24-2"><a href="#cb24-2" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots()</span>
<span id="cb24-4"><a href="#cb24-4" tabindex="-1"></a></span>
<span id="cb24-5"><a href="#cb24-5" tabindex="-1"></a>ax.bar(bins, test_sample_proba[<span class="dv">0</span>,:], color<span class="op">=</span>(<span class="st">'b'</span>, <span class="st">'r'</span>))</span>
<span id="cb24-6"><a href="#cb24-6" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Probability'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb24-7"><a href="#cb24-7" tabindex="-1"></a>xticks(bins, (<span class="st">'Label 0'</span>, <span class="st">'Label 1'</span>), fontsize<span class="op">=</span><span class="dv">16</span>)<span class="op">;</span></span>
<span id="cb24-8"><a href="#cb24-8" tabindex="-1"></a></span>
<span id="cb24-9"><a href="#cb24-9" tabindex="-1"></a>show()</span></code></pre>
</div>
<figure><img src="fig/01-classification_intro-rendered-unnamed-chunk-19-7.png" width="672" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p style="text-align: justify;">
Even though the sample is from the region that (according to the
creation of the data) is in the ‘True’ region, it is labelled as false.
The reason is that there were few or no training data points in that
specific region.
</p>
<p style="text-align: justify;">
Here is a plot of the probability for the state space. White represents
False and Black represents True, the values in between are gray coded.
Note that the probability values are complementary. We only need the
probabilities for one of our classes.
</p>
<div class="codewrapper sourceCode" id="cb25">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" tabindex="-1"></a>state_space_proba <span class="op">=</span> clf.predict_proba(XY_statespace)</span>
<span id="cb25-2"><a href="#cb25-2" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" tabindex="-1"></a>grid_shape <span class="op">=</span> grid_a.shape</span>
<span id="cb25-4"><a href="#cb25-4" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" tabindex="-1"></a>proba_grid <span class="op">=</span> state_space_proba[:, <span class="dv">1</span>].reshape(grid_shape)</span>
<span id="cb25-6"><a href="#cb25-6" tabindex="-1"></a></span>
<span id="cb25-7"><a href="#cb25-7" tabindex="-1"></a>contour_levels <span class="op">=</span> linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">6</span>)</span>
<span id="cb25-8"><a href="#cb25-8" tabindex="-1"></a></span>
<span id="cb25-9"><a href="#cb25-9" tabindex="-1"></a></span>
<span id="cb25-10"><a href="#cb25-10" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">5</span>))</span>
<span id="cb25-11"><a href="#cb25-11" tabindex="-1"></a></span>
<span id="cb25-12"><a href="#cb25-12" tabindex="-1"></a>cax <span class="op">=</span> ax.contourf(grid_a, grid_b, proba_grid, cmap<span class="op">=</span><span class="st">'Greys'</span>, levels<span class="op">=</span>contour_levels)</span>
<span id="cb25-13"><a href="#cb25-13" tabindex="-1"></a>fig.colorbar(cax)</span>
<span id="cb25-14"><a href="#cb25-14" tabindex="-1"></a></span>
<span id="cb25-15"><a href="#cb25-15" tabindex="-1"></a>ax.scatter(test_sample[<span class="dv">0</span>][<span class="dv">0</span>], test_sample[<span class="dv">0</span>][<span class="dv">1</span>], c<span class="op">=</span><span class="st">'r'</span>, marker<span class="op">=</span><span class="st">'o'</span>, s<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb25-16"><a href="#cb25-16" tabindex="-1"></a></span>
<span id="cb25-17"><a href="#cb25-17" tabindex="-1"></a>ax.plot(p1, p2, p3, p4, c<span class="op">=</span><span class="st">'r'</span>)</span>
<span id="cb25-18"><a href="#cb25-18" tabindex="-1"></a></span>
<span id="cb25-19"><a href="#cb25-19" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Feature 1'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb25-20"><a href="#cb25-20" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Feature 2'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)<span class="op">;</span></span>
<span id="cb25-21"><a href="#cb25-21" tabindex="-1"></a></span>
<span id="cb25-22"><a href="#cb25-22" tabindex="-1"></a>show()</span></code></pre>
</div>
<figure><img src="fig/01-classification_intro-rendered-unnamed-chunk-20-9.png" width="576" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>The single red dot marks the individual data point we used to
illustrate the prediction probability above.</p>
</div>
<div class="section level3">
<h3 id="feature-importances">Feature Importances<a class="anchor" aria-label="anchor" href="#feature-importances"></a>
</h3>
<p style="text-align: justify;">
We can check the contribution of each feature for the success of the
classification. The feature importance is given as the fraction
contribution of each feature to the prediction.
</p>
<div class="codewrapper sourceCode" id="cb26">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" tabindex="-1"></a>importances <span class="op">=</span> clf.feature_importances_</span>
<span id="cb26-2"><a href="#cb26-2" tabindex="-1"></a></span>
<span id="cb26-3"><a href="#cb26-3" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Relative importance:'</span>)</span>
<span id="cb26-4"><a href="#cb26-4" tabindex="-1"></a></span>
<span id="cb26-5"><a href="#cb26-5" tabindex="-1"></a>template <span class="op">=</span> <span class="st">'Feature 1: </span><span class="sc">{:.1f}</span><span class="st">%; Feature 2: </span><span class="sc">{:.1f}</span><span class="st">%'</span></span>
<span id="cb26-6"><a href="#cb26-6" tabindex="-1"></a></span>
<span id="cb26-7"><a href="#cb26-7" tabindex="-1"></a><span class="bu">print</span>(template.<span class="bu">format</span>(importances[<span class="dv">0</span>]<span class="op">*</span><span class="dv">100</span>, importances[<span class="dv">1</span>]<span class="op">*</span><span class="dv">100</span>))</span>
<span id="cb26-8"><a href="#cb26-8" tabindex="-1"></a></span>
<span id="cb26-9"><a href="#cb26-9" tabindex="-1"></a>bins <span class="op">=</span> arange(importances.shape[<span class="dv">0</span>])</span>
<span id="cb26-10"><a href="#cb26-10" tabindex="-1"></a></span>
<span id="cb26-11"><a href="#cb26-11" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots()</span>
<span id="cb26-12"><a href="#cb26-12" tabindex="-1"></a></span>
<span id="cb26-13"><a href="#cb26-13" tabindex="-1"></a>ax.bar(bins, importances, color<span class="op">=</span>(<span class="st">'g'</span>, <span class="st">'m'</span>))<span class="op">;</span></span>
<span id="cb26-14"><a href="#cb26-14" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Feature Importance'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb26-15"><a href="#cb26-15" tabindex="-1"></a></span>
<span id="cb26-16"><a href="#cb26-16" tabindex="-1"></a>xticks(bins, (<span class="st">'Feature 1'</span>, <span class="st">'Feature 2'</span>), fontsize<span class="op">=</span><span class="dv">16</span>)<span class="op">;</span></span>
<span id="cb26-17"><a href="#cb26-17" tabindex="-1"></a></span>
<span id="cb26-18"><a href="#cb26-18" tabindex="-1"></a>show()</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Relative importance:
Feature 1: 61.6%; Feature 2: 38.4%</code></pre>
</div>
<figure><img src="fig/01-classification_intro-rendered-unnamed-chunk-21-11.png" width="672" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>In this case, the predictions are based on a 61% contribution from
feature 1 and a 38% contribution from feature 2.</p>
<div id="note-1" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="note-1" class="callout-inner">
<h3 class="callout-title">Note</h3>
<div class="callout-content">
<p style="text-align: justify;">
</p>
<p>It should be noted that the attribute
<code>.feature_importances_</code> will not work if applied to a
Multi-Layer Pereceptron (MLP) Classifier. This attribute actually only
works with specific models such as random forest or decision trees.</p>
<p>We can, however, make use of a permutation-based feature importance
measure for the MLP classifier, instead. This can be accessed using the
function <code>.permutation_importance</code>, which measures the
decrease in the model’s performance, each time a specific feature is
shuffled; effectively measuring its importance to the resulting
prediction.</p>
<p>This attribute is available within scikit-learn’s inspection
sub-library, and assuming you have a trained classifier stored in a
variable, you could use it, as follows:</p>
<div class="codewrapper sourceCode" id="cb28">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" tabindex="-1"></a><span class="im">from</span> sklearn.neural_network <span class="im">import</span> MLPClassifier</span>
<span id="cb28-2"><a href="#cb28-2" tabindex="-1"></a><span class="im">from</span> sklearn.inspection <span class="im">import</span> permutation_importance</span>
<span id="cb28-3"><a href="#cb28-3" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_iris</span>
<span id="cb28-4"><a href="#cb28-4" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb28-5"><a href="#cb28-5" tabindex="-1"></a></span>
<span id="cb28-6"><a href="#cb28-6" tabindex="-1"></a><span class="co"># Load a simple dataset</span></span>
<span id="cb28-7"><a href="#cb28-7" tabindex="-1"></a>X, y <span class="op">=</span> load_iris(return_X_y<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb28-8"><a href="#cb28-8" tabindex="-1"></a></span>
<span id="cb28-9"><a href="#cb28-9" tabindex="-1"></a><span class="co"># Split into train and test sets</span></span>
<span id="cb28-10"><a href="#cb28-10" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb28-11"><a href="#cb28-11" tabindex="-1"></a></span>
<span id="cb28-12"><a href="#cb28-12" tabindex="-1"></a><span class="co"># Train a multi-layer perceptron classifier</span></span>
<span id="cb28-13"><a href="#cb28-13" tabindex="-1"></a>clf <span class="op">=</span> MLPClassifier(max_iter<span class="op">=</span><span class="dv">1000</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb28-14"><a href="#cb28-14" tabindex="-1"></a>clf.fit(X_train, y_train)</span></code></pre>
</div>
<style>#sk-container-id-2 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: #000;
  --sklearn-color-text-muted: #666;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-2 {
  color: var(--sklearn-color-text);
}

#sk-container-id-2 pre {
  padding: 0;
}

#sk-container-id-2 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-2 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-2 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-2 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-2 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-2 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-2 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-2 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-2 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-2 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-2 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-2 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-2 label.sk-toggleable__label {
  cursor: pointer;
  display: flex;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
  align-items: start;
  justify-content: space-between;
  gap: 0.5em;
}

#sk-container-id-2 label.sk-toggleable__label .caption {
  font-size: 0.6rem;
  font-weight: lighter;
  color: var(--sklearn-color-text-muted);
}

#sk-container-id-2 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-2 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-2 div.sk-label label.sk-toggleable__label,
#sk-container-id-2 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-2 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-2 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-2 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-2 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 0.5em;
  text-align: center;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-2 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-2 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-2 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-2 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style>
<div id="sk-container-id-2" class="sk-top-container">
<div class="sk-text-repr-fallback">
<pre>MLPClassifier(max_iter=1000, random_state=42)</pre>
<b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b>
</div>
<div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator fitted sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" checked><label for="sk-estimator-id-2" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>MLPClassifier</div></div>
<div>
<a class="external-link sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.neural_network.MLPClassifier.html">?<span>Documentation for MLPClassifier</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span>
</div></label><div class="sk-toggleable__content fitted"><pre>MLPClassifier(max_iter=1000, random_state=42)</pre></div> </div></div></div>
</div>
<div class="codewrapper sourceCode" id="cb29">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" tabindex="-1"></a><span class="co"># Compute permutation importance on the test set</span></span>
<span id="cb29-2"><a href="#cb29-2" tabindex="-1"></a>result <span class="op">=</span> permutation_importance(clf, X_test, y_test, n_repeats<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">123</span>)</span>
<span id="cb29-3"><a href="#cb29-3" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" tabindex="-1"></a><span class="co"># Display the mean importance for each feature</span></span>
<span id="cb29-5"><a href="#cb29-5" tabindex="-1"></a><span class="bu">print</span>(result.importances_mean)</span></code></pre>
</div>
<p>[0.07368421 0.02105263 0.62368421 0.21578947]</p>

</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="application">Application<a class="anchor" aria-label="anchor" href="#application"></a>
</h2>
<hr class="half-width">
<p>Now we pick the ‘Height’ and ‘Weight’ columns from the patients data
to predict the gender labels. We use a split of 4/5 of the data for
training and 1/5 for testing.</p>
<div class="codewrapper sourceCode" id="cb30">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" tabindex="-1"></a>df <span class="op">=</span> read_csv(<span class="st">'data/patients_data.csv'</span>)</span>
<span id="cb30-2"><a href="#cb30-2" tabindex="-1"></a></span>
<span id="cb30-3"><a href="#cb30-3" tabindex="-1"></a><span class="bu">print</span>(df.shape)</span>
<span id="cb30-4"><a href="#cb30-4" tabindex="-1"></a></span>
<span id="cb30-5"><a href="#cb30-5" tabindex="-1"></a><span class="co"># Convert pounds to kg and inches to cm:</span></span>
<span id="cb30-6"><a href="#cb30-6" tabindex="-1"></a>df[<span class="st">'Weight'</span>] <span class="op">=</span> <span class="fl">0.454</span><span class="op">*</span>df[<span class="st">'Weight'</span>]</span>
<span id="cb30-7"><a href="#cb30-7" tabindex="-1"></a>df[<span class="st">'Height'</span>] <span class="op">=</span> <span class="fl">2.540</span><span class="op">*</span>df[<span class="st">'Height'</span>]</span>
<span id="cb30-8"><a href="#cb30-8" tabindex="-1"></a></span>
<span id="cb30-9"><a href="#cb30-9" tabindex="-1"></a>df.head(<span class="dv">10</span>)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>(100, 8)
   Age  Height  Weight  Systolic  Diastolic  Smoker  Gender  Peak Flow
0   38  180.34  79.904       124         93       1    Male        200
1   43  175.26  74.002       109         77       0    Male        615
2   38  162.56  59.474       125         83       0  Female        642
3   40  170.18  60.382       117         75       0  Female        511
4   49  162.56  54.026       122         80       0  Female        497
5   46  172.72  64.468       121         70       0  Female        528
6   33  162.56  64.468       130         88       1  Female        269
7   40  172.72  81.720       115         82       0    Male        324
8   28  172.72  83.082       115         78       0    Male        501
9   31  167.64  59.928       118         86       0  Female        723</code></pre>
</div>
<div class="section level3">
<h3 id="prepare-training-data-and-labels">
<strong>Prepare training data and labels</strong><a class="anchor" aria-label="anchor" href="#prepare-training-data-and-labels"></a>
</h3>
<div class="codewrapper sourceCode" id="cb32">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" tabindex="-1"></a><span class="co"># Extract data as numpy array</span></span>
<span id="cb32-2"><a href="#cb32-2" tabindex="-1"></a>df_np <span class="op">=</span> df.to_numpy()</span>
<span id="cb32-3"><a href="#cb32-3" tabindex="-1"></a></span>
<span id="cb32-4"><a href="#cb32-4" tabindex="-1"></a><span class="co"># Pick a fraction of height and weight data as training data</span></span>
<span id="cb32-5"><a href="#cb32-5" tabindex="-1"></a>samples <span class="op">=</span> <span class="dv">80</span></span>
<span id="cb32-6"><a href="#cb32-6" tabindex="-1"></a></span>
<span id="cb32-7"><a href="#cb32-7" tabindex="-1"></a>X <span class="op">=</span> df_np[:samples, [<span class="dv">1</span>, <span class="dv">2</span>]]</span>
<span id="cb32-8"><a href="#cb32-8" tabindex="-1"></a></span>
<span id="cb32-9"><a href="#cb32-9" tabindex="-1"></a><span class="bu">print</span>(X.shape)</span></code></pre>
</div>
<p>(80, 2)</p>
<p>For the labels of the training data we convert the ‘Male’ and
‘Female’ strings to categorical values.</p>
<div class="codewrapper sourceCode" id="cb33">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" tabindex="-1"></a>gender_boolean <span class="op">=</span> df[<span class="st">'Gender'</span>] <span class="op">==</span> <span class="st">'Female'</span></span>
<span id="cb33-2"><a href="#cb33-2" tabindex="-1"></a></span>
<span id="cb33-3"><a href="#cb33-3" tabindex="-1"></a>y <span class="op">=</span> gender_boolean[:<span class="dv">80</span>]</span>
<span id="cb33-4"><a href="#cb33-4" tabindex="-1"></a></span>
<span id="cb33-5"><a href="#cb33-5" tabindex="-1"></a><span class="co"># printed as 0 and 1:</span></span>
<span id="cb33-6"><a href="#cb33-6" tabindex="-1"></a></span>
<span id="cb33-7"><a href="#cb33-7" tabindex="-1"></a>y.astype(<span class="st">'int'</span>)</span></code></pre>
</div>
<p>0 0 1 0 2 1 3 1 4 1 .. 75 0 76 1 77 0 78 0 79 1 Name: Gender, Length:
80, dtype: int64</p>
</div>
<div class="section level3">
<h3 id="train-classifier-and-predict">
<strong>Train classifier and predict</strong><a class="anchor" aria-label="anchor" href="#train-classifier-and-predict"></a>
</h3>
<div class="codewrapper sourceCode" id="cb34">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb34-2"><a href="#cb34-2" tabindex="-1"></a></span>
<span id="cb34-3"><a href="#cb34-3" tabindex="-1"></a>seed(RANDOM_SEED)</span>
<span id="cb34-4"><a href="#cb34-4" tabindex="-1"></a></span>
<span id="cb34-5"><a href="#cb34-5" tabindex="-1"></a>clf <span class="op">=</span> RandomForestClassifier(random_state<span class="op">=</span>RANDOM_SEED)</span>
<span id="cb34-6"><a href="#cb34-6" tabindex="-1"></a></span>
<span id="cb34-7"><a href="#cb34-7" tabindex="-1"></a>clf.fit(X, y)</span></code></pre>
</div>
<style>#sk-container-id-3 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: #000;
  --sklearn-color-text-muted: #666;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-3 {
  color: var(--sklearn-color-text);
}

#sk-container-id-3 pre {
  padding: 0;
}

#sk-container-id-3 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-3 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-3 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-3 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-3 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-3 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-3 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-3 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-3 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-3 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-3 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-3 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-3 label.sk-toggleable__label {
  cursor: pointer;
  display: flex;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
  align-items: start;
  justify-content: space-between;
  gap: 0.5em;
}

#sk-container-id-3 label.sk-toggleable__label .caption {
  font-size: 0.6rem;
  font-weight: lighter;
  color: var(--sklearn-color-text-muted);
}

#sk-container-id-3 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-3 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-3 div.sk-label label.sk-toggleable__label,
#sk-container-id-3 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-3 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-3 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-3 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-3 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 0.5em;
  text-align: center;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-3 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-3 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-3 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-3 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style>
<div id="sk-container-id-3" class="sk-top-container">
<div class="sk-text-repr-fallback">
<pre>RandomForestClassifier(random_state=1234)</pre>
<b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b>
</div>
<div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator fitted sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox" checked><label for="sk-estimator-id-3" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>RandomForestClassifier</div></div>
<div>
<a class="external-link sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html">?<span>Documentation for RandomForestClassifier</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span>
</div></label><div class="sk-toggleable__content fitted"><pre>RandomForestClassifier(random_state=1234)</pre></div> </div></div></div>
</div>
<p>We now take the remaining fifth of the data to predict.</p>
<div class="codewrapper sourceCode" id="cb35">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" tabindex="-1"></a>X_test <span class="op">=</span> df.loc[<span class="dv">80</span>:, [<span class="st">'Height'</span>, <span class="st">'Weight'</span>]]</span>
<span id="cb35-2"><a href="#cb35-2" tabindex="-1"></a></span>
<span id="cb35-3"><a href="#cb35-3" tabindex="-1"></a>X_test <span class="op">=</span> X_test.values</span>
<span id="cb35-4"><a href="#cb35-4" tabindex="-1"></a></span>
<span id="cb35-5"><a href="#cb35-5" tabindex="-1"></a>predict_test <span class="op">=</span> clf.predict(X_test)</span>
<span id="cb35-6"><a href="#cb35-6" tabindex="-1"></a></span>
<span id="cb35-7"><a href="#cb35-7" tabindex="-1"></a>probab_test <span class="op">=</span> clf.predict_proba(X_test)</span>
<span id="cb35-8"><a href="#cb35-8" tabindex="-1"></a></span>
<span id="cb35-9"><a href="#cb35-9" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Predictions: '</span>, predict_test, <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>, <span class="st">'Probabilities: '</span>, <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>,  probab_test)</span></code></pre>
</div>
<p>Predictions: [False False False True True False True True True True
False False True False True False False False False False]
Probabilities:<br>
[[1. 0. ] [1. 0. ] [1. 0. ] [0. 1. ] [0. 1. ] [1. 0. ] [0. 1. ] [0. 1. ]
[0. 1. ] [0. 1. ] [1. 0. ] [1. 0. ] [0.02 0.98] [1. 0. ] [0. 1. ] [1. 0.
] [1. 0. ] [1. 0. ] [1. 0. ] [0.97 0.03]]</p>
<p>As in the example above, we create a state space grid to visualise
the outcome for the two features.</p>
<div class="codewrapper sourceCode" id="cb36">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" tabindex="-1"></a>X1_min, X1_max <span class="op">=</span> <span class="bu">min</span>(X[:, <span class="dv">0</span>]), <span class="bu">max</span>(X[:, <span class="dv">0</span>])</span>
<span id="cb36-2"><a href="#cb36-2" tabindex="-1"></a>X2_min, X2_max <span class="op">=</span> <span class="bu">min</span>(X[:, <span class="dv">1</span>]), <span class="bu">max</span>(X[:, <span class="dv">1</span>])</span>
<span id="cb36-3"><a href="#cb36-3" tabindex="-1"></a></span>
<span id="cb36-4"><a href="#cb36-4" tabindex="-1"></a>resolution <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb36-5"><a href="#cb36-5" tabindex="-1"></a></span>
<span id="cb36-6"><a href="#cb36-6" tabindex="-1"></a>vec_a <span class="op">=</span> linspace(X1_min, X1_max, resolution)</span>
<span id="cb36-7"><a href="#cb36-7" tabindex="-1"></a>vec_b <span class="op">=</span> linspace(X2_min, X2_max, resolution)</span>
<span id="cb36-8"><a href="#cb36-8" tabindex="-1"></a></span>
<span id="cb36-9"><a href="#cb36-9" tabindex="-1"></a>grid_a, grid_b <span class="op">=</span> meshgrid(vec_a, vec_b)</span>
<span id="cb36-10"><a href="#cb36-10" tabindex="-1"></a></span>
<span id="cb36-11"><a href="#cb36-11" tabindex="-1"></a></span>
<span id="cb36-12"><a href="#cb36-12" tabindex="-1"></a>grid_a_flat <span class="op">=</span> grid_a.ravel()</span>
<span id="cb36-13"><a href="#cb36-13" tabindex="-1"></a>grid_b_flat <span class="op">=</span> grid_b.ravel()</span>
<span id="cb36-14"><a href="#cb36-14" tabindex="-1"></a></span>
<span id="cb36-15"><a href="#cb36-15" tabindex="-1"></a>X_statespace <span class="op">=</span> c_[grid_a_flat, grid_b_flat]</span></code></pre>
</div>
<p>We can now obtain the categorical and probability predictions from
the trained classifier for all points of the grid.</p>
<div class="codewrapper sourceCode" id="cb37">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" tabindex="-1"></a>predict <span class="op">=</span> clf.predict(X_statespace)</span>
<span id="cb37-2"><a href="#cb37-2" tabindex="-1"></a>probabs <span class="op">=</span> clf.predict_proba(X_statespace)</span></code></pre>
</div>
<p>Here is the plot of the state space and the predicted
probabilities:</p>
<div class="codewrapper sourceCode" id="cb38">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" tabindex="-1"></a>feature_1, feature_2 <span class="op">=</span> <span class="dv">0</span>, <span class="dv">1</span></span>
<span id="cb38-2"><a href="#cb38-2" tabindex="-1"></a></span>
<span id="cb38-3"><a href="#cb38-3" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots(ncols<span class="op">=</span><span class="dv">3</span>, nrows<span class="op">=</span><span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb38-4"><a href="#cb38-4" tabindex="-1"></a></span>
<span id="cb38-5"><a href="#cb38-5" tabindex="-1"></a>ax[<span class="dv">0</span>].scatter(X[:, feature_1], X[:, feature_2], c<span class="op">=</span>y, s<span class="op">=</span><span class="dv">40</span>, cmap<span class="op">=</span><span class="st">'bwr'</span>)<span class="op">;</span></span>
<span id="cb38-6"><a href="#cb38-6" tabindex="-1"></a>ax[<span class="dv">0</span>].set_xlim(X1_min, X1_max)<span class="op">;</span></span>
<span id="cb38-7"><a href="#cb38-7" tabindex="-1"></a>ax[<span class="dv">0</span>].set_ylim(X2_min, X2_max)<span class="op">;</span></span>
<span id="cb38-8"><a href="#cb38-8" tabindex="-1"></a>ax[<span class="dv">0</span>].set_xlabel(<span class="st">'Feature 1'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)<span class="op">;</span></span>
<span id="cb38-9"><a href="#cb38-9" tabindex="-1"></a>ax[<span class="dv">0</span>].set_ylabel(<span class="st">'Feature 2'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)<span class="op">;</span></span>
<span id="cb38-10"><a href="#cb38-10" tabindex="-1"></a></span>
<span id="cb38-11"><a href="#cb38-11" tabindex="-1"></a>cax1 <span class="op">=</span> ax[<span class="dv">1</span>].scatter(X_statespace[:, feature_1], X_statespace[:, feature_2], c<span class="op">=</span>predict, s<span class="op">=</span><span class="dv">1</span>, cmap<span class="op">=</span><span class="st">'bwr'</span>)<span class="op">;</span></span>
<span id="cb38-12"><a href="#cb38-12" tabindex="-1"></a>ax[<span class="dv">1</span>].scatter(X_test[:, feature_1], X_test[:, feature_2], c<span class="op">=</span>predict_test, s<span class="op">=</span><span class="dv">40</span>, cmap<span class="op">=</span><span class="st">'Greys'</span>)<span class="op">;</span></span>
<span id="cb38-13"><a href="#cb38-13" tabindex="-1"></a>ax[<span class="dv">1</span>].set_xlabel(<span class="st">'Feature 1'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)<span class="op">;</span></span>
<span id="cb38-14"><a href="#cb38-14" tabindex="-1"></a>ax[<span class="dv">1</span>].set_xlim(X1_min, X1_max)<span class="op">;</span></span>
<span id="cb38-15"><a href="#cb38-15" tabindex="-1"></a>ax[<span class="dv">1</span>].set_ylim(X2_min, X2_max)<span class="op">;</span></span>
<span id="cb38-16"><a href="#cb38-16" tabindex="-1"></a>fig.colorbar(cax1, ax<span class="op">=</span>ax[<span class="dv">1</span>])<span class="op">;</span></span>
<span id="cb38-17"><a href="#cb38-17" tabindex="-1"></a></span>
<span id="cb38-18"><a href="#cb38-18" tabindex="-1"></a>grid_shape <span class="op">=</span> grid_a.shape</span>
<span id="cb38-19"><a href="#cb38-19" tabindex="-1"></a></span>
<span id="cb38-20"><a href="#cb38-20" tabindex="-1"></a>probab_grid <span class="op">=</span> probabs[:, <span class="dv">1</span>].reshape(grid_shape)</span>
<span id="cb38-21"><a href="#cb38-21" tabindex="-1"></a></span>
<span id="cb38-22"><a href="#cb38-22" tabindex="-1"></a><span class="co"># Subject with 170cm and 70 kg</span></span>
<span id="cb38-23"><a href="#cb38-23" tabindex="-1"></a>pos1, pos2 <span class="op">=</span> <span class="dv">170</span>, <span class="dv">70</span></span>
<span id="cb38-24"><a href="#cb38-24" tabindex="-1"></a></span>
<span id="cb38-25"><a href="#cb38-25" tabindex="-1"></a>test_sample <span class="op">=</span> [pos1, pos2]</span>
<span id="cb38-26"><a href="#cb38-26" tabindex="-1"></a></span>
<span id="cb38-27"><a href="#cb38-27" tabindex="-1"></a>contour_levels <span class="op">=</span> linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">10</span>)</span>
<span id="cb38-28"><a href="#cb38-28" tabindex="-1"></a></span>
<span id="cb38-29"><a href="#cb38-29" tabindex="-1"></a>cax2 <span class="op">=</span> ax[<span class="dv">2</span>].contourf(grid_a, grid_b, probab_grid, cmap<span class="op">=</span><span class="st">'Greys'</span>, levels<span class="op">=</span>contour_levels)<span class="op">;</span></span>
<span id="cb38-30"><a href="#cb38-30" tabindex="-1"></a>fig.colorbar(cax2, ax<span class="op">=</span>ax[<span class="dv">2</span>])<span class="op">;</span></span>
<span id="cb38-31"><a href="#cb38-31" tabindex="-1"></a></span>
<span id="cb38-32"><a href="#cb38-32" tabindex="-1"></a>ax[<span class="dv">2</span>].scatter(test_sample[<span class="dv">0</span>], test_sample[<span class="dv">1</span>], c<span class="op">=</span><span class="st">'r'</span>, marker<span class="op">=</span><span class="st">'o'</span>, s<span class="op">=</span><span class="dv">100</span>)<span class="op">;</span></span>
<span id="cb38-33"><a href="#cb38-33" tabindex="-1"></a>ax[<span class="dv">2</span>].set_xlabel(<span class="st">'Feature 1'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)<span class="op">;</span></span>
<span id="cb38-34"><a href="#cb38-34" tabindex="-1"></a>ax[<span class="dv">2</span>].set_xlim(X1_min, X1_max)<span class="op">;</span></span>
<span id="cb38-35"><a href="#cb38-35" tabindex="-1"></a>ax[<span class="dv">2</span>].set_ylim(X2_min, X2_max)<span class="op">;</span></span>
<span id="cb38-36"><a href="#cb38-36" tabindex="-1"></a></span>
<span id="cb38-37"><a href="#cb38-37" tabindex="-1"></a>show()</span></code></pre>
</div>
<figure><img src="fig/01-classification_intro-rendered-unnamed-chunk-30-13.png" width="1440" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p style="text-align: justify;">
The left panel shows the original data with labels as colours, i.e. the
training data. Central panel shows the classified state space with the
test samples as black dots in predicted category ‘Female’ and white dots
in predicted category ‘Male’. Right panel shows the state space with
prediction probabilities with black for ‘Female’ and white for ‘Male’.
The red dot represents the simulated subject with 170cm and 70 kg (see
below).
</p>
</div>
<div class="section level3">
<h3 id="probability-of-a-single-observation">
<strong>Probability of a single observation</strong><a class="anchor" aria-label="anchor" href="#probability-of-a-single-observation"></a>
</h3>
<p style="text-align: justify;">
Let us pick that subject and obtain its predicted label and probability.
Note the use of double brackets to create a sample that is a
two-dimensional array.
</p>
<div class="codewrapper sourceCode" id="cb39">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" tabindex="-1"></a>test_sample <span class="op">=</span> [[pos1, pos2]]</span>
<span id="cb39-2"><a href="#cb39-2" tabindex="-1"></a></span>
<span id="cb39-3"><a href="#cb39-3" tabindex="-1"></a>test_predict <span class="op">=</span> clf.predict(test_sample)</span>
<span id="cb39-4"><a href="#cb39-4" tabindex="-1"></a>test_proba   <span class="op">=</span> clf.predict_proba(test_sample)</span>
<span id="cb39-5"><a href="#cb39-5" tabindex="-1"></a></span>
<span id="cb39-6"><a href="#cb39-6" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Predicted class:'</span>, test_predict, <span class="st">'Female'</span>)</span>
<span id="cb39-7"><a href="#cb39-7" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Probability:'</span>, test_proba[<span class="dv">0</span>, <span class="dv">0</span>])</span>
<span id="cb39-8"><a href="#cb39-8" tabindex="-1"></a><span class="bu">print</span>(<span class="st">''</span>)</span>
<span id="cb39-9"><a href="#cb39-9" tabindex="-1"></a></span>
<span id="cb39-10"><a href="#cb39-10" tabindex="-1"></a>bins <span class="op">=</span> arange(test_proba.shape[<span class="dv">1</span>])</span>
<span id="cb39-11"><a href="#cb39-11" tabindex="-1"></a></span>
<span id="cb39-12"><a href="#cb39-12" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots()</span>
<span id="cb39-13"><a href="#cb39-13" tabindex="-1"></a></span>
<span id="cb39-14"><a href="#cb39-14" tabindex="-1"></a>ax.bar(bins, test_proba[<span class="dv">0</span>,:], color<span class="op">=</span>(<span class="st">'r'</span>, <span class="st">'b'</span>))<span class="op">;</span></span>
<span id="cb39-15"><a href="#cb39-15" tabindex="-1"></a>xticks(bins, (<span class="st">'Female'</span>, <span class="st">'Male'</span>), fontsize<span class="op">=</span><span class="dv">16</span>)<span class="op">;</span></span>
<span id="cb39-16"><a href="#cb39-16" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Probability'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)<span class="op">;</span></span>
<span id="cb39-17"><a href="#cb39-17" tabindex="-1"></a></span>
<span id="cb39-18"><a href="#cb39-18" tabindex="-1"></a>show()</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Predicted class: [False] Female
Probability: 0.66</code></pre>
</div>
<figure><img src="fig/01-classification_intro-rendered-unnamed-chunk-31-15.png" width="672" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p style="text-align: justify;">
This shows that the predicted label is female but the probability is
less than 70 % and, e.g. if a clinical decision was to be taken based on
the outcome of the classification, it might suggest looking for
additional evidence before the decision is made.
</p>
</div>
<div class="section level3">
<h3 id="feature-importances-1">
<strong>Feature Importances</strong><a class="anchor" aria-label="anchor" href="#feature-importances-1"></a>
</h3>
<div class="codewrapper sourceCode" id="cb41">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" tabindex="-1"></a>importances <span class="op">=</span> clf.feature_importances_</span>
<span id="cb41-2"><a href="#cb41-2" tabindex="-1"></a></span>
<span id="cb41-3"><a href="#cb41-3" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Features importances:'</span>)</span>
<span id="cb41-4"><a href="#cb41-4" tabindex="-1"></a>template <span class="op">=</span> <span class="st">'Feature 1: </span><span class="sc">{:.1f}</span><span class="st">%; Feature 2: </span><span class="sc">{:.1f}</span><span class="st">%'</span></span>
<span id="cb41-5"><a href="#cb41-5" tabindex="-1"></a><span class="bu">print</span>(template.<span class="bu">format</span>(importances[<span class="dv">0</span>]<span class="op">*</span><span class="dv">100</span>, importances[<span class="dv">1</span>]<span class="op">*</span><span class="dv">100</span>))</span>
<span id="cb41-6"><a href="#cb41-6" tabindex="-1"></a><span class="bu">print</span>(<span class="st">''</span>)</span>
<span id="cb41-7"><a href="#cb41-7" tabindex="-1"></a></span>
<span id="cb41-8"><a href="#cb41-8" tabindex="-1"></a>bins <span class="op">=</span> arange(importances.shape[<span class="dv">0</span>])</span>
<span id="cb41-9"><a href="#cb41-9" tabindex="-1"></a></span>
<span id="cb41-10"><a href="#cb41-10" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots()</span>
<span id="cb41-11"><a href="#cb41-11" tabindex="-1"></a></span>
<span id="cb41-12"><a href="#cb41-12" tabindex="-1"></a>ax.bar(bins, importances, color<span class="op">=</span>(<span class="st">'m'</span>, <span class="st">'g'</span>))<span class="op">;</span></span>
<span id="cb41-13"><a href="#cb41-13" tabindex="-1"></a>xticks(bins, (<span class="st">'Feature 1'</span>, <span class="st">'Feature 2'</span>), fontsize<span class="op">=</span><span class="dv">16</span>)<span class="op">;</span></span>
<span id="cb41-14"><a href="#cb41-14" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Feature Importance'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)<span class="op">;</span></span>
<span id="cb41-15"><a href="#cb41-15" tabindex="-1"></a></span>
<span id="cb41-16"><a href="#cb41-16" tabindex="-1"></a>show()</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Features importances:
Feature 1: 31.7%; Feature 2: 68.3%</code></pre>
</div>
<figure><img src="fig/01-classification_intro-rendered-unnamed-chunk-32-17.png" width="672" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure>
Feature Height contributes about one third and feature Weight about two
thirds to the decisions.
<p style="text-align: justify;">
Feature importances can be used in data sets with many features, e.g. to
reduce the number of features used for classification. Some features
might not contribute to the classification and could therefore be left
out of the process.
</p>
<p>In the next lesson, we are going to test multiple classifiers and
quantify their performance to improve the outcome of the
classification.</p>
<p><br></p>
</div>
</section><section><h2 class="section-heading" id="exercises">Exercises<a class="anchor" aria-label="anchor" href="#exercises"></a>
</h2>
<hr class="half-width">
<div id="end-of-chapter-exercises" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="end-of-chapter-exercises" class="callout-inner">
<h3 class="callout-title">End of chapter Exercises</h3>
<div class="callout-content">
<p style="text-align: justify;">
</p>
<p>Repeat the training and prediction workflow as described in the
Classification lesson for two other independant features in the data,
namely: - Peak Flow - Pulse Pressure <em>(Hint: use a column operation
to add an additional ‘PP’ column to the data given the equation
below).</em></p>
<p><br>
Pulse Pressure (PP) is a metric that represents the force the heart
generates each time it contracts, and can be used to give clinical
indicators of arterial stiffness or cardiovascular disease.<br><br>
The equation for pulse pressure is:</p>
<p><span class="math display">\[
PP = \text{Systolic BP} - \text{Diastolic BP}
\]</span></p>
<p><br>
Use 70 training and 30 testing samples where the labels are assigned
according to the condition:</p>
<ul>
<li>0 / False for ‘non-smoker’</li>
<li>1 / True for ‘smoker’</li>
</ul>
<p>Use the above code to:</p>
<ol style="list-style-type: decimal">
<li><p>Train the random forest classifier.</p></li>
<li><p>Create state space scatter plots, making use of categorical
colouring. Include a probability contour plot.</p></li>
<li>
<p>Create a plot of the probability of the predicted label given a
chosen pair of observations (features):</p>
<ul>
<li>Choose a pair of observations that are at the classifcation
boundary. <em>(Use the probability contour plot as a guide)</em>
</li>
<li>Print and plot the model probabilities for both labels</li>
<li>Observe and comment on how well the model is able to predict
observations that are on or near to the boundary <em>(Hint: Play around
with multiple observations to get a feel for this)</em>
</li>
</ul>
</li>
<li>
<p>Create multiple scatter plots with predicted labels, true labels
and use a Boolean array that compares predicted and true labels.</p>
<ul>
<li>How many of the 30 test data points are correctly predicted?</li>
<li>Which observations are incorrectly predicted, and why?</li>
</ul>
</li>
<li><p>Plot feature importance to understand how much each feature
contributes to the predictions.</p></li>
</ol>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1">
  Solutions are provided after assignments are marked.
  </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">

</div>
</div>
</div>
</div>
<div id="further-practice-iris-data" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="further-practice-iris-data" class="callout-inner">
<h3 class="callout-title">Further Practice: Iris data</h3>
<div class="callout-content">
<p>You can try to use the Random Forest classifier on the <a href="https://en.wikipedia.org/wiki/Iris_flower_data_set" class="external-link">Iris
data</a>:</p>
<p>The Iris data are a collection of five features (sepal length, sepal
width, petal length, petal width and species) from 3 species of Iris
(Iris setosa, Iris virginica and Iris versicolor). The species name is
used for training in classification.</p>
<p>Import the data from <a href="https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html" class="external-link">scikit-learn</a>
as:</p>
<div class="codewrapper sourceCode" id="cb43">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> datasets</span>
<span id="cb43-2"><a href="#cb43-2" tabindex="-1"></a></span>
<span id="cb43-3"><a href="#cb43-3" tabindex="-1"></a><span class="co"># Import Iris data</span></span>
<span id="cb43-4"><a href="#cb43-4" tabindex="-1"></a>iris <span class="op">=</span> datasets.load_iris()</span>
<span id="cb43-5"><a href="#cb43-5" tabindex="-1"></a></span>
<span id="cb43-6"><a href="#cb43-6" tabindex="-1"></a><span class="co"># Get first two features and labels</span></span>
<span id="cb43-7"><a href="#cb43-7" tabindex="-1"></a>X <span class="op">=</span> iris.data[:, :<span class="dv">2</span>]</span>
<span id="cb43-8"><a href="#cb43-8" tabindex="-1"></a>y <span class="op">=</span> iris.target</span>
<span id="cb43-9"><a href="#cb43-9" tabindex="-1"></a></span>
<span id="cb43-10"><a href="#cb43-10" tabindex="-1"></a><span class="bu">print</span>(X.shape, y.shape)</span></code></pre>
</div>
<p>(150, 2) (150,)</p>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>Classification is to assign labels to unlabeled data.</li>
<li>
<code>SciKit Learn</code> is an open source application programming
interface (API) for machine learning.</li>
<li>
<code>.fit()</code> function is used to receive the training data
and perform the training of the model.</li>
<li>
<code>.predict()</code> function helps to find out what the model
claims these data to be.</li>
<li>
<code>.predict_proba()</code> function predicts the probability of
any predictions.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section><section id="aio-02-improvement"><p>Content from <a href="02-improvement.html">Improvement</a></p>
<hr>
<p>Last updated on 2025-03-31 |

        <a href="https://github.com/carpentries/workbench-template-md/edit/main/episodes/02-improvement.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<p><a href="https://drive.usercontent.google.com/u/1/uc?id=1Gib2BeOLzIb6dgVMQQuPqw8nLA8Ti0SX&amp;export=download" class="external-link"><strong>Download
Chapter notebook (ipynb)</strong></a></p>
<p><a href="https://drive.usercontent.google.com/u/1/uc?id=16tDnxEFO77t0UusDStdhXdnm9duuMCOP&amp;export=download" class="external-link"><strong>Download
Chapter PDF</strong></a></p>
<p><a href="https://docs.google.com/forms/d/e/1FAIpQLSdr0capF7jloJhPH3Pki1B3LZoKOG16poOpuVJ7SL2LkwLHQA/viewform?pli=1" class="external-link"><span style="color: rgb(255, 0, 0);"><strong>Mandatory Lesson Feedback
Survey</strong></span></a></p>
<div id="discussion1" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Discussion</h3>
<div class="callout-content">
<ul>
<li>How to deal with complex classification problems?</li>
<li>Why is it important to use different classification algorithms?</li>
<li>What is the best way to find the optimal classifier?</li>
<li>How can we avoid over-fitting of data?</li>
<li>How do we evaluate the performance of classifiers?</li>
</ul>
</div>
</div>
</div>
<p align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/LH3cUN7WXlg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
</p>
<br><p align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/GvUvwHmTXUs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
</p>
<br><p align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/xjpQRhtY1l0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
</p>
<br><p align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/nEyt1Ht8GOk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
</p>
<p><br></p>
<div id="remarks" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="remarks" class="callout-inner">
<h3 class="callout-title">Remarks</h3>
<div class="callout-content">
<ol style="list-style-type: decimal">
<li><p>From now on the code will become more complex. When copied, the
code should run without errors with the given data sets. (Please report
any errors thrown when running the code without modifications).</p></li>
<li><p>Make a copy of the notebook and start experimenting by modifying
part of the code and comparing the outcome. Modifying existing code is
one of the successful strategies when learning to programme as a
non-programmer.</p></li>
<li><p>The first resource to consult when facing bugs are the official
documentations, be it Python, Numpy, SciKit Learn or other.</p></li>
<li><p>If you formulate a problem adequately, often there may be good
answers on <a href="https://stackoverflow.com" class="external-link">Stack
Overflow</a>.</p></li>
<li><p>Sometimes, simply copying and pasting an error message into the
search engine can point you to the solution.</p></li>
</ol>
</div>
</div>
</div>
<div class="section level3">
<h3 id="import-functions">
<strong>Import functions</strong><a class="anchor" aria-label="anchor" href="#import-functions"></a>
</h3>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> mgrid, linspace, c_, arange, mean, array</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">from</span> numpy.random <span class="im">import</span> uniform, seed</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="im">from</span> mpl_toolkits <span class="im">import</span> mplot3d</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="im">from</span> matplotlib.pyplot <span class="im">import</span> subplots, axes, scatter, xticks, show</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_circles</span></code></pre>
</div>
<div id="challenge" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="challenge" class="callout-inner">
<h3 class="callout-title">Challenge</h3>
<div class="callout-content">
<p style="text-align: justify;">
We would like to test several machine learning models’ ability to deal
with a complicated task. A complicated task is one where the topology of
the labelled data is not trivially separable into classes by
(hyper)planes, e.g. by a straight line in a scatter plot.
</p>
<p>Our example is one class of data organised in a doughnut shape and
the other class contained within the first doughnut forming a
doughnut-within-a-doughnut.</p>
<p>Here is the function code to create these data, followed by a
function call to produce a figure.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="kw">def</span> make_torus_3D(n_samples<span class="op">=</span><span class="dv">100</span>, shuffle<span class="op">=</span><span class="va">True</span>, noise<span class="op">=</span><span class="va">None</span>, random_state<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>                 factor<span class="op">=</span><span class="fl">.8</span>):</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>    <span class="co">"""Make a large torus containing a smaller torus in 3-D.</span></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a><span class="co">    A toy dataset to visualise clustering and classification</span></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a><span class="co">    algorithms.</span></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a><span class="co">    Read more in the User Guide.</span></span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a><span class="co">    n_samples : int, optional (default=100)</span></span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a><span class="co">        The total number of points generated. If odd, the inner circle will</span></span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a><span class="co">        have one point more than the outer circle.</span></span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a></span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a><span class="co">    shuffle : bool, optional (default=True)</span></span>
<span id="cb2-17"><a href="#cb2-17" tabindex="-1"></a><span class="co">        Whether to shuffle the samples.</span></span>
<span id="cb2-18"><a href="#cb2-18" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" tabindex="-1"></a><span class="co">    noise : double or None (default=None)</span></span>
<span id="cb2-20"><a href="#cb2-20" tabindex="-1"></a><span class="co">        Standard deviation of Gaussian noise added to the data.</span></span>
<span id="cb2-21"><a href="#cb2-21" tabindex="-1"></a></span>
<span id="cb2-22"><a href="#cb2-22" tabindex="-1"></a><span class="co">    random_state : int, RandomState instance or None (default)</span></span>
<span id="cb2-23"><a href="#cb2-23" tabindex="-1"></a><span class="co">        Determines random number generation for dataset shuffling and noise.</span></span>
<span id="cb2-24"><a href="#cb2-24" tabindex="-1"></a><span class="co">        Pass an int for reproducible output across multiple function calls.</span></span>
<span id="cb2-25"><a href="#cb2-25" tabindex="-1"></a><span class="co">        See :term:`Glossary &lt;random_state&gt;`.</span></span>
<span id="cb2-26"><a href="#cb2-26" tabindex="-1"></a></span>
<span id="cb2-27"><a href="#cb2-27" tabindex="-1"></a><span class="co">    factor : 0 &lt; double &lt; 1 (default=.8)</span></span>
<span id="cb2-28"><a href="#cb2-28" tabindex="-1"></a><span class="co">        Scale factor between inner and outer circle.</span></span>
<span id="cb2-29"><a href="#cb2-29" tabindex="-1"></a></span>
<span id="cb2-30"><a href="#cb2-30" tabindex="-1"></a><span class="co">    Returns</span></span>
<span id="cb2-31"><a href="#cb2-31" tabindex="-1"></a><span class="co">    -------</span></span>
<span id="cb2-32"><a href="#cb2-32" tabindex="-1"></a><span class="co">    X : array of shape [n_samples, 2]</span></span>
<span id="cb2-33"><a href="#cb2-33" tabindex="-1"></a><span class="co">        The generated samples.</span></span>
<span id="cb2-34"><a href="#cb2-34" tabindex="-1"></a></span>
<span id="cb2-35"><a href="#cb2-35" tabindex="-1"></a><span class="co">    y : array of shape [n_samples]</span></span>
<span id="cb2-36"><a href="#cb2-36" tabindex="-1"></a><span class="co">        The integer labels (0 or 1) for class membership of each sample.</span></span>
<span id="cb2-37"><a href="#cb2-37" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb2-38"><a href="#cb2-38" tabindex="-1"></a>    <span class="im">from</span> numpy <span class="im">import</span> pi, linspace, cos, sin, append, ones, zeros, hstack, vstack, intp</span>
<span id="cb2-39"><a href="#cb2-39" tabindex="-1"></a>    <span class="im">from</span> sklearn.utils <span class="im">import</span> check_random_state, shuffle</span>
<span id="cb2-40"><a href="#cb2-40" tabindex="-1"></a></span>
<span id="cb2-41"><a href="#cb2-41" tabindex="-1"></a>    <span class="cf">if</span> factor <span class="op">&gt;=</span> <span class="dv">1</span> <span class="kw">or</span> factor <span class="op">&lt;</span> <span class="dv">0</span>:</span>
<span id="cb2-42"><a href="#cb2-42" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"'factor' has to be between 0 and 1."</span>)</span>
<span id="cb2-43"><a href="#cb2-43" tabindex="-1"></a>    </span>
<span id="cb2-44"><a href="#cb2-44" tabindex="-1"></a>    <span class="co"># Determine the number of samples for each torus.</span></span>
<span id="cb2-45"><a href="#cb2-45" tabindex="-1"></a>    n_samples_out <span class="op">=</span> n_samples <span class="op">//</span> <span class="dv">2</span></span>
<span id="cb2-46"><a href="#cb2-46" tabindex="-1"></a>    n_samples_in <span class="op">=</span> n_samples <span class="op">-</span> n_samples_out</span>
<span id="cb2-47"><a href="#cb2-47" tabindex="-1"></a>    </span>
<span id="cb2-48"><a href="#cb2-48" tabindex="-1"></a>    <span class="co"># Define the radii and thickness of the outer and inner tori.</span></span>
<span id="cb2-49"><a href="#cb2-49" tabindex="-1"></a>    co, ao, ci, ai <span class="op">=</span> <span class="dv">3</span>, <span class="dv">1</span>, <span class="fl">3.6</span>, <span class="fl">0.2</span></span>
<span id="cb2-50"><a href="#cb2-50" tabindex="-1"></a>    </span>
<span id="cb2-51"><a href="#cb2-51" tabindex="-1"></a>    <span class="co"># Initialize the random number generator.</span></span>
<span id="cb2-52"><a href="#cb2-52" tabindex="-1"></a>    generator <span class="op">=</span> check_random_state(random_state)</span>
<span id="cb2-53"><a href="#cb2-53" tabindex="-1"></a>    </span>
<span id="cb2-54"><a href="#cb2-54" tabindex="-1"></a>    <span class="co"># to not have the first point = last point, we set endpoint=False.</span></span>
<span id="cb2-55"><a href="#cb2-55" tabindex="-1"></a>    linspace_out <span class="op">=</span> linspace(<span class="dv">0</span>, <span class="dv">2</span> <span class="op">*</span> pi, n_samples_out, endpoint<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb2-56"><a href="#cb2-56" tabindex="-1"></a>    linspace_in  <span class="op">=</span> linspace(<span class="dv">0</span>, <span class="dv">2</span> <span class="op">*</span> pi, n_samples_in,  endpoint<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb2-57"><a href="#cb2-57" tabindex="-1"></a>    </span>
<span id="cb2-58"><a href="#cb2-58" tabindex="-1"></a>    <span class="co"># Compute 3D coordinates for the outer torus.</span></span>
<span id="cb2-59"><a href="#cb2-59" tabindex="-1"></a>    outer_circ_x <span class="op">=</span> (co<span class="op">+</span>ao<span class="op">*</span>cos(linspace_out)) <span class="op">*</span> cos(linspace_out<span class="op">*</span><span class="fl">61.1</span>)</span>
<span id="cb2-60"><a href="#cb2-60" tabindex="-1"></a>    outer_circ_y <span class="op">=</span> (co<span class="op">+</span>ao<span class="op">*</span>cos(linspace_out)) <span class="op">*</span> sin(linspace_out<span class="op">*</span><span class="fl">61.1</span>)</span>
<span id="cb2-61"><a href="#cb2-61" tabindex="-1"></a>    outer_circ_z <span class="op">=</span>    ao<span class="op">*</span>sin(linspace_out)</span>
<span id="cb2-62"><a href="#cb2-62" tabindex="-1"></a>    </span>
<span id="cb2-63"><a href="#cb2-63" tabindex="-1"></a>    <span class="co"># Compute 3D coordinates for the inner torus (scaled by `factor`).</span></span>
<span id="cb2-64"><a href="#cb2-64" tabindex="-1"></a>    inner_circ_x <span class="op">=</span> (ci<span class="op">+</span>ai<span class="op">*</span>cos(linspace_in)) <span class="op">*</span> cos(linspace_in<span class="op">*</span><span class="fl">61.1</span>)<span class="op">*</span> factor</span>
<span id="cb2-65"><a href="#cb2-65" tabindex="-1"></a>    inner_circ_y <span class="op">=</span> (ci<span class="op">+</span>ai<span class="op">*</span>cos(linspace_in)) <span class="op">*</span> sin(linspace_in<span class="op">*</span><span class="fl">61.1</span>) <span class="op">*</span> factor</span>
<span id="cb2-66"><a href="#cb2-66" tabindex="-1"></a>    inner_circ_z <span class="op">=</span>    ai<span class="op">*</span>sin(linspace_in) <span class="op">*</span> factor</span>
<span id="cb2-67"><a href="#cb2-67" tabindex="-1"></a></span>
<span id="cb2-68"><a href="#cb2-68" tabindex="-1"></a>    <span class="co"># Stack the coordinates into a single array (X: [n_samples, 3]).</span></span>
<span id="cb2-69"><a href="#cb2-69" tabindex="-1"></a>    X <span class="op">=</span> vstack([append(outer_circ_x, inner_circ_x),</span>
<span id="cb2-70"><a href="#cb2-70" tabindex="-1"></a>                append(outer_circ_y, inner_circ_y),</span>
<span id="cb2-71"><a href="#cb2-71" tabindex="-1"></a>                append(outer_circ_z, inner_circ_z)]).T</span>
<span id="cb2-72"><a href="#cb2-72" tabindex="-1"></a></span>
<span id="cb2-73"><a href="#cb2-73" tabindex="-1"></a>    <span class="co"># Generate class labels: 0 for outer torus, 1 for inner torus.</span></span>
<span id="cb2-74"><a href="#cb2-74" tabindex="-1"></a>    y <span class="op">=</span> hstack([zeros(n_samples_out, dtype<span class="op">=</span>intp),</span>
<span id="cb2-75"><a href="#cb2-75" tabindex="-1"></a>                   ones(n_samples_in, dtype<span class="op">=</span>intp)])</span>
<span id="cb2-76"><a href="#cb2-76" tabindex="-1"></a></span>
<span id="cb2-77"><a href="#cb2-77" tabindex="-1"></a>    <span class="co"># If specified, shuffle the dataset.</span></span>
<span id="cb2-78"><a href="#cb2-78" tabindex="-1"></a>    <span class="cf">if</span> shuffle:</span>
<span id="cb2-79"><a href="#cb2-79" tabindex="-1"></a>        X, y <span class="op">=</span> shuffle(X, y, random_state<span class="op">=</span>generator)</span>
<span id="cb2-80"><a href="#cb2-80" tabindex="-1"></a></span>
<span id="cb2-81"><a href="#cb2-81" tabindex="-1"></a>    <span class="co"># Add Gaussian noise if specified.</span></span>
<span id="cb2-82"><a href="#cb2-82" tabindex="-1"></a>    <span class="cf">if</span> noise <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb2-83"><a href="#cb2-83" tabindex="-1"></a>        X <span class="op">+=</span> generator.normal(scale<span class="op">=</span>noise, size<span class="op">=</span>X.shape)</span>
<span id="cb2-84"><a href="#cb2-84" tabindex="-1"></a></span>
<span id="cb2-85"><a href="#cb2-85" tabindex="-1"></a>    <span class="cf">return</span> X, y</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="co"># Set a fixed random seed for reproducibility</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>RANDOM_STATE  <span class="op">=</span> <span class="dv">12345</span></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>seed(RANDOM_STATE)</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a><span class="co"># Generate a 3D torus dataset with 2000 samples</span></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>X, y <span class="op">=</span> make_torus_3D(n_samples<span class="op">=</span><span class="dv">2000</span>, factor<span class="op">=</span><span class="fl">.9</span>, noise<span class="op">=</span><span class="fl">.001</span>, random_state<span class="op">=</span>RANDOM_STATE)</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a><span class="co"># Select feature indices for 3D visualization</span></span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a>feature_1, feature_2, feature_3 <span class="op">=</span> <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span></span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a><span class="co"># Get the minimum and maximum values of X for scaling (not used later)</span></span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a>ft_min, ft_max <span class="op">=</span> X.<span class="bu">min</span>(), X.<span class="bu">max</span>()</span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a><span class="co"># Create a new figure and axis for 3D plotting</span></span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">9</span>))</span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a><span class="co"># Set up 3D axes for visualization</span></span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a>ax <span class="op">=</span> axes(projection<span class="op">=</span><span class="st">"3d"</span>)</span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a></span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a><span class="co"># Create a 3D scatter plot</span></span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a>im <span class="op">=</span> ax.scatter3D(X[:, feature_1], X[:, feature_2], X[:, feature_3], marker<span class="op">=</span><span class="st">'o'</span>, s<span class="op">=</span><span class="dv">20</span>, c<span class="op">=</span>y, cmap<span class="op">=</span><span class="st">'bwr'</span>)<span class="op">;</span></span>
<span id="cb3-22"><a href="#cb3-22" tabindex="-1"></a></span>
<span id="cb3-23"><a href="#cb3-23" tabindex="-1"></a><span class="co"># Set axis labels</span></span>
<span id="cb3-24"><a href="#cb3-24" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Feature 1'</span>)</span>
<span id="cb3-25"><a href="#cb3-25" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Feature 2'</span>)</span>
<span id="cb3-26"><a href="#cb3-26" tabindex="-1"></a>ax.set_zlabel(<span class="st">'Feature 3'</span>)</span>
<span id="cb3-27"><a href="#cb3-27" tabindex="-1"></a></span>
<span id="cb3-28"><a href="#cb3-28" tabindex="-1"></a><span class="co"># Angles to pick the perspective</span></span>
<span id="cb3-29"><a href="#cb3-29" tabindex="-1"></a>ax.view_init(<span class="dv">30</span>, <span class="dv">50</span>)<span class="op">;</span></span>
<span id="cb3-30"><a href="#cb3-30" tabindex="-1"></a></span>
<span id="cb3-31"><a href="#cb3-31" tabindex="-1"></a>show()</span></code></pre>
</div>
<figure><img src="fig/02-improvement-rendered-unnamed-chunk-3-1.png" width="1152" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p style="text-align: justify;">
The challenge here is that the only way to separate the data of the two
labels from each other is to find a separating border that lies between
the blue and the red doughnut (mathematically: torus) and itself is a
torus, i.e. a complex topology. Similarly, one can test to separate one
class of data that lie on the surface of a sphere and then have data on
another sphere embedded within it. Typically, it is unknown what type of
high-dimensional topologies is present in biological data. As such it is
not clear at the outset which classification strategy will work best.
Let us start with a simpler example.
</p>
</div>
</div>
</div>
</div>
<section><h2 class="section-heading" id="training-a-variety-of-machine-learning-models">Training a variety of machine learning models<a class="anchor" aria-label="anchor" href="#training-a-variety-of-machine-learning-models"></a>
</h2>
<hr class="half-width">
<p><code>scikit-learn</code> provides the means to generate practice
datasets with specific qualities. In this section, we will use the
<code>make_circles</code> function - a function that generates a toy
dataset which consists of two concentric circles (see the function’s <a href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_circles.html" class="external-link">documentation.</a>)
for more information:</p>
<div class="section level3">
<h3 id="circular-test-data">
<strong>Circular Test Data</strong><a class="anchor" aria-label="anchor" href="#circular-test-data"></a>
</h3>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co"># Set random seed for reproducibility.</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>RANDOM_STATE  <span class="op">=</span> <span class="dv">1234</span></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>seed(RANDOM_STATE)</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a><span class="co"># Generates synthetic circular data: 'n_samples' sets the total number of datapoints to 500.</span></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a><span class="co"># 'factor' controls the inner circle to be 30% of the radius of the outer circle.</span></span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a><span class="co"># 'noise' adds a very small amount of Gaussian noise.</span></span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>X, y <span class="op">=</span> make_circles(n_samples<span class="op">=</span><span class="dv">500</span>, factor<span class="op">=</span><span class="fl">0.3</span>, noise<span class="op">=</span><span class="fl">.05</span>, random_state<span class="op">=</span>RANDOM_STATE)</span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a><span class="co"># This obtains the overall maximum and minimum feature values:</span></span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a>feature_1, feature_2 <span class="op">=</span> <span class="dv">0</span>, <span class="dv">1</span></span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a>ft_min, ft_max <span class="op">=</span> X.<span class="bu">min</span>(), X.<span class="bu">max</span>()</span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Shape of X:'</span>, X.shape)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Shape of X: (500, 2)</code></pre>
</div>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="co"># Plotting:</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>), nrows<span class="op">=</span><span class="dv">1</span>, ncols<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>ax[<span class="dv">0</span>].scatter(X[:, feature_1], X[:, feature_2], c<span class="op">=</span>y, s<span class="op">=</span><span class="dv">4</span>, cmap<span class="op">=</span><span class="st">'bwr'</span>)<span class="op">;</span></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a>ax[<span class="dv">1</span>].hist(X)<span class="op">;</span></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>show()</span></code></pre>
</div>
<figure><img src="fig/02-improvement-rendered-unnamed-chunk-4-3.png" width="960" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p style="text-align: justify;">
The function yields only two features. The reason is that with two
features we can visualise the complete state space in a two-dimensional
scatter plot. The data of both labels are organised along a ring. There
is a certain amount of randomness added to create data distributed
normally around the ring.
</p>
<p style="text-align: justify;">
The tricky thing about such a data distribution is that in a standard
view of the data, the histogram, the clear state space organisation is
not visible. There are e.g. no two distinct mean values of the
distributions. Also, while the two features are clearly dependent on
each other (as seen in the scatter plot), it is not possible to regress
one with the other by means of fits of the type y = f(x).
</p>
<p>We will now use different classes of machine learning models to fit
to these labelled data.</p>
</div>
<div class="section level3">
<h3 id="classification-algorithms">
<strong>Classification Algorithms</strong><a class="anchor" aria-label="anchor" href="#classification-algorithms"></a>
</h3>
<p>Different classification algorithms approach problems differently.
Let us name the algorithms in <code>scikit-learn</code>.</p>
<p><code>scikit-learn</code> provides the following algorithms for
classification problems. Each listed classifier is hyperlinked to its
relevant scikit-learn Documentation page.</p>
<ul>
<li>Ensemble: Averaging:
<ul>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" class="external-link">Random
Forest</a></li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html" class="external-link">Extra
Tree</a></li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html" class="external-link">Isolation
Forest</a></li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html" class="external-link">Bagging</a></li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html" class="external-link">Voting</a></li>
</ul>
</li>
<li>Boosting:
<ul>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html" class="external-link">Gradient
Boosting</a></li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html" class="external-link">AdaBoost</a></li>
</ul>
</li>
<li>Decision Trees:
<ul>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html" class="external-link">Decision
Tree</a></li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.ExtraTreeClassifier.html" class="external-link">Extra
Tree</a></li>
</ul>
</li>
<li>Nearest Neighbour:
<ul>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html" class="external-link">K
Nearest Neighbour</a></li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.RadiusNeighborsClassifier.html" class="external-link">Radius
Neighbours</a></li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestCentroid.html" class="external-link">Nearest
Centroid</a></li>
</ul>
</li>
<li>Support Vector Machine:
<ul>
<li>with non-linear kernel:
<ul>
<li><a href="https://scikit-learn.org/stable/modules/svm.html#svm-kernels" class="external-link">Radial
Basis Function (RBF)</a></li>
<li><a href="https://scikit-learn.org/stable/modules/svm.html#svm-kernels" class="external-link">Polynomial</a></li>
<li><a href="https://scikit-learn.org/stable/modules/svm.html#svm-kernels" class="external-link">Sigmoid</a></li>
</ul>
</li>
<li>with linear kernel:
<ul>
<li><a href="https://scikit-learn.org/stable/modules/svm.html#svm-kernels" class="external-link">Linear
kernel</a></li>
</ul>
</li>
<li>parametrised with non-linear kernel:
<ul>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.NuSVC.html" class="external-link">Nu-Support
Vector Classification</a></li>
</ul>
</li>
</ul>
</li>
<li>Neural Networks:
<ul>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html" class="external-link">Multi-layer
Perceptron</a></li>
<li>Gaussian:
<ul>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessClassifier.html" class="external-link">Gaussian
Process</a></li>
</ul>
</li>
<li>Linear Models:
<ul>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html" class="external-link">Logistic
Regression</a></li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.PassiveAggressiveClassifier.html" class="external-link">Passive
Aggressive</a></li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html" class="external-link">Ridge</a></li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html" class="external-link">Linear
classifiers with Stochastic Gradient Descent</a></li>
</ul>
</li>
</ul>
</li>
<li>Baysian:
<ul>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html" class="external-link">Bernoulli</a></li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html" class="external-link">Multinomial</a></li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.ComplementNB.html" class="external-link">Complement</a></li>
</ul>
</li>
</ul>
<p>Some of these algorithms require a more in-depth understanding of how
they work. To that end, we only review the performance of those that are
easier to implement and adjust.</p>
<strong>AdaBoost</strong>
<p style="text-align: justify;">
The AdaBoost algorithm is special in that it does not work on its own;
instead, it complements another ensemble algorithm (e.g. Random Forest)
and <em>boosts</em> its performance by weighing the training data
through a boosting algorithm. Note that boosting the performance does
not necessarily translate into a better fit. This is because boosting
algorithms are generally robust against over-fitting, meaning that they
always try to produce generalisable models.
</p>
<strong>Seeding</strong>
<p style="text-align: justify;">
Most machine learning algorithms rely on random number generation to
produce results. Therefore, one simple, but important adjustment is to
<code>seed</code> the number generator, and thereby making our
comparisons more consistent; i.e. ensure that all models use the same
set of random numbers. Almost all scikit-learn models take an argument
called <code>random_state</code>, which takes an integer number to seed
the random number generator.
</p>
</div>
<div class="section level3">
<h3 id="training-and-testing">
<strong>Training and Testing</strong><a class="anchor" aria-label="anchor" href="#training-and-testing"></a>
</h3>
<p>Here is code to import a number of classifiers from scikit-learn, fit
them to the training data and predict the (complete) state space. The
result is plotted below.</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC, LinearSVC</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a><span class="im">from</span> sklearn.neural_network <span class="im">import</span> MLPClassifier</span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>classifiers <span class="op">=</span> {</span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a>    <span class="st">'Random Forest'</span>: RandomForestClassifier(random_state<span class="op">=</span>RANDOM_STATE),</span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a>    <span class="st">'AdaBoost (Random Forest)'</span>: AdaBoostClassifier(RandomForestClassifier(random_state<span class="op">=</span>RANDOM_STATE)),</span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a>    <span class="st">'Extra Trees'</span>: ExtraTreesClassifier(random_state<span class="op">=</span>RANDOM_STATE),</span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a>    <span class="st">'AdaBoost (Extra Tree)'</span>: AdaBoostClassifier(ExtraTreesClassifier(random_state<span class="op">=</span>RANDOM_STATE)),</span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a>    <span class="st">'Decision Tree'</span>: DecisionTreeClassifier(random_state<span class="op">=</span>RANDOM_STATE),</span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a>    <span class="st">'SVC (RBF)'</span>: SVC(random_state<span class="op">=</span>RANDOM_STATE),</span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a>    <span class="st">'SVC (Linear)'</span>: LinearSVC(random_state<span class="op">=</span>RANDOM_STATE),</span>
<span id="cb7-15"><a href="#cb7-15" tabindex="-1"></a>    <span class="st">'Multi-layer Perceptron'</span>: MLPClassifier(max_iter<span class="op">=</span><span class="dv">5000</span>, random_state<span class="op">=</span>RANDOM_STATE)</span>
<span id="cb7-16"><a href="#cb7-16" tabindex="-1"></a>}</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a>ft_min, ft_max <span class="op">=</span> <span class="op">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a><span class="co"># Constructing (2 grids x 300 rows x 300 cols):</span></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>grid_1, grid_2 <span class="op">=</span> mgrid[ft_min:ft_max:<span class="fl">.01</span>, ft_min:ft_max:<span class="fl">.01</span>]</span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a><span class="co"># We need only the shape for one of the grids (i.e. 300 x  300):</span></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a>grid_shape <span class="op">=</span> grid_1.shape</span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a><span class="co"># state space grid for testing</span></span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a>new_obs <span class="op">=</span> c_[grid_1.ravel(), grid_2.ravel()]</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>contour_levels <span class="op">=</span> linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">6</span>)</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>fig, all_axes <span class="op">=</span> subplots(figsize<span class="op">=</span>[<span class="dv">15</span>, <span class="dv">5</span>], ncols<span class="op">=</span><span class="dv">4</span>, nrows<span class="op">=</span><span class="dv">2</span>, sharey<span class="op">=</span><span class="va">True</span>, sharex<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a><span class="cf">for</span> ax, (name, clf) <span class="kw">in</span> <span class="bu">zip</span>(all_axes.ravel(), classifiers.items()):</span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a>    clf.fit(X, y)</span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a>    y_pred <span class="op">=</span> clf.predict(new_obs)</span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a>    y_pred_grid <span class="op">=</span> y_pred.reshape(grid_shape)</span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a></span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a>    ax.scatter(X[:, feature_1], X[:, feature_2], c<span class="op">=</span>y, s<span class="op">=</span><span class="dv">1</span>, cmap<span class="op">=</span><span class="st">'bwr_r'</span>)</span>
<span id="cb9-11"><a href="#cb9-11" tabindex="-1"></a>    ax.contourf(grid_1, grid_2, y_pred_grid, cmap<span class="op">=</span><span class="st">'gray_r'</span>, alpha<span class="op">=</span><span class="fl">.2</span>, levels<span class="op">=</span>contour_levels)</span>
<span id="cb9-12"><a href="#cb9-12" tabindex="-1"></a>    ax.set_ylim(ft_min, ft_max)</span>
<span id="cb9-13"><a href="#cb9-13" tabindex="-1"></a>    ax.set_xlim(ft_min, ft_max)</span>
<span id="cb9-14"><a href="#cb9-14" tabindex="-1"></a>    ax.set_yticks([<span class="op">-</span><span class="fl">1.5</span>, <span class="dv">0</span>, <span class="fl">1.5</span>])</span>
<span id="cb9-15"><a href="#cb9-15" tabindex="-1"></a>    ax.set_xticks([<span class="op">-</span><span class="fl">1.5</span>, <span class="dv">0</span>, <span class="fl">1.5</span>])</span>
<span id="cb9-16"><a href="#cb9-16" tabindex="-1"></a>    ax.set_title(name, fontsize<span class="op">=</span><span class="dv">10</span>)<span class="op">;</span></span>
<span id="cb9-17"><a href="#cb9-17" tabindex="-1"></a></span>
<span id="cb9-18"><a href="#cb9-18" tabindex="-1"></a>show()</span></code></pre>
</div>
<figure><img src="fig/02-improvement-rendered-unnamed-chunk-7-5.png" width="1440" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p style="text-align: justify;">
Seven of the eight classifiers were able to separate the inner data set
from the outer data set successfully. The main difference is that some
algorithms ended up with a more rectangular shape of the boundary
whereas the others found a more circular form which reflects the
original data distribution more closely. One classifier simply fails:
the support vector classifier (SVC) with linear basis functions: it
tries to fit a straight line to separate the classes which in this case
is impossible.
</p>
</div>
<div class="section level3">
<h3 id="the-train-test-split">
<strong>The Train-Test Split</strong><a class="anchor" aria-label="anchor" href="#the-train-test-split"></a>
</h3>
<p style="text-align: justify;">
We will now modify our workflow to avoid the need to create separate
testing data (the typical situation when dealing with recorded data).
For this we start with a data set of n labelled samples. Of these n
samples, a certain percentage is used for training (using the provided
labels) and the rest for testing (withholding the labels). The testing
data then do not need to be prepared separately.
</p>
<p style="text-align: justify;">
The function we use is <code>train_test_split</code> from SciKit Learn.
A nice feature of this function is that it tries to preserve the ratio
of labels in the split. E.g. if the data contain 70% of
<code>True</code> and 30 % of <code>False</code> labels, the algorithm
tries to preserve this ratio in the split as good as possible: around
70% of the training data and of the testing data will have the
<code>True</code> label.
</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a>X, y <span class="op">=</span> make_circles(n_samples<span class="op">=</span><span class="dv">1000</span>, factor<span class="op">=</span><span class="fl">0.3</span>, noise<span class="op">=</span><span class="fl">.05</span>, random_state<span class="op">=</span>RANDOM_STATE)</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">.3</span>, random_state<span class="op">=</span>RANDOM_STATE, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a><span class="bu">print</span>(X_train.shape, X_test.shape)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>(700, 2) (300, 2)</code></pre>
</div>
<p style="text-align: justify;">
Here is an illustration of the two sets of data. The splitting into
testing and training data is done randomly. Picking test data randomly
is particularly important for real data as it helps to reduce potential
bias in the recording order.
</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots(figsize<span class="op">=</span>(<span class="dv">7</span>, <span class="dv">6</span>), ncols<span class="op">=</span><span class="dv">2</span>, nrows<span class="op">=</span><span class="dv">2</span>, sharex<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>ax[<span class="dv">0</span>, <span class="dv">0</span>].scatter(X_train[:, feature_1], X_train[:, feature_2], c<span class="op">=</span>y_train, s<span class="op">=</span><span class="dv">4</span>, cmap<span class="op">=</span><span class="st">'bwr'</span>)</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a>ax[<span class="dv">0</span>, <span class="dv">1</span>].scatter(X_test[:, feature_1], X_test[:, feature_2], c<span class="op">=</span>y_test, s<span class="op">=</span><span class="dv">4</span>, cmap<span class="op">=</span><span class="st">'bwr'</span>)</span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a></span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a>ax[<span class="dv">1</span>, <span class="dv">0</span>].hist(X_train)</span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a>ax[<span class="dv">1</span>, <span class="dv">1</span>].hist(X_test)</span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" tabindex="-1"></a>ax[<span class="dv">0</span>, <span class="dv">0</span>].set_title(<span class="st">'Training data'</span>)</span>
<span id="cb12-10"><a href="#cb12-10" tabindex="-1"></a>ax[<span class="dv">0</span>, <span class="dv">1</span>].set_title(<span class="st">'Test data'</span>)</span>
<span id="cb12-11"><a href="#cb12-11" tabindex="-1"></a></span>
<span id="cb12-12"><a href="#cb12-12" tabindex="-1"></a>ax[<span class="dv">0</span>, <span class="dv">0</span>].set_ylim(ft_min, ft_max)</span>
<span id="cb12-13"><a href="#cb12-13" tabindex="-1"></a>ax[<span class="dv">0</span>, <span class="dv">1</span>].set_ylim(ft_min, ft_max)</span>
<span id="cb12-14"><a href="#cb12-14" tabindex="-1"></a></span>
<span id="cb12-15"><a href="#cb12-15" tabindex="-1"></a>ax[<span class="dv">1</span>, <span class="dv">0</span>].set_ylim(<span class="dv">0</span>, <span class="dv">100</span>)</span>
<span id="cb12-16"><a href="#cb12-16" tabindex="-1"></a>ax[<span class="dv">1</span>, <span class="dv">1</span>].set_ylim(<span class="dv">0</span>, <span class="dv">100</span>)<span class="op">;</span></span>
<span id="cb12-17"><a href="#cb12-17" tabindex="-1"></a></span>
<span id="cb12-18"><a href="#cb12-18" tabindex="-1"></a>show()</span></code></pre>
</div>
<figure><img src="fig/02-improvement-rendered-unnamed-chunk-9-7.png" width="672" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure>
Now we can repeat the training with this split dataset using eight types
of models as above.
<p style="text-align: justify;">
To compare the model performances, we use <strong>scoring</strong>: the
method <code>.score</code> takes as input arguments the testing samples
and their true labels. It then uses the model predictions to calculate
the fraction of labels in the testing data that were predicted
correctly.
</p>
<p style="text-align: justify;">
There are different techniques to evaluate the performance, but the
<code>.score</code> method provides a quick, simple, and handy way to
assess a model. As far as classification algorithms in scikit-learn are
concerned, the method usually produces the <strong>mean
accuracy</strong>, which is between 0 and 1; and the higher the score,
the better the fit.
</p>
<div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a>fig, all_axes <span class="op">=</span> subplots(figsize<span class="op">=</span>[<span class="dv">15</span>, <span class="dv">5</span>], ncols<span class="op">=</span><span class="dv">4</span>, nrows<span class="op">=</span><span class="dv">2</span>, sharey<span class="op">=</span><span class="va">True</span>, sharex<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a><span class="cf">for</span> ax, (name, clf) <span class="kw">in</span> <span class="bu">zip</span>(all_axes.ravel(), classifiers.items()):</span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a>    <span class="co"># Training the model using training data:</span></span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a>    clf.fit(X_train, y_train)</span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a>    y_pred <span class="op">=</span> clf.predict(new_obs)</span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a>    y_pred_grid <span class="op">=</span> y_pred.reshape(grid_shape)</span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" tabindex="-1"></a>    <span class="co"># Evaluating the score using test data:</span></span>
<span id="cb13-11"><a href="#cb13-11" tabindex="-1"></a>    score <span class="op">=</span> clf.score(X_test, y_test)</span>
<span id="cb13-12"><a href="#cb13-12" tabindex="-1"></a></span>
<span id="cb13-13"><a href="#cb13-13" tabindex="-1"></a>    <span class="co"># Scattering the test data only:</span></span>
<span id="cb13-14"><a href="#cb13-14" tabindex="-1"></a>    ax.scatter(X_test[:, feature_1], X_test[:, feature_2], c<span class="op">=</span>y_test, s<span class="op">=</span><span class="dv">4</span>, cmap<span class="op">=</span><span class="st">'bwr'</span>, marker<span class="op">=</span><span class="st">'.'</span>)</span>
<span id="cb13-15"><a href="#cb13-15" tabindex="-1"></a></span>
<span id="cb13-16"><a href="#cb13-16" tabindex="-1"></a>    ax.contourf(grid_1, grid_2, y_pred_grid, cmap<span class="op">=</span><span class="st">'gray_r'</span>, alpha<span class="op">=</span><span class="fl">.2</span>, levels<span class="op">=</span>contour_levels)</span>
<span id="cb13-17"><a href="#cb13-17" tabindex="-1"></a><span class="co">#    ax.contourf(grid[0], grid[1], y_pred_grid, cmap='gray_r', alpha=.2, levels=contour_levels)</span></span>
<span id="cb13-18"><a href="#cb13-18" tabindex="-1"></a></span>
<span id="cb13-19"><a href="#cb13-19" tabindex="-1"></a>    ax.set_ylim(ft_min, ft_max)</span>
<span id="cb13-20"><a href="#cb13-20" tabindex="-1"></a>    ax.set_xlim(ft_min, ft_max)</span>
<span id="cb13-21"><a href="#cb13-21" tabindex="-1"></a>    ax.set_yticks([<span class="op">-</span><span class="fl">1.5</span>, <span class="dv">0</span>, <span class="fl">1.5</span>])</span>
<span id="cb13-22"><a href="#cb13-22" tabindex="-1"></a>    ax.set_xticks([<span class="op">-</span><span class="fl">1.5</span>, <span class="dv">0</span>, <span class="fl">1.5</span>])</span>
<span id="cb13-23"><a href="#cb13-23" tabindex="-1"></a></span>
<span id="cb13-24"><a href="#cb13-24" tabindex="-1"></a>    label <span class="op">=</span> <span class="st">'</span><span class="sc">{}</span><span class="st"> - Score: </span><span class="sc">{:.2f}</span><span class="st">'</span>.<span class="bu">format</span>(name, score)</span>
<span id="cb13-25"><a href="#cb13-25" tabindex="-1"></a>    ax.set_title(label , fontsize<span class="op">=</span><span class="dv">10</span>)<span class="op">;</span></span>
<span id="cb13-26"><a href="#cb13-26" tabindex="-1"></a></span>
<span id="cb13-27"><a href="#cb13-27" tabindex="-1"></a>show()</span></code></pre>
</div>
<figure><img src="fig/02-improvement-rendered-unnamed-chunk-10-9.png" width="1440" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p style="text-align: justify;">
Here, we only plotted the test data, those that were classified based on
the trained model. The gray area shows the result of the classification:
within the gray area the prediction is 1 (the red samples) and outside
it is 0 (the blue samples). The result is that testing data are
classified correctly in all but one of the classifiers, so their
performance is 1, or 100 %. This is excellent because it demonstrates
that most classifiers are able to deal with embedded topologies.
</p>
<p>Let us now repeat the procedure with a higher level of noise to make
the task more complicated.</p>
<div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a>X, y <span class="op">=</span> make_circles(n_samples<span class="op">=</span><span class="dv">1000</span>, factor<span class="op">=</span><span class="fl">.5</span>, noise<span class="op">=</span><span class="fl">.3</span>, random_state<span class="op">=</span>RANDOM_STATE)</span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">.3</span>, random_state<span class="op">=</span>RANDOM_STATE, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots(figsize<span class="op">=</span>(<span class="dv">7</span>, <span class="dv">6</span>), ncols<span class="op">=</span><span class="dv">2</span>, nrows<span class="op">=</span><span class="dv">2</span>, sharex<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a></span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a>ax[<span class="dv">0</span>, <span class="dv">0</span>].scatter(X_train[:, feature_1], X_train[:, feature_2], c<span class="op">=</span>y_train, s<span class="op">=</span><span class="dv">4</span>, cmap<span class="op">=</span><span class="st">'bwr'</span>)</span>
<span id="cb14-8"><a href="#cb14-8" tabindex="-1"></a>ax[<span class="dv">0</span>, <span class="dv">1</span>].scatter(X_test[:, feature_1], X_test[:, feature_2], c<span class="op">=</span>y_test, s<span class="op">=</span><span class="dv">4</span>, cmap<span class="op">=</span><span class="st">'bwr'</span>)</span>
<span id="cb14-9"><a href="#cb14-9" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" tabindex="-1"></a></span>
<span id="cb14-11"><a href="#cb14-11" tabindex="-1"></a>ax[<span class="dv">1</span>, <span class="dv">0</span>].hist(X_train)</span>
<span id="cb14-12"><a href="#cb14-12" tabindex="-1"></a></span>
<span id="cb14-13"><a href="#cb14-13" tabindex="-1"></a>ax[<span class="dv">1</span>, <span class="dv">1</span>].hist(X_test)</span>
<span id="cb14-14"><a href="#cb14-14" tabindex="-1"></a></span>
<span id="cb14-15"><a href="#cb14-15" tabindex="-1"></a>ax[<span class="dv">0</span>, <span class="dv">0</span>].set_title(<span class="st">'Training data'</span>)</span>
<span id="cb14-16"><a href="#cb14-16" tabindex="-1"></a>ax[<span class="dv">0</span>, <span class="dv">1</span>].set_title(<span class="st">'Test data'</span>)</span>
<span id="cb14-17"><a href="#cb14-17" tabindex="-1"></a></span>
<span id="cb14-18"><a href="#cb14-18" tabindex="-1"></a>ax[<span class="dv">0</span>, <span class="dv">0</span>].set_ylim(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb14-19"><a href="#cb14-19" tabindex="-1"></a>ax[<span class="dv">0</span>, <span class="dv">1</span>].set_ylim(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb14-20"><a href="#cb14-20" tabindex="-1"></a></span>
<span id="cb14-21"><a href="#cb14-21" tabindex="-1"></a>ax[<span class="dv">1</span>, <span class="dv">0</span>].set_ylim(<span class="dv">0</span>, <span class="dv">200</span>)</span>
<span id="cb14-22"><a href="#cb14-22" tabindex="-1"></a>ax[<span class="dv">1</span>, <span class="dv">1</span>].set_ylim(<span class="dv">0</span>, <span class="dv">200</span>)<span class="op">;</span></span>
<span id="cb14-23"><a href="#cb14-23" tabindex="-1"></a></span>
<span id="cb14-24"><a href="#cb14-24" tabindex="-1"></a>show()</span></code></pre>
</div>
<figure><img src="fig/02-improvement-rendered-unnamed-chunk-11-11.png" width="672" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a>fig, all_axes <span class="op">=</span> subplots(figsize<span class="op">=</span>[<span class="dv">15</span>, <span class="dv">5</span>], ncols<span class="op">=</span><span class="dv">4</span>, nrows<span class="op">=</span><span class="dv">2</span>, sharey<span class="op">=</span><span class="va">True</span>, sharex<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a><span class="cf">for</span> ax, (name, clf) <span class="kw">in</span> <span class="bu">zip</span>(all_axes.ravel(), classifiers.items()):</span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a>    <span class="co"># Training the model using training data:</span></span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a>    clf.fit(X_train, y_train)</span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a>    y_pred <span class="op">=</span> clf.predict(new_obs)</span>
<span id="cb15-8"><a href="#cb15-8" tabindex="-1"></a>    y_pred_grid <span class="op">=</span> y_pred.reshape(grid_shape)</span>
<span id="cb15-9"><a href="#cb15-9" tabindex="-1"></a></span>
<span id="cb15-10"><a href="#cb15-10" tabindex="-1"></a>    <span class="co"># Evaluating the score using test data:</span></span>
<span id="cb15-11"><a href="#cb15-11" tabindex="-1"></a>    score <span class="op">=</span> clf.score(X_test, y_test)</span>
<span id="cb15-12"><a href="#cb15-12" tabindex="-1"></a></span>
<span id="cb15-13"><a href="#cb15-13" tabindex="-1"></a>    <span class="co"># Scattering the test data only:</span></span>
<span id="cb15-14"><a href="#cb15-14" tabindex="-1"></a>    ax.scatter(X_test[:, feature_1], X_test[:, feature_2], c<span class="op">=</span>y_test, s<span class="op">=</span><span class="dv">4</span>, cmap<span class="op">=</span><span class="st">'bwr'</span>, marker<span class="op">=</span><span class="st">'.'</span>)</span>
<span id="cb15-15"><a href="#cb15-15" tabindex="-1"></a></span>
<span id="cb15-16"><a href="#cb15-16" tabindex="-1"></a>    ax.contourf(grid_1, grid_2, y_pred_grid, cmap<span class="op">=</span><span class="st">'gray_r'</span>, alpha<span class="op">=</span><span class="fl">.2</span>, levels<span class="op">=</span>contour_levels)</span>
<span id="cb15-17"><a href="#cb15-17" tabindex="-1"></a></span>
<span id="cb15-18"><a href="#cb15-18" tabindex="-1"></a>    ax.set_ylim(ft_min, ft_max)</span>
<span id="cb15-19"><a href="#cb15-19" tabindex="-1"></a>    ax.set_xlim(ft_min, ft_max)</span>
<span id="cb15-20"><a href="#cb15-20" tabindex="-1"></a>    ax.set_yticks([<span class="op">-</span><span class="fl">1.5</span>, <span class="dv">0</span>, <span class="fl">1.5</span>])</span>
<span id="cb15-21"><a href="#cb15-21" tabindex="-1"></a>    ax.set_xticks([<span class="op">-</span><span class="fl">1.5</span>, <span class="dv">0</span>, <span class="fl">1.5</span>])</span>
<span id="cb15-22"><a href="#cb15-22" tabindex="-1"></a></span>
<span id="cb15-23"><a href="#cb15-23" tabindex="-1"></a>    label <span class="op">=</span> <span class="st">'</span><span class="sc">{}</span><span class="st"> - Score: </span><span class="sc">{:.2f}</span><span class="st">'</span>.<span class="bu">format</span>(name, score)</span>
<span id="cb15-24"><a href="#cb15-24" tabindex="-1"></a>    ax.set_title(label , fontsize<span class="op">=</span><span class="dv">10</span>)<span class="op">;</span></span>
<span id="cb15-25"><a href="#cb15-25" tabindex="-1"></a></span>
<span id="cb15-26"><a href="#cb15-26" tabindex="-1"></a>show()</span></code></pre>
</div>
<figure><img src="fig/02-improvement-rendered-unnamed-chunk-12-13.png" width="1440" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p style="text-align: justify;">
Now the data are mixed in the plane and there is no simple way to
separate the two classes. We can see in the plots how the algorithms try
to cope with their different strategies. One thing that is immediately
obvious is that the fitting patterns are different. Particularly, we can
see the fragmented outcome of the <em>decision tree</em> classifier and
the smooth elliptic area found by the <em>support vector classifier
(SVC)</em> with radial basis functions (RBF) and the neural network
(MLP). On a closer look, you may also notice that with ensemble methods
in the upper row, the patterns are somewhat disorganised. This is due to
the way ensemble methods work: they sample the data randomly and then
class them into different categories based on their labels.
</p>
<p style="text-align: justify;">
If the prediction was made by chance (throwing a dice), one would expect
a 50 % score. Thus, the example also shows that the performance depends
on the type of problem and that this testing helps to find an optimal
classifier.
</p>
<div id="never-expose-the-test-data" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="never-expose-the-test-data" class="callout-inner">
<h3 class="callout-title"><strong>Never expose the test
data</strong></h3>
<div class="callout-content">
<p style="text-align: justify;">
Testing a model on data that is used in training is a methodological
mistake. It is therefore vital that the test data is <strong>never,
ever</strong> used for training a model at any stage. This is one of the
most fundamental principles of machine learning, and its importance
cannot be exaggerated. There are numerous examples of people making this
mistake one way or another, especially where multiple classification
algorithms are used to address a problem.
</p>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="the-stratified-shuffle-split">The Stratified Shuffle Split<a class="anchor" aria-label="anchor" href="#the-stratified-shuffle-split"></a>
</h2>
<hr class="half-width">
<p style="text-align: justify;">
One potential bias arises when we try to improve the performance of our
models through the change of the so-called
<strong>hyperparameters</strong> (instead of using the default
parameters as we did so far). We will always receive the optimal output
given <strong>the specific test data chosen</strong>. This may lead to
overfitting the model on the chosen training and testing data. This can
be avoided by choosing different splits into testing and training data
and repeating the fit procedure. Doing different splits while preserving
the fraction of labels of each class in the original data, the method is
called the <strong>stratified shuffle split</strong>.
</p>
<p style="text-align: justify;">
We first need to import and instantiate the splitter. We set key word
argument <code>n_splits</code> to determine the number of different
splits. <code>test_size</code> lets us determine what fraction of
samples is used for the testing data.
</p>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> StratifiedShuffleSplit</span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a>sss <span class="op">=</span> StratifiedShuffleSplit(random_state<span class="op">=</span>RANDOM_STATE, n_splits<span class="op">=</span><span class="dv">10</span>, test_size<span class="op">=</span><span class="fl">0.3</span>)</span></code></pre>
</div>
<p>Let us look at the different splits obtained:</p>
<div class="codewrapper sourceCode" id="cb17">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots(figsize<span class="op">=</span>[<span class="dv">10</span>, <span class="dv">5</span>])</span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a>n_splits <span class="op">=</span> sss.n_splits</span>
<span id="cb17-4"><a href="#cb17-4" tabindex="-1"></a>split_data_indices <span class="op">=</span> sss.split(X<span class="op">=</span>X, y<span class="op">=</span>y)</span>
<span id="cb17-5"><a href="#cb17-5" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" tabindex="-1"></a><span class="cf">for</span> index, (tr, tt) <span class="kw">in</span> <span class="bu">enumerate</span>(split_data_indices):</span>
<span id="cb17-7"><a href="#cb17-7" tabindex="-1"></a>    indices <span class="op">=</span> X[:, feature_1].copy()</span>
<span id="cb17-8"><a href="#cb17-8" tabindex="-1"></a>    indices[tt] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb17-9"><a href="#cb17-9" tabindex="-1"></a>    indices[tr] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb17-10"><a href="#cb17-10" tabindex="-1"></a></span>
<span id="cb17-11"><a href="#cb17-11" tabindex="-1"></a>    <span class="co"># Visualize the results</span></span>
<span id="cb17-12"><a href="#cb17-12" tabindex="-1"></a>    x_axis <span class="op">=</span> arange(indices.size)</span>
<span id="cb17-13"><a href="#cb17-13" tabindex="-1"></a>    y_axis <span class="op">=</span> [index <span class="op">+</span> <span class="fl">.5</span>] <span class="op">*</span> indices.size</span>
<span id="cb17-14"><a href="#cb17-14" tabindex="-1"></a>    ax.scatter(x_axis, y_axis, c<span class="op">=</span>indices, marker<span class="op">=</span><span class="st">'_'</span>, lw<span class="op">=</span><span class="dv">10</span>, cmap<span class="op">=</span><span class="st">'coolwarm'</span>, vmin<span class="op">=-</span><span class="fl">.2</span>, vmax<span class="op">=</span><span class="fl">1.2</span>)</span>
<span id="cb17-15"><a href="#cb17-15" tabindex="-1"></a></span>
<span id="cb17-16"><a href="#cb17-16" tabindex="-1"></a><span class="co"># Plot the data classes and groups at the end</span></span>
<span id="cb17-17"><a href="#cb17-17" tabindex="-1"></a>class_y <span class="op">=</span> [index <span class="op">+</span> <span class="fl">1.5</span>] <span class="op">*</span> indices.size</span>
<span id="cb17-18"><a href="#cb17-18" tabindex="-1"></a>ax.scatter(x_axis, class_y, c<span class="op">=</span>y, marker<span class="op">=</span><span class="st">'_'</span>, lw<span class="op">=</span><span class="dv">10</span>, cmap<span class="op">=</span><span class="st">'coolwarm'</span>)</span>
<span id="cb17-19"><a href="#cb17-19" tabindex="-1"></a></span>
<span id="cb17-20"><a href="#cb17-20" tabindex="-1"></a><span class="co"># Formatting</span></span>
<span id="cb17-21"><a href="#cb17-21" tabindex="-1"></a>ylabels <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(n_splits))</span>
<span id="cb17-22"><a href="#cb17-22" tabindex="-1"></a>ylabels.extend([<span class="st">'Data'</span>])</span>
<span id="cb17-23"><a href="#cb17-23" tabindex="-1"></a></span>
<span id="cb17-24"><a href="#cb17-24" tabindex="-1"></a>ax.set_yticks(arange(n_splits <span class="op">+</span> <span class="dv">1</span>) <span class="op">+</span> <span class="fl">.5</span>)</span>
<span id="cb17-25"><a href="#cb17-25" tabindex="-1"></a>ax.set_yticklabels(ylabels)</span>
<span id="cb17-26"><a href="#cb17-26" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Sample index'</span>)</span>
<span id="cb17-27"><a href="#cb17-27" tabindex="-1"></a>ax.set_ylabel(<span class="st">'SSS iteration'</span>)<span class="op">;</span></span>
<span id="cb17-28"><a href="#cb17-28" tabindex="-1"></a></span>
<span id="cb17-29"><a href="#cb17-29" tabindex="-1"></a>show()</span></code></pre>
</div>
<figure><img src="fig/02-improvement-rendered-unnamed-chunk-14-15.png" width="960" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p style="text-align: justify;">
By choosing n_splits=10, we obtained ten different splits that have
similarly distributed train and test data subsets from the original
data. The fraction of the data set aside for testing is 30 %. The
different splits cover the whole data set evenly. As such, using them
for training and testing will lead to a fairly unbiased average
performance.
</p>
<p>Let us look at the data in state space to check that the
classification task is now a real challenge.</p>
<div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">8</span>))</span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a><span class="cf">for</span> train_index, test_index <span class="kw">in</span> sss.split(X, y):</span>
<span id="cb18-4"><a href="#cb18-4" tabindex="-1"></a>    ax.scatter(X[train_index, <span class="dv">0</span>], X[train_index, <span class="dv">1</span>], c<span class="op">=</span>y[train_index], cmap<span class="op">=</span><span class="st">'Set1'</span>, s<span class="op">=</span><span class="dv">30</span>, marker<span class="op">=</span><span class="st">'^'</span>, alpha<span class="op">=</span><span class="fl">.5</span>)</span>
<span id="cb18-5"><a href="#cb18-5" tabindex="-1"></a>    ax.scatter(X[test_index, <span class="dv">0</span>], X[test_index, <span class="dv">1</span>], c<span class="op">=</span>y[test_index], cmap<span class="op">=</span><span class="st">'cool'</span>, s<span class="op">=</span><span class="dv">30</span>, alpha<span class="op">=</span><span class="fl">.5</span>, marker<span class="op">=</span><span class="st">'*'</span>, label<span class="op">=</span><span class="st">'Test'</span>)<span class="op">;</span></span>
<span id="cb18-6"><a href="#cb18-6" tabindex="-1"></a></span>
<span id="cb18-7"><a href="#cb18-7" tabindex="-1"></a>show()</span></code></pre>
</div>
<figure><img src="fig/02-improvement-rendered-unnamed-chunk-15-17.png" width="768" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>These are the scatter plots of the training (magenta) and testing
(blue) data. Here are their distributions:</p>
<div class="codewrapper sourceCode" id="cb19">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">8</span>))</span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" tabindex="-1"></a><span class="cf">for</span> train_index, test_index <span class="kw">in</span> sss.split(X, y):</span>
<span id="cb19-4"><a href="#cb19-4" tabindex="-1"></a>    ax.hist(X[train_index], color<span class="op">=</span>[<span class="st">'magenta'</span>, <span class="st">'red'</span>], alpha<span class="op">=</span><span class="fl">.5</span>, histtype<span class="op">=</span><span class="st">'step'</span>)</span>
<span id="cb19-5"><a href="#cb19-5" tabindex="-1"></a>    ax.hist(X[test_index], color<span class="op">=</span>[<span class="st">'cyan'</span>, <span class="st">'blue'</span>], alpha<span class="op">=</span><span class="fl">.4</span>, histtype<span class="op">=</span><span class="st">'step'</span>)<span class="op">;</span></span>
<span id="cb19-6"><a href="#cb19-6" tabindex="-1"></a></span>
<span id="cb19-7"><a href="#cb19-7" tabindex="-1"></a>show()</span></code></pre>
</div>
<figure><img src="fig/02-improvement-rendered-unnamed-chunk-16-19.png" width="768" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p style="text-align: justify;">
The distributions differ in height because less data are in the testing
test. Otherwise they are similarly centred and spread. Using a number of
realisations (instead of just one) we expect to obtain a more accurate
and robust result of the training.
</p>
<p style="text-align: justify;">
We now train our classifiers on these different splits and obtain the
respective scores. They will give a robust measure of the classifier’s
performance given the data and avoid potential bias due to the selection
of specific test data.
</p>
<div class="codewrapper sourceCode" id="cb20">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a>X, y <span class="op">=</span> make_circles(n_samples<span class="op">=</span><span class="dv">1000</span>, factor<span class="op">=</span><span class="fl">.3</span>, noise<span class="op">=</span><span class="fl">.4</span>, random_state<span class="op">=</span>RANDOM_STATE)</span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" tabindex="-1"></a>score <span class="op">=</span> <span class="bu">list</span>()</span>
<span id="cb20-4"><a href="#cb20-4" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" tabindex="-1"></a><span class="cf">for</span> train_index, test_index <span class="kw">in</span> sss.split(X, y):</span>
<span id="cb20-6"><a href="#cb20-6" tabindex="-1"></a>    X_s, y_s <span class="op">=</span> X[train_index, :], y[train_index]</span>
<span id="cb20-7"><a href="#cb20-7" tabindex="-1"></a>    new_obs_s, y_test_s <span class="op">=</span> X[test_index, :], y[test_index]</span>
<span id="cb20-8"><a href="#cb20-8" tabindex="-1"></a></span>
<span id="cb20-9"><a href="#cb20-9" tabindex="-1"></a>    score_clf <span class="op">=</span> <span class="bu">list</span>()</span>
<span id="cb20-10"><a href="#cb20-10" tabindex="-1"></a></span>
<span id="cb20-11"><a href="#cb20-11" tabindex="-1"></a>    <span class="cf">for</span> name, clf <span class="kw">in</span> classifiers.items():</span>
<span id="cb20-12"><a href="#cb20-12" tabindex="-1"></a></span>
<span id="cb20-13"><a href="#cb20-13" tabindex="-1"></a>        clf.fit(X_s, y_s)</span>
<span id="cb20-14"><a href="#cb20-14" tabindex="-1"></a>        y_pred <span class="op">=</span> clf.predict(new_obs_s)</span>
<span id="cb20-15"><a href="#cb20-15" tabindex="-1"></a>        score_clf.append(clf.score(new_obs_s, y_test_s))</span>
<span id="cb20-16"><a href="#cb20-16" tabindex="-1"></a></span>
<span id="cb20-17"><a href="#cb20-17" tabindex="-1"></a>    score.append(score_clf)</span>
<span id="cb20-18"><a href="#cb20-18" tabindex="-1"></a></span>
<span id="cb20-19"><a href="#cb20-19" tabindex="-1"></a>score_mean <span class="op">=</span> mean(score, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb20-20"><a href="#cb20-20" tabindex="-1"></a></span>
<span id="cb20-21"><a href="#cb20-21" tabindex="-1"></a>bins <span class="op">=</span> arange(<span class="bu">len</span>(score_mean))</span>
<span id="cb20-22"><a href="#cb20-22" tabindex="-1"></a></span>
<span id="cb20-23"><a href="#cb20-23" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots()</span>
<span id="cb20-24"><a href="#cb20-24" tabindex="-1"></a></span>
<span id="cb20-25"><a href="#cb20-25" tabindex="-1"></a>ax.bar(bins, score_mean)<span class="op">;</span></span>
<span id="cb20-26"><a href="#cb20-26" tabindex="-1"></a>ax.set_xticks(arange(<span class="dv">0</span>,<span class="dv">8</span>)<span class="op">+</span><span class="fl">0.4</span>)</span>
<span id="cb20-27"><a href="#cb20-27" tabindex="-1"></a>ax.set_xticklabels(classifiers.keys(), rotation<span class="op">=-</span><span class="dv">70</span>)<span class="op">;</span></span>
<span id="cb20-28"><a href="#cb20-28" tabindex="-1"></a></span>
<span id="cb20-29"><a href="#cb20-29" tabindex="-1"></a>show()</span>
<span id="cb20-30"><a href="#cb20-30" tabindex="-1"></a></span>
<span id="cb20-31"><a href="#cb20-31" tabindex="-1"></a><span class="bu">print</span>(classifiers.keys())</span>
<span id="cb20-32"><a href="#cb20-32" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Average scores: '</span>)</span>
<span id="cb20-33"><a href="#cb20-33" tabindex="-1"></a><span class="bu">print</span>([<span class="st">"</span><span class="sc">{0:0.2f}</span><span class="st">"</span>.<span class="bu">format</span>(ind) <span class="cf">for</span> ind <span class="kw">in</span> score_mean])</span></code></pre>
</div>
<style>#sk-container-id-1 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: #000;
  --sklearn-color-text-muted: #666;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-1 {
  color: var(--sklearn-color-text);
}

#sk-container-id-1 pre {
  padding: 0;
}

#sk-container-id-1 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-1 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-1 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-1 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-1 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-1 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-1 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-1 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-1 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-1 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-1 label.sk-toggleable__label {
  cursor: pointer;
  display: flex;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
  align-items: start;
  justify-content: space-between;
  gap: 0.5em;
}

#sk-container-id-1 label.sk-toggleable__label .caption {
  font-size: 0.6rem;
  font-weight: lighter;
  color: var(--sklearn-color-text-muted);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-1 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-1 div.sk-label label.sk-toggleable__label,
#sk-container-id-1 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-1 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-1 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-1 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-1 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 0.5em;
  text-align: center;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-1 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-1 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-1 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-1 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style>
<div id="sk-container-id-1" class="sk-top-container">
<div class="sk-text-repr-fallback">
<pre>MLPClassifier(max_iter=5000, random_state=1234)</pre>
<b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b>
</div>
<div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator fitted sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>MLPClassifier</div></div>
<div>
<a class="external-link sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.neural_network.MLPClassifier.html">?<span>Documentation for MLPClassifier</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span>
</div></label><div class="sk-toggleable__content fitted"><pre>MLPClassifier(max_iter=5000, random_state=1234)</pre></div> </div></div></div>
</div>
<figure><img src="fig/02-improvement-rendered-unnamed-chunk-17-21.png" width="672" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>dict_keys(['Random Forest', 'AdaBoost (Random Forest)', 'Extra Trees', 'AdaBoost (Extra Tree)', 'Decision Tree', 'SVC (RBF)', 'SVC (Linear)', 'Multi-layer Perceptron'])
Average scores:
['0.76', '0.76', '0.75', '0.75', '0.70', '0.79', '0.50', '0.78']</code></pre>
</div>
<p>The result is the average score for the ten splits performed. All
results for the noise-contaminated data are now in the seventies.</p>
<p style="text-align: justify;">
This is still good given the quality of the data. It appears that the
<em>decision tree</em> classifier gives the lowest result for this kind
of problem, <em>SVC (RBF)</em> scores highest. We have to keep in mind,
however, that we are using the classifiers with their default settings.
We will later use variation of the so-called hyperparameters to further
improve the classification score.
</p>
<p>Here we have used a for loop to train and test on each of the
different splits of the data. SciKit Learn also contains functions that
take the stratified shuffle split as an argument,
e.g. <code>permutation_test_score</code>. In that case, the splits do
not need to be done separately.</p>
<p>We have now reached a point where we can trust to have a robust and
unbiased outcome of the training. Let us now look at more refined ways
to quantify the result.</p>
</section><section><h2 class="section-heading" id="evaluation-roc-and-auc">Evaluation: ROC and AUC<a class="anchor" aria-label="anchor" href="#evaluation-roc-and-auc"></a>
</h2>
<hr class="half-width">
<p style="text-align: justify;">
There are various measures that may be used to evaluate the performance
of a machine learning model. Such measures look at different
characteristics, including the goodness of fit and generalisability of a
model. Evaluation measures used with regards to classification models
include, but are not limited to:
</p>
<ul>
<li>Receiver Operation Characteristic (ROC) and Area Under the Curve
(AUC) - for binary classifiers.</li>
<li>Accuracy</li>
<li>Precision</li>
<li>Recall</li>
</ul>
<p style="text-align: justify;">
There are many other metrics that, depending on the problem, we may use
to evaluate a machine learning model. Please see <a href="https://scikit-learn.org/stable/modules/model_evaluation.html" class="external-link">the
official documentation</a> for additional information on these measures
and their implementation in scikit-learn.
</p>
<p>The quantities we are going to look at are the <strong>Receiver
Operation Characteristic (ROC)</strong> and the <strong>Area Under the
Curve (AUC)</strong>.</p>
<p style="text-align: justify;">
A receiver operation characteristic, often referred to as the
<strong>ROC curve</strong>, is a visualisation of the discrimination
threshold in a binary classification model. It illustrates the rate of
true positives (TPR) against the rate of false positives (FPR) at
different thresholds. The aforementioned rates are essentially defined
as:
</p>
<ul>
<li>True Positive Rate (TPR): the sensitivity of the model</li>
<li>False Positive Rate (FPR): one minus the specificity of the
model</li>
</ul>
<p>This makes ROC a measure of sensitivity versus specificity.</p>
<p style="text-align: justify;">
The area under the ROC curve, often referred to as AUC, reduces the
information contained within a ROC curve down to a value between 0 and
1, with 1 being a perfect fit. An AUC value of 0.5 represents any random
guess, and values below demonstrate a performance that’s even worse than
a lucky guess!
</p>
<div id="discussion3" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Discussion</h3>
<div class="callout-content">
<p style="text-align: justify;">
<code>scikit-learn</code> includes specialist functions called
<code>roc_curve</code> and <code>roc_auc_score</code> to obtain ROC (FPR
and TPR values for visualisation) and AUC respectively. Both functions
receive as input arguments the test labels (i.e. <code>y_test</code>)
and the score (probability) associated with each prediction. We obtain
the latter measure using one of the following two techniques:
</p>
<ul>
<li>Decision function: where classification models have a
<code>.decision_function</code> method that provides us with score
associated with each label.</li>
<li>Probability: where classification models have a
<code>.predict_proba</code> method that provides us with the probability
associated with each prediction (we used it in the Classification
Introduction lesson). In this case, however, the results are provided in
the form of a two-dimensional array where columns represent different
labels (as defined in property). Given that we will plot ROC curves for
binary problems (two labels), we only pick one of these columns.
Usually, the second column (the feature representing <code>True</code>
or <strong>1</strong>) is the one to choose. However, if you notice that
the results are unexpectedly bad, you may try the other column just be
sure.</li>
</ul>
</div>
</div>
</div>
<p style="text-align: justify;">
We can see that our classifiers now reach different degrees of
prediction. The degree can be quantified by the <strong>Area Under the
Curve (AUC)</strong>. It refers to the area between the blue ROC curve
and the orange diagonal. The area under the ROC curve, often referred to
as AUC, reduces the information contained within a ROC curve down to a
value between and 0 and 1, with 1 being a perfect fit. An AUC value of
0.5 represents a random guess, and values below the diagonal demonstrate
a performance that’s even worse than a guess!
</p>
<p style="text-align: justify;">
scikit-learn includes specialist functions called <code>roc_curve</code>
and <code>roc_auc_score</code> to obtain ROC (FPR and TPR values for
visualisation) and AUC respectively. Both function receive as input
arguments the test labels (i.e. y_score) and the score (probability)
associated with each prediction. We obtain the latter measure using one
of the following two techniques:
</p>
<ul>
<li>Decision function: where classification models have a
<code>.decision_function</code> method that provides us with a score
associated with each label.</li>
<li>Probability: where classification models have a
<code>predict_proba_</code> method that provides us with the probability
associated with each prediction. In this case, however, the results are
provided in the form of a two-dimensional array where columns represents
different labels (as defined in <code>.classes</code> property). Given
that we only plot ROC curves for binary problems, we should only use one
of these columns. Usually, the second column (the feature representing
<code>True</code> or <strong>1</strong>) is the one to choose. However,
if you notice that the results are unexpectedly bad, you may try the
other column just be sure.</li>
</ul>
<div class="codewrapper sourceCode" id="cb22">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_curve, roc_auc_score</span>
<span id="cb22-2"><a href="#cb22-2" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" tabindex="-1"></a>fig, all_axes <span class="op">=</span> subplots(figsize<span class="op">=</span>[<span class="dv">15</span>, <span class="dv">10</span>], ncols<span class="op">=</span><span class="dv">4</span>, nrows<span class="op">=</span><span class="dv">2</span>, sharey<span class="op">=</span><span class="va">True</span>, sharex<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb22-4"><a href="#cb22-4" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" tabindex="-1"></a><span class="cf">for</span> ax, (name, clf) <span class="kw">in</span> <span class="bu">zip</span>(all_axes.ravel(), classifiers.items()):</span>
<span id="cb22-6"><a href="#cb22-6" tabindex="-1"></a>    clf.fit(X_train, y_train)</span>
<span id="cb22-7"><a href="#cb22-7" tabindex="-1"></a></span>
<span id="cb22-8"><a href="#cb22-8" tabindex="-1"></a>    <span class="co"># Checking whether or not the object has `decision_function`:</span></span>
<span id="cb22-9"><a href="#cb22-9" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">hasattr</span>(clf, <span class="st">'decision_function'</span>):</span>
<span id="cb22-10"><a href="#cb22-10" tabindex="-1"></a>        <span class="co"># If it does:</span></span>
<span id="cb22-11"><a href="#cb22-11" tabindex="-1"></a>        y_score <span class="op">=</span> clf.decision_function(X_test)</span>
<span id="cb22-12"><a href="#cb22-12" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb22-13"><a href="#cb22-13" tabindex="-1"></a>        <span class="co"># Otherwise:</span></span>
<span id="cb22-14"><a href="#cb22-14" tabindex="-1"></a>        y_score <span class="op">=</span> clf.predict_proba(X_test)[:, feature_2]  <span class="co"># We only need one column.</span></span>
<span id="cb22-15"><a href="#cb22-15" tabindex="-1"></a></span>
<span id="cb22-16"><a href="#cb22-16" tabindex="-1"></a>    <span class="co"># Obtaining the x- and y-axis values for the ROC curve:</span></span>
<span id="cb22-17"><a href="#cb22-17" tabindex="-1"></a>    fpr, tpr, thresh <span class="op">=</span> roc_curve(y_test, y_score)</span>
<span id="cb22-18"><a href="#cb22-18" tabindex="-1"></a></span>
<span id="cb22-19"><a href="#cb22-19" tabindex="-1"></a>    <span class="co"># Obtaining the AUC value:</span></span>
<span id="cb22-20"><a href="#cb22-20" tabindex="-1"></a>    roc_auc <span class="op">=</span> roc_auc_score(y_test, y_score)</span>
<span id="cb22-21"><a href="#cb22-21" tabindex="-1"></a></span>
<span id="cb22-22"><a href="#cb22-22" tabindex="-1"></a>    ax.plot(fpr, tpr, lw<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb22-23"><a href="#cb22-23" tabindex="-1"></a>    ax.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], lw<span class="op">=</span><span class="dv">1</span>, linestyle<span class="op">=</span><span class="st">'--'</span>)</span>
<span id="cb22-24"><a href="#cb22-24" tabindex="-1"></a></span>
<span id="cb22-25"><a href="#cb22-25" tabindex="-1"></a>    ax.set_xlabel(<span class="st">'False Positive Rate'</span>)</span>
<span id="cb22-26"><a href="#cb22-26" tabindex="-1"></a>    ax.set_ylabel(<span class="st">'True Positive Rate'</span>)</span>
<span id="cb22-27"><a href="#cb22-27" tabindex="-1"></a></span>
<span id="cb22-28"><a href="#cb22-28" tabindex="-1"></a>    label <span class="op">=</span> <span class="st">'</span><span class="sc">{}</span><span class="st"> - AUC: </span><span class="sc">{:.2f}</span><span class="st">'</span>.<span class="bu">format</span>(name, roc_auc)</span>
<span id="cb22-29"><a href="#cb22-29" tabindex="-1"></a>    ax.set_title(label, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb22-30"><a href="#cb22-30" tabindex="-1"></a></span>
<span id="cb22-31"><a href="#cb22-31" tabindex="-1"></a>show()</span></code></pre>
</div>
<figure><img src="fig/02-improvement-rendered-unnamed-chunk-18-23.png" width="1440" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>The (orange) diagonal represents predictions of the two labels by a
coin toss. To be of value the classifier must reach a ROC curve above
the diagonal.</p>
<p style="text-align: justify;">
This concludes our first steps into classification with scikit-learn.
There are many more aspects of classification. From a practical point of
view, <a href="https://scikit-learn.org/stable/modules/preprocessing.html" class="external-link">data
normalisation</a> and <a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.permutation_test_score.html" class="external-link">permutation
test score</a> as well as the workflow report are important. These will
be the topics of our next lesson.
</p>
<p><br></p>
</section><section><h2 class="section-heading" id="exercises">Exercises<a class="anchor" aria-label="anchor" href="#exercises"></a>
</h2>
<hr class="half-width">
<div id="end-of-chapter-exercises" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="end-of-chapter-exercises" class="callout-inner">
<h3 class="callout-title">End of chapter Exercises</h3>
<div class="callout-content">
<p>Take the torus-within-a-torus data generator from the
<strong>Challenge</strong> above.</p>
<ol style="list-style-type: decimal">
<li>Create a 3-feature dataset with the <code>make_torus_3D()</code>
function using the following properties:</li>
</ol>
<ul>
<li>2000 samples</li>
<li>A factor of 0.8</li>
<li>A noise level of 0.3</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>Create a 3-D scatter plot of the newly generated dataset.</li>
</ol>
<p><em>(Optional: Play around with factor and noise to observe how they
can make the dataset more or less complex)</em>.</p>
<p>3a. Using the classifiers given above, train and score each
model:</p>
<ul>
<li>Use the stratified-shuffle-split method:
<ul>
<li>Set the function to generate 5 sets of test/train splits</li>
<li>Set the test size to 0.3 (30%)</li>
</ul>
</li>
<li>Calculate and store the average score for each classifier</li>
</ul>
<p>3b. Plot the average score for all classifiers. - What is the best
performing classifier?</p>
<ol start="4" style="list-style-type: decimal">
<li>Select the best-performing model from the previous question and
store it as a new instance:</li>
</ol>
<ul>
<li>Plot the feature importances obtained from your chosen model to see
how each feature contriutes to the outcome.</li>
</ul>
<p><em>(Hint: You’ll need to intialise and fit the model again. You can
use the whole dataset for this)</em>.</p>
<ol start="5" style="list-style-type: decimal">
<li>OPTIONAL: Explore how noise affects the accuracy of a
classifier.</li>
</ol>
<ul>
<li><p>Generate three datasets with noise levels of <strong>0.05, 0.2,
0.6</strong> using <code>make_torus_3D()</code>. Keep the number of
samples and factor the same as in <strong>Question 1</strong>.</p></li>
<li>
<p>Create an ROC AUC plot for each dataset using the same-best
performing model you used in <strong>Question 4</strong> as the model to
train and predict with.</p>
<ul>
<li>Use the <code>train_test_split()</code> function from scikit-learn
to split your data.</li>
<li><em>Look to the lesson for an example of how to generate ROC curve
plots.</em></li>
</ul>
</li>
</ul>
<p><em>(Hint! When calling a for loop on your datasets you will need to
nest them inside a list).</em></p>
<p>Observe and comment on how noise affects the performance of the
classifiers in terms of True and False positives.</p>
<div class="section level2">
<h2 id="recommendation">Recommendation<a class="anchor" aria-label="anchor" href="#recommendation"></a>
</h2>
<p style="text-align: justify;">
Pick any of the provided (or other) data sets with labels to repeat the
above. Feel free to try and do any testing or plotting that you find
important. This is not an assignment to get the correct answer. Rather
at this stage, we practise to use functionality from scikit-learn to
search for structure in the data that helps to achieve the best
predictions possible.
</p>
</div>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1">
  Solutions are provided after assignments are marked.
  </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">

</div>
</div>
</div>
</div>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>Different classification algorithms approach problems
differently.</li>
<li>
<code>train_test_split</code> function tries to preserve the ratio
of labels in the split</li>
<li>Increasing the level of noise in the data makes the task more
complicated.</li>
<li>The potential bias due to splitting could be avoid using stratified
shuffle split.</li>
<li>
<code>StratifiedShuffleSplit</code> is a method that uses
<code>n_splits</code> and <code>test_size</code> parameters.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section><section id="aio-03-refinement"><p>Content from <a href="03-refinement.html">Refinement</a></p>
<hr>
<p>Last updated on 2025-03-31 |

        <a href="https://github.com/carpentries/workbench-template-md/edit/main/episodes/03-refinement.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<p><a href="https://drive.usercontent.google.com/u/1/uc?id=1cqu1pvFr9rWK92CUZX7u2bI6W7NYRpxK&amp;export=download" class="external-link"><strong>Download
Chapter notebook (ipynb)</strong></a></p>
<p><a href="https://drive.usercontent.google.com/u/1/uc?id=19SuFCaGlQz1_4cc3nESKTEadR2B_wtW3&amp;export=download" class="external-link"><strong>Download
Chapter PDF</strong></a></p>
<p><a href="https://docs.google.com/forms/d/e/1FAIpQLSdr0capF7jloJhPH3Pki1B3LZoKOG16poOpuVJ7SL2LkwLHQA/viewform?pli=1" class="external-link"><span style="color: rgb(255, 0, 0);"><strong>Mandatory Lesson Feedback
Survey</strong></span></a></p>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How do different evaluation metrics differ?</li>
<li>What techniques are used to improve on chance prediction?</li>
<li>What are the limitations of a confusion matrix?</li>
<li>How can normalisation and hyperparameter tuning help to improve the
results?</li>
<li>How could test data leakage be avoided?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Introducing different types of metrics for model evaluation.</li>
<li>Understanding the permutation score.</li>
<li>Illustrating model evaluation using the confusion matrix.</li>
<li>working with normalisation and hyperparameter tuning.</li>
<li>The concept of progressive adjustment.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<p align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/Vo9eBk9P9rk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
</p>
<br><p align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/JJ_5Dc1Tcg4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
</p>
<p><br></p>
<div class="section level3">
<h3 id="import-functions">
<strong>Import functions</strong><a class="anchor" aria-label="anchor" href="#import-functions"></a>
</h3>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> mgrid, linspace, c_, arange, mean, array</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">from</span> numpy.random <span class="im">import</span> uniform, seed</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_circles</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">from</span> mpl_toolkits <span class="im">import</span> mplot3d</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="im">from</span> matplotlib.pyplot <span class="im">import</span> subplots, axes, scatter, xticks, show</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC, LinearSVC</span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a><span class="im">from</span> sklearn.neural_network <span class="im">import</span> MLPClassifier</span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a>RANDOM_STATE <span class="op">=</span> <span class="dv">111</span></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a>classifiers <span class="op">=</span> {</span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a>    <span class="st">'Random Forest'</span>: RandomForestClassifier(random_state<span class="op">=</span>RANDOM_STATE),</span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a>    <span class="st">'AdaBoost (Random Forest)'</span>: AdaBoostClassifier(RandomForestClassifier(random_state<span class="op">=</span>RANDOM_STATE)),</span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a>    <span class="st">'Extra Trees'</span>: ExtraTreesClassifier(random_state<span class="op">=</span>RANDOM_STATE),</span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a>    <span class="st">'AdaBoost (Extra Tree)'</span>: AdaBoostClassifier(ExtraTreesClassifier(random_state<span class="op">=</span>RANDOM_STATE)),</span>
<span id="cb1-20"><a href="#cb1-20" tabindex="-1"></a>    <span class="st">'Decision Tree'</span>: DecisionTreeClassifier(random_state<span class="op">=</span>RANDOM_STATE),</span>
<span id="cb1-21"><a href="#cb1-21" tabindex="-1"></a>    <span class="st">'SVC (RBF)'</span>: SVC(random_state<span class="op">=</span>RANDOM_STATE),</span>
<span id="cb1-22"><a href="#cb1-22" tabindex="-1"></a>    <span class="st">'SVC (Linear)'</span>: LinearSVC(random_state<span class="op">=</span>RANDOM_STATE),</span>
<span id="cb1-23"><a href="#cb1-23" tabindex="-1"></a>    <span class="st">'Multi-layer Perceptron'</span>: MLPClassifier(max_iter<span class="op">=</span><span class="dv">5000</span>, random_state<span class="op">=</span>RANDOM_STATE)</span>
<span id="cb1-24"><a href="#cb1-24" tabindex="-1"></a>}</span></code></pre>
</div>
</div>
<section><h2 class="section-heading" id="revision-example-with-circular-test-data">Revision Example with Circular Test Data<a class="anchor" aria-label="anchor" href="#revision-example-with-circular-test-data"></a>
</h2>
<hr class="half-width">
<p>For our classification problem, we will use the
<code>make_circles</code> function. See the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_circles.html" class="external-link">documentation</a></p>
<p>The parameters for noise level and relative size of the two circles
are such that the task becomes difficult.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>seed(RANDOM_STATE)</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>X, y <span class="op">=</span> make_circles(n_samples<span class="op">=</span><span class="dv">500</span>, factor<span class="op">=</span><span class="fl">0.5</span>, noise<span class="op">=</span><span class="fl">.3</span>, random_state<span class="op">=</span>RANDOM_STATE)</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>feature_1, feature_2 <span class="op">=</span> <span class="dv">0</span>, <span class="dv">1</span></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>ft_min, ft_max <span class="op">=</span> X.<span class="bu">min</span>(), X.<span class="bu">max</span>()</span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Shape of X:'</span>, X.shape)</span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>), nrows<span class="op">=</span><span class="dv">1</span>, ncols<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a>ax[<span class="dv">0</span>].scatter(X[:, feature_1], X[:, feature_2], c<span class="op">=</span>y, s<span class="op">=</span><span class="dv">4</span>, cmap<span class="op">=</span><span class="st">'bwr'</span>)<span class="op">;</span></span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a>ax[<span class="dv">0</span>].set_xlabel(<span class="st">'Feature 1'</span>)</span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a>ax[<span class="dv">0</span>].set_ylabel(<span class="st">'Feature 1'</span>)</span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a>ax[<span class="dv">1</span>].hist(X)<span class="op">;</span></span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a>ax[<span class="dv">1</span>].set_xlabel(<span class="st">'Value'</span>)</span>
<span id="cb2-17"><a href="#cb2-17" tabindex="-1"></a>ax[<span class="dv">1</span>].set_ylabel(<span class="st">'Count'</span>)</span>
<span id="cb2-18"><a href="#cb2-18" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" tabindex="-1"></a>show()</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Shape of X: (500, 2)</code></pre>
</div>
<figure><img src="fig/03-refinement-rendered-unnamed-chunk-2-1.png" width="960" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>For training, we use the same classifiers as in the previous Lesson.
We train on the whole data set and then use a meshgrid of the state
space for prediction.</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>ft_min, ft_max <span class="op">=</span> <span class="op">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a><span class="co"># Constructing (2 grids x 300 rows x 300 cols):</span></span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>grid_1, grid_2 <span class="op">=</span> mgrid[ft_min:ft_max:<span class="fl">.01</span>, ft_min:ft_max:<span class="fl">.01</span>]</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a><span class="co"># We need only the shape for one of the grids (i.e. 300 x  300):</span></span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>grid_shape <span class="op">=</span> grid_1.shape</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a><span class="co"># state space grid for testing</span></span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a>new_obs <span class="op">=</span> c_[grid_1.ravel(), grid_2.ravel()]</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>contour_levels <span class="op">=</span> linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">6</span>)</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>fig, all_axes <span class="op">=</span> subplots(figsize<span class="op">=</span>[<span class="dv">15</span>, <span class="dv">5</span>], ncols<span class="op">=</span><span class="dv">4</span>, nrows<span class="op">=</span><span class="dv">2</span>, sharey<span class="op">=</span><span class="va">True</span>, sharex<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a><span class="cf">for</span> ax, (name, clf) <span class="kw">in</span> <span class="bu">zip</span>(all_axes.ravel(), classifiers.items()):</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a>    clf.fit(X, y)</span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a>    y_pred <span class="op">=</span> clf.predict(new_obs)</span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>    y_pred_grid <span class="op">=</span> y_pred.reshape(grid_shape)</span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">""</span>)</span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a></span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a>    ax.scatter(X[:, feature_1], X[:, feature_2], c<span class="op">=</span>y, s<span class="op">=</span><span class="dv">1</span>, cmap<span class="op">=</span><span class="st">'bwr_r'</span>)</span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a>    ax.contourf(grid_1, grid_2, y_pred_grid, cmap<span class="op">=</span><span class="st">'gray_r'</span>, alpha<span class="op">=</span><span class="fl">.2</span>, levels<span class="op">=</span>contour_levels)<span class="op">;</span></span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a></span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a>    ax.set_ylim(ft_min, ft_max)</span>
<span id="cb5-17"><a href="#cb5-17" tabindex="-1"></a>    ax.set_xlim(ft_min, ft_max)</span>
<span id="cb5-18"><a href="#cb5-18" tabindex="-1"></a>    ax.set_yticks([ft_min, <span class="dv">0</span>, ft_max])</span>
<span id="cb5-19"><a href="#cb5-19" tabindex="-1"></a>    ax.set_xticks([ft_min, <span class="dv">0</span>, ft_max])</span>
<span id="cb5-20"><a href="#cb5-20" tabindex="-1"></a>    ax.set_title(name, fontsize<span class="op">=</span><span class="dv">10</span>)<span class="op">;</span></span>
<span id="cb5-21"><a href="#cb5-21" tabindex="-1"></a></span>
<span id="cb5-22"><a href="#cb5-22" tabindex="-1"></a>show()</span></code></pre>
</div>
<figure><img src="fig/03-refinement-rendered-unnamed-chunk-4-3.png" width="1440" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p style="text-align: justify;">
Seven of the eight classifiers are able to separate the inner data set
from the outer data set successfully. The main difference is that some
algorithms ended up with a more rectangular shape of the boundary
whereas the others find a more circular form which reflects the original
data distribution more closely. One classifier simply fails: SVC
(linear). It tries to fit a straight line to separate the classes which
in this case is impossible.
</p>
<div id="note" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="note" class="callout-inner">
<h3 class="callout-title">Note</h3>
<div class="callout-content">
<p><strong>Code</strong>: Note how the keyword argument
<code>sharey</code> is used in the call of <code>subplots</code> to have
y-axis only labelled once. The name of the classifier is extracted from
the dictionary as its key and used to set up the title of each
panel.</p>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="metrics">Metrics<a class="anchor" aria-label="anchor" href="#metrics"></a>
</h2>
<hr class="half-width">
<p>We already used the score to evaluate the model performance. Here are
some further metrics used in machine learning.</p>
<p style="text-align: justify;">
<strong>Accuracy</strong> is a metric that evaluates the integrity of
the model by comparing true labels with their predicted counterparts. It
produces a value between 0 and 1, where 1 is the best possible outcome,
and <span class="math inline">\(1 / n_{classes}\)</span> represents the
probability of a random guess. See <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html" class="external-link">the
Scikit-learn documentation for the accuracy_score.</a> The mathematical
formula can be found in the <a href="https://scikit-learn.org/stable/modules/model_evaluation.html#accuracy-score" class="external-link">metrics
and scoring section of the documentation</a>.
</p>
<p style="text-align: justify;">
<strong>Recall</strong> is a metric that evaluates the ability of a
classification model to find true positive labels. The measure produces
a scalar value between 0 and 1, where 1 is the perfect outcome. See <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html" class="external-link">the
Scikit-learn documentation for the recall_score</a>. The recall is the
percentage of true predictions of the overall number of predictions. It
is also known as <em>sensitivity</em>.
</p>
<p style="text-align: justify;">
<strong>Average Precision</strong>, also referred to as AP, is a metric
that produces a scalar value for the precision-recall curve between and
with being the outcome. The metric obtains this value by weighing:
</p>
<ul>
<li>the mean of precisions (P) at each threshold (n),</li>
<li>the increase in recall (R) from the previous threshold (n-1).</li>
</ul>
<p>The metric is mathematically defined as follows:</p>
<p><span class="math display">\[ AP = \sum_{n}^{}(R_n - R_{n-1}) \cdot P
\]</span></p>
<div id="average-precision-vs-auc" class="callout discussion">
<div class="callout-square">
<i class="callout-icon" data-feather="message-circle"></i>
</div>
<div id="average-precision-vs-auc" class="callout-inner">
<h3 class="callout-title">Average precision vs AUC</h3>
<div class="callout-content">
<p style="text-align: justify;">
As you may have noticed, the AUC metric also evaluates the area under
the precision-recall curve using the trapezoid rule and with linear
interpolation. The interpolation, however, may cause the resulting
output to be better than it actually is. In other words, the AUC measure
evaluates the outcome rather optimistically.
</p>
</div>
</div>
</div>
Precision is also called the <em>positive predictive value</em>.
<p style="text-align: justify;">
<strong>F1 Score</strong> Another useful metric to evaluate a
classification model that relies on precision and recall is the F1
Score, see the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html" class="external-link">Scikit-learn
documentation</a>. It is mathematically defined as:
</p>
<p><span class="math display">\[ F_1 = 2 \cdot \frac{P\cdot R}{P+R}
\]</span></p>
<p>where <span class="math inline">\(P\)</span> and <span class="math inline">\(R\)</span> represent precision and recall,
respectively.</p>
<p>Wikipedia has a <a href="https://en.wikipedia.org/wiki/Precision_and_recall" class="external-link">nice summary
of the measures and connections between them</a>.</p>
<p>In Scikit-learn, these measures can be used in a standardised
fashion. Here is an example using the <code>recall_score</code>.</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">.5</span>, random_state<span class="op">=</span>RANDOM_STATE, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a><span class="bu">print</span>(X_train.shape, X_test.shape)</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>(250, 2) (250, 2)</code></pre>
</div>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> recall_score</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>fig, all_axes <span class="op">=</span> subplots(figsize<span class="op">=</span>[<span class="dv">15</span>, <span class="dv">5</span>], ncols<span class="op">=</span><span class="dv">4</span>, nrows<span class="op">=</span><span class="dv">2</span>, sharey<span class="op">=</span><span class="va">True</span>, sharex<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a><span class="cf">for</span> ax, (name, clf) <span class="kw">in</span> <span class="bu">zip</span>(all_axes.ravel(), classifiers.items()):</span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a>    <span class="co"># Training the model using training data:</span></span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a>    clf.fit(X_train, y_train)</span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a>    y_pred_gr <span class="op">=</span> clf.predict(new_obs)</span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a>    y_pred_grid <span class="op">=</span> y_pred_gr.reshape(grid_shape)</span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a>    y_predicted <span class="op">=</span> clf.predict(X_test)</span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">""</span>)</span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a>    <span class="co"># Evaluating the score using test data:</span></span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a>    score <span class="op">=</span> clf.score(X_test, y_test)</span>
<span id="cb8-17"><a href="#cb8-17" tabindex="-1"></a>    recall <span class="op">=</span> recall_score(y_test, y_predicted)</span>
<span id="cb8-18"><a href="#cb8-18" tabindex="-1"></a></span>
<span id="cb8-19"><a href="#cb8-19" tabindex="-1"></a>    <span class="co"># Scattering the test data only:</span></span>
<span id="cb8-20"><a href="#cb8-20" tabindex="-1"></a>    ax.scatter(X_test[:, feature_1], X_test[:, feature_2], c<span class="op">=</span>y_test, s<span class="op">=</span><span class="dv">4</span>, cmap<span class="op">=</span><span class="st">'bwr'</span>, marker<span class="op">=</span><span class="st">'.'</span>)</span>
<span id="cb8-21"><a href="#cb8-21" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">""</span>)</span>
<span id="cb8-22"><a href="#cb8-22" tabindex="-1"></a>    ax.contourf(grid_1, grid_2, y_pred_grid, cmap<span class="op">=</span><span class="st">'gray_r'</span>, alpha<span class="op">=</span><span class="fl">.2</span>, levels<span class="op">=</span>contour_levels)</span>
<span id="cb8-23"><a href="#cb8-23" tabindex="-1"></a></span>
<span id="cb8-24"><a href="#cb8-24" tabindex="-1"></a>    ax.set_ylim(ft_min, ft_max)</span>
<span id="cb8-25"><a href="#cb8-25" tabindex="-1"></a>    ax.set_xlim(ft_min, ft_max)</span>
<span id="cb8-26"><a href="#cb8-26" tabindex="-1"></a>    ax.set_yticks([<span class="op">-</span><span class="fl">1.5</span>, <span class="dv">0</span>, <span class="fl">1.5</span>])</span>
<span id="cb8-27"><a href="#cb8-27" tabindex="-1"></a>    ax.set_xticks([<span class="op">-</span><span class="fl">1.5</span>, <span class="dv">0</span>, <span class="fl">1.5</span>])</span>
<span id="cb8-28"><a href="#cb8-28" tabindex="-1"></a></span>
<span id="cb8-29"><a href="#cb8-29" tabindex="-1"></a>    label <span class="op">=</span> <span class="st">'</span><span class="sc">{}</span><span class="st"> - Recall: </span><span class="sc">{:.2f}</span><span class="st">'</span>.<span class="bu">format</span>(name, recall)</span>
<span id="cb8-30"><a href="#cb8-30" tabindex="-1"></a>    ax.set_title(label , fontsize<span class="op">=</span><span class="dv">10</span>)<span class="op">;</span></span>
<span id="cb8-31"><a href="#cb8-31" tabindex="-1"></a></span>
<span id="cb8-32"><a href="#cb8-32" tabindex="-1"></a>show()</span></code></pre>
</div>
<figure><img src="fig/03-refinement-rendered-unnamed-chunk-6-5.png" width="1440" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><div class="section level3">
<h3 id="reducing-bias-on-test-data">
<strong>Reducing Bias on Test Data</strong><a class="anchor" aria-label="anchor" href="#reducing-bias-on-test-data"></a>
</h3>
<p style="text-align: justify;">
Whilst <code>SciKit Learn</code> provides us with a dedicated function
to obtain accuracy, the value it provides depends on how our training
and test data have been split. Using the train-test-split, we can
randomly shuffle the data to address this very problem. However, this
implicitly assumed that our original data followed a specific
distribution which is best represented by shuffling the data. That may
not always be the case. In practice, we can never fully eliminate this
type of bias. What we can do, however, is to split, shuffle, and permute
the samples in the original dataset repeatedly to minimise the
likelihood of bias.
</p>
</div>
</section><section><h2 class="section-heading" id="permutation-score">Permutation Score<a class="anchor" aria-label="anchor" href="#permutation-score"></a>
</h2>
<hr class="half-width">
<p style="text-align: justify;">
When dealing with biological and medical data, the results of machine
learning often are not clear-cut. The question remains whether or not to
trust a predictor as being truly above chance levels. An effective
technique to address this is to randomly shuffle the labels
independently of the data. I.e. we permutate only the labels, and check
whether the classification score actually decreases. The
<strong>permutation score</strong> then quantifies how trustworthy the
result with the correct labels is. See <a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.permutation_test_score.html" class="external-link">the
Scikit-learn documentation</a> for details.
</p>
<p style="text-align: justify;">
Now that we know about evaluation metrics, we are set to properly begin
the evaluation process. We can use so-called cross-validators for
testing the models if a test is run many times on data with differently
permuted labels. To facilitate this, Scikit-learn provides the function
<code>permutation_test_score</code>.
</p>
<div id="note-1" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="note-1" class="callout-inner">
<h3 class="callout-title">Note</h3>
<div class="callout-content">
<p style="text-align: justify;">
The process of cross-validation is computationally expensive, as is the
process of repeatedly permuting, fitting, and testing our models. In
this context, we will be using both processes to complement each other.
This makes the operation time-consuming and slow.
</p>
</div>
</div>
</div>
<p style="text-align: justify;">
When possible, Scikit-learn provides us the with ability to use multiple
CPU cores to speed up intensive computations through multiprocessing.
Where available, this can be achieved by setting the <code>n_jobs</code>
argument of a function or a class to the number of CPU cores we wish to
use. Conveniently, it can be set to <code>n_jobs=-1</code> to use all
available CPU cores (see e.g. <a href="">the Hyperparameter Tuning
section</a> below). Here, we have shown the use of only one core with
<code>n_jobs=1</code> which is computationally slow. You can adjust it
according to the machine you are using to make it faster.
</p>
<p>The keyword argument <code>n_permutations</code> is set to 100 by
default. You can speed the cross-validation up by choosing a smaller
number.</p>
<div class="codewrapper sourceCode" id="cb9">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> permutation_test_score</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>n_classes <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a>chance <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> n_classes</span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a>fig, axes <span class="op">=</span> subplots(figsize<span class="op">=</span>[<span class="dv">16</span>, <span class="dv">12</span>], ncols<span class="op">=</span><span class="dv">4</span>, nrows<span class="op">=</span><span class="dv">2</span>, sharey<span class="op">=</span><span class="va">True</span>, sharex<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a><span class="cf">for</span> ax, (name, clf) <span class="kw">in</span> <span class="bu">zip</span>(axes.ravel(), classifiers.items()):</span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a></span>
<span id="cb9-11"><a href="#cb9-11" tabindex="-1"></a>    score, permutation_scores, pvalue <span class="op">=</span> permutation_test_score(clf, X, y, scoring<span class="op">=</span><span class="st">"accuracy"</span>, n_jobs<span class="op">=</span><span class="dv">1</span>,n_permutations<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb9-12"><a href="#cb9-12" tabindex="-1"></a></span>
<span id="cb9-13"><a href="#cb9-13" tabindex="-1"></a>    score_label <span class="op">=</span> <span class="st">'Score: </span><span class="sc">{:.3f}</span><span class="st">, (p=</span><span class="sc">{:.4f}</span><span class="st">)'</span>.<span class="bu">format</span>(score, pvalue)</span>
<span id="cb9-14"><a href="#cb9-14" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">""</span>)</span>
<span id="cb9-15"><a href="#cb9-15" tabindex="-1"></a>    chance_label <span class="op">=</span> <span class="st">'Chance: </span><span class="sc">{:.3f}</span><span class="st">'</span>.<span class="bu">format</span>(chance)</span>
<span id="cb9-16"><a href="#cb9-16" tabindex="-1"></a></span>
<span id="cb9-17"><a href="#cb9-17" tabindex="-1"></a>    ax.hist(permutation_scores)</span>
<span id="cb9-18"><a href="#cb9-18" tabindex="-1"></a>    ax.axvline(score,  c<span class="op">=</span><span class="st">'g'</span>, label<span class="op">=</span>score_label,  linewidth<span class="op">=</span><span class="fl">3.0</span>)</span>
<span id="cb9-19"><a href="#cb9-19" tabindex="-1"></a>    ax.axvline(chance, c<span class="op">=</span><span class="st">'r'</span>, label<span class="op">=</span>chance_label, linewidth<span class="op">=</span><span class="fl">3.0</span>)</span>
<span id="cb9-20"><a href="#cb9-20" tabindex="-1"></a>    ax.set_title(name, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb9-21"><a href="#cb9-21" tabindex="-1"></a>    ax.legend(fontsize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb9-22"><a href="#cb9-22" tabindex="-1"></a></span>
<span id="cb9-23"><a href="#cb9-23" tabindex="-1"></a>show()</span></code></pre>
</div>
<figure><img src="fig/03-refinement-rendered-unnamed-chunk-7-7.png" width="1536" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p style="text-align: justify;">
Apart from SVC (linear), all classifiers show satisfactory separation of
the permutation test (blue distribution with red mean value) from the
data score (green line). Apart from SVC (linear), the p-values are below
0.01.
</p>
<p style="text-align: justify;">
Here is a <a href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_permutation_tests_for_classification.html#sphx-glr-auto-examples-model-selection-plot-permutation-tests-for-classification-py" class="external-link">Scikit-learn
example using permutations with the Iris data</a>.
</p>
</section><section><h2 class="section-heading" id="confusion-matrix">Confusion Matrix<a class="anchor" aria-label="anchor" href="#confusion-matrix"></a>
</h2>
<hr class="half-width">
<p style="text-align: justify;">
Another useful method to evaluate a model and demonstrate its integrity
is to produce a <a href="https://en.wikipedia.org/wiki/Confusion_matrix" class="external-link">confusion
matrix</a>. The matrix demonstrates the number of correctly predicted
labels against the incorrect ones. As such it can, however, only be used
for classification problems with two labels.
</p>
<p>Scikit-learn provides a <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html" class="external-link">function
to create a confusion matrix</a>. Here is an expanded function to
simplify the visualisation of this matrix.</p>
<div class="codewrapper sourceCode" id="cb10">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="kw">def</span> plot_confusion_matrix(y_test, y_pred, classes, normalize<span class="op">=</span><span class="va">False</span>, ax<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a><span class="co">    This function prints and plots the confusion matrix.</span></span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a><span class="co">    y_test (array)</span></span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a><span class="co">    y_pred (array)</span></span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a><span class="co">    classes (array)</span></span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a><span class="co">    normalize (bool) Normalize the results (True), or show them as integer numbers (False).</span></span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a><span class="co">    ax Visualization axis.</span></span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a><span class="co">    The function is an adaptation of a SciKit Learn example.</span></span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a></span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a>    <span class="im">from</span> itertools <span class="im">import</span> product</span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a>    <span class="im">from</span> numpy <span class="im">import</span> asarray, newaxis</span>
<span id="cb10-14"><a href="#cb10-14" tabindex="-1"></a>    <span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb10-15"><a href="#cb10-15" tabindex="-1"></a>    cm <span class="op">=</span> confusion_matrix(y_test,y_pred)</span>
<span id="cb10-16"><a href="#cb10-16" tabindex="-1"></a>    n_classes <span class="op">=</span> <span class="bu">len</span>(classes)</span>
<span id="cb10-17"><a href="#cb10-17" tabindex="-1"></a></span>
<span id="cb10-18"><a href="#cb10-18" tabindex="-1"></a>    <span class="cf">if</span> normalize:</span>
<span id="cb10-19"><a href="#cb10-19" tabindex="-1"></a>        cm <span class="op">=</span> asarray(cm).astype(<span class="st">'float32'</span>) <span class="op">/</span>cm.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)[:, newaxis]</span>
<span id="cb10-20"><a href="#cb10-20" tabindex="-1"></a></span>
<span id="cb10-21"><a href="#cb10-21" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> ax:</span>
<span id="cb10-22"><a href="#cb10-22" tabindex="-1"></a>        <span class="im">from</span> matplotlib.pyplot <span class="im">import</span> subplots, show</span>
<span id="cb10-23"><a href="#cb10-23" tabindex="-1"></a>        fig, ax <span class="op">=</span> subplots()</span>
<span id="cb10-24"><a href="#cb10-24" tabindex="-1"></a></span>
<span id="cb10-25"><a href="#cb10-25" tabindex="-1"></a>    ticks <span class="op">=</span> <span class="bu">range</span>(n_classes)</span>
<span id="cb10-26"><a href="#cb10-26" tabindex="-1"></a>    ax.imshow(cm, interpolation<span class="op">=</span><span class="st">'nearest'</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>)</span>
<span id="cb10-27"><a href="#cb10-27" tabindex="-1"></a>    ax.set_xticks(ticks)</span>
<span id="cb10-28"><a href="#cb10-28" tabindex="-1"></a>    ax.set_xticklabels(classes, rotation<span class="op">=</span><span class="dv">90</span>)</span>
<span id="cb10-29"><a href="#cb10-29" tabindex="-1"></a>    ax.set_yticks(ticks)</span>
<span id="cb10-30"><a href="#cb10-30" tabindex="-1"></a>    ax.set_yticklabels(classes)</span>
<span id="cb10-31"><a href="#cb10-31" tabindex="-1"></a>    fmt <span class="op">=</span> <span class="st">'.2f'</span> <span class="cf">if</span> normalize <span class="cf">else</span> <span class="st">'d'</span></span>
<span id="cb10-32"><a href="#cb10-32" tabindex="-1"></a>    thresh <span class="op">=</span> <span class="dv">3</span><span class="op">*</span>cm.<span class="bu">max</span>() <span class="op">/</span> <span class="dv">4</span></span>
<span id="cb10-33"><a href="#cb10-33" tabindex="-1"></a>    cm_dim <span class="op">=</span> cm.shape</span>
<span id="cb10-34"><a href="#cb10-34" tabindex="-1"></a></span>
<span id="cb10-35"><a href="#cb10-35" tabindex="-1"></a>    <span class="co"># Matrix indices:</span></span>
<span id="cb10-36"><a href="#cb10-36" tabindex="-1"></a>    indices_a <span class="op">=</span> <span class="bu">range</span>(cm_dim[<span class="dv">0</span>])</span>
<span id="cb10-37"><a href="#cb10-37" tabindex="-1"></a>    indices_b <span class="op">=</span> <span class="bu">range</span>(cm_dim[<span class="dv">1</span>])</span>
<span id="cb10-38"><a href="#cb10-38" tabindex="-1"></a>    <span class="co"># Cartesian product of matrix indices:</span></span>
<span id="cb10-39"><a href="#cb10-39" tabindex="-1"></a>    indices <span class="op">=</span> product(indices_a, indices_b)</span>
<span id="cb10-40"><a href="#cb10-40" tabindex="-1"></a>    fmt <span class="op">=</span> <span class="st">'.2f'</span> <span class="cf">if</span> normalize <span class="cf">else</span> <span class="st">'d'</span></span>
<span id="cb10-41"><a href="#cb10-41" tabindex="-1"></a></span>
<span id="cb10-42"><a href="#cb10-42" tabindex="-1"></a>    <span class="cf">for</span> ind_a, ind_b <span class="kw">in</span> indices:</span>
<span id="cb10-43"><a href="#cb10-43" tabindex="-1"></a>      label <span class="op">=</span> <span class="bu">format</span>(cm[ind_a, ind_b], fmt)</span>
<span id="cb10-44"><a href="#cb10-44" tabindex="-1"></a>      color <span class="op">=</span> <span class="st">"white"</span> <span class="cf">if</span> cm[ind_a, ind_b] <span class="op">&gt;</span> thresh <span class="cf">else</span> <span class="st">"black"</span></span>
<span id="cb10-45"><a href="#cb10-45" tabindex="-1"></a>      ax.text(ind_b, ind_a, label, ha<span class="op">=</span><span class="st">"center"</span>, color<span class="op">=</span>color)</span>
<span id="cb10-46"><a href="#cb10-46" tabindex="-1"></a>    ax.set_ylabel(<span class="st">'True label'</span>)</span>
<span id="cb10-47"><a href="#cb10-47" tabindex="-1"></a>    ax.set_xlabel(<span class="st">'Predicted label'</span>)</span>
<span id="cb10-48"><a href="#cb10-48" tabindex="-1"></a></span>
<span id="cb10-49"><a href="#cb10-49" tabindex="-1"></a>    <span class="cf">return</span> ax</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb11">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>class_names <span class="op">=</span> (<span class="st">'False (0)'</span>, <span class="st">'True (1)'</span>)</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>fig, axes <span class="op">=</span> subplots(figsize<span class="op">=</span>(<span class="dv">17</span>, <span class="dv">12</span>), ncols<span class="op">=</span><span class="dv">4</span>, nrows<span class="op">=</span><span class="dv">2</span>, sharey<span class="op">=</span><span class="va">True</span>, sharex<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a><span class="cf">for</span> ax, (name, clf) <span class="kw">in</span> <span class="bu">zip</span>(axes.ravel(), classifiers.items()):</span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a>    clf.fit(X_train, y_train)</span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a></span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a>    y_pred <span class="op">=</span> clf.predict(X_test)</span>
<span id="cb11-11"><a href="#cb11-11" tabindex="-1"></a></span>
<span id="cb11-12"><a href="#cb11-12" tabindex="-1"></a>    plot_confusion_matrix(y_test, y_pred, classes<span class="op">=</span>class_names, normalize<span class="op">=</span><span class="va">True</span>, ax<span class="op">=</span>ax)</span>
<span id="cb11-13"><a href="#cb11-13" tabindex="-1"></a></span>
<span id="cb11-14"><a href="#cb11-14" tabindex="-1"></a>    ax.set_title(name, fontsize<span class="op">=</span><span class="dv">10</span>)<span class="op">;</span></span>
<span id="cb11-15"><a href="#cb11-15" tabindex="-1"></a></span>
<span id="cb11-16"><a href="#cb11-16" tabindex="-1"></a></span>
<span id="cb11-17"><a href="#cb11-17" tabindex="-1"></a>show()</span></code></pre>
</div>
<figure><img src="fig/03-refinement-rendered-unnamed-chunk-9-9.png" width="1632" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>Ideally, the diagonal fields are both white and the off-diagonal
fields maximally dark.</p>
</section><section><h2 class="section-heading" id="further-refinements">Further Refinements<a class="anchor" aria-label="anchor" href="#further-refinements"></a>
</h2>
<hr class="half-width">
<p style="text-align: justify;">
Once we decide what algorithm to use, we start by training that
algorithm with its default settings and evaluate the results. If not
satisfied, we can make further adjustments to the
<strong>hyper-parameters</strong> of the algorithm to improve the
results. As always in machine learning, it is of great importance that
we avoid overfitting, i.e. maintain the generalisability of the model
whilst improving its performance.
</p>
<p>We start by creating a classification problem with 3 features and 2
labels using the <code>make_classification</code> function. Data are now
displayed in pseudo-3D.</p>
<div class="codewrapper sourceCode" id="cb12">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_classification</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>X, y <span class="op">=</span> make_classification(</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a>    n_samples<span class="op">=</span><span class="dv">500</span>,</span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a>    n_features<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a>    n_classes<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a>    n_informative<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a>    n_redundant<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb12-9"><a href="#cb12-9" tabindex="-1"></a>    n_repeated<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb12-10"><a href="#cb12-10" tabindex="-1"></a>    n_clusters_per_class<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb12-11"><a href="#cb12-11" tabindex="-1"></a>    class_sep<span class="op">=</span><span class="fl">.7</span>,</span>
<span id="cb12-12"><a href="#cb12-12" tabindex="-1"></a>    scale<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb12-13"><a href="#cb12-13" tabindex="-1"></a>    random_state<span class="op">=</span>RANDOM_STATE</span>
<span id="cb12-14"><a href="#cb12-14" tabindex="-1"></a>)</span>
<span id="cb12-15"><a href="#cb12-15" tabindex="-1"></a></span>
<span id="cb12-16"><a href="#cb12-16" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots()</span>
<span id="cb12-17"><a href="#cb12-17" tabindex="-1"></a></span>
<span id="cb12-18"><a href="#cb12-18" tabindex="-1"></a>ax.hist(X)<span class="op">;</span></span>
<span id="cb12-19"><a href="#cb12-19" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Value'</span>)</span>
<span id="cb12-20"><a href="#cb12-20" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Count'</span>)</span>
<span id="cb12-21"><a href="#cb12-21" tabindex="-1"></a></span>
<span id="cb12-22"><a href="#cb12-22" tabindex="-1"></a>show()</span></code></pre>
</div>
<figure><img src="fig/03-refinement-rendered-unnamed-chunk-10-11.png" width="672" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><div class="codewrapper sourceCode" id="cb13">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="im">from</span> mpl_toolkits.mplot3d <span class="im">import</span> Axes3D</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>), subplot_kw<span class="op">=</span><span class="bu">dict</span>(projection<span class="op">=</span><span class="st">'3d'</span>))</span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a>ax.scatter(X[:, <span class="dv">0</span>], X[:, <span class="dv">1</span>], X[:, <span class="dv">2</span>], c<span class="op">=</span>y, s<span class="op">=</span><span class="dv">5</span>, cmap<span class="op">=</span><span class="st">'bwr'</span>)<span class="op">;</span></span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a>show()</span></code></pre>
</div>
<figure><img src="fig/03-refinement-rendered-unnamed-chunk-11-13.png" width="960" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><div class="codewrapper sourceCode" id="cb14">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a>fig, axes <span class="op">=</span> subplots(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">3</span>), ncols<span class="op">=</span><span class="dv">3</span>, sharex<span class="op">=</span><span class="va">True</span>, sharey<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a>axes[<span class="dv">0</span>].scatter(X[:, <span class="dv">0</span>], X[:, <span class="dv">1</span>], c<span class="op">=</span>y, s<span class="op">=</span><span class="dv">2</span>, cmap<span class="op">=</span><span class="st">'bwr'</span>)</span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a>axes[<span class="dv">1</span>].scatter(X[:, <span class="dv">0</span>], X[:, <span class="dv">2</span>], c<span class="op">=</span>y, s<span class="op">=</span><span class="dv">2</span>, cmap<span class="op">=</span><span class="st">'bwr'</span>)</span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a>axes[<span class="dv">2</span>].scatter(X[:, <span class="dv">1</span>], X[:, <span class="dv">2</span>], c<span class="op">=</span>y, s<span class="op">=</span><span class="dv">2</span>, cmap<span class="op">=</span><span class="st">'bwr'</span>)<span class="op">;</span></span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a></span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a>show()</span></code></pre>
</div>
<figure><img src="fig/03-refinement-rendered-unnamed-chunk-11-14.png" width="1152" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><div id="note-2" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<div id="note-2" class="callout-inner">
<h3 class="callout-title">Note</h3>
<div class="callout-content">
<p><strong>Code</strong>: Note the setting up of 3D axis. Some examples
with code to learn 3D plotting are <a href="https://matplotlib.org/2.0.2/mpl_toolkits/mplot3d/tutorial.html" class="external-link">provided
in these tutorials</a>.</p>
</div>
</div>
</div>
<p>We can now go ahead and use our classifier dictionary – which
contains the classifiers with their default settings – to train and
evaluate the models. We use the train-test split to evaluate the
performance.</p>
<div class="codewrapper sourceCode" id="cb15">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">.8</span>, random_state<span class="op">=</span>RANDOM_STATE, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a><span class="cf">for</span> name, clf <span class="kw">in</span> classifiers.items():</span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a>    clf.fit(X_train, y_train)</span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a>    score <span class="op">=</span> clf.score(X_test, y_test)</span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'</span><span class="sc">{:&lt;30}</span><span class="st"> Score: </span><span class="sc">{:.2f}</span><span class="st">'</span>.<span class="bu">format</span>(name, score))</span></code></pre>
</div>
<style>#sk-container-id-1 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: #000;
  --sklearn-color-text-muted: #666;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-1 {
  color: var(--sklearn-color-text);
}

#sk-container-id-1 pre {
  padding: 0;
}

#sk-container-id-1 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-1 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-1 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-1 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-1 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-1 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-1 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-1 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-1 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-1 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-1 label.sk-toggleable__label {
  cursor: pointer;
  display: flex;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
  align-items: start;
  justify-content: space-between;
  gap: 0.5em;
}

#sk-container-id-1 label.sk-toggleable__label .caption {
  font-size: 0.6rem;
  font-weight: lighter;
  color: var(--sklearn-color-text-muted);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-1 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-1 div.sk-label label.sk-toggleable__label,
#sk-container-id-1 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-1 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-1 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-1 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-1 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 0.5em;
  text-align: center;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-1 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-1 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-1 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-1 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style>
<div id="sk-container-id-1" class="sk-top-container">
<div class="sk-text-repr-fallback">
<pre>MLPClassifier(max_iter=5000, random_state=111)</pre>
<b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b>
</div>
<div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator fitted sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>MLPClassifier</div></div>
<div>
<a class="external-link sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.neural_network.MLPClassifier.html">?<span>Documentation for MLPClassifier</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span>
</div></label><div class="sk-toggleable__content fitted"><pre>MLPClassifier(max_iter=5000, random_state=111)</pre></div> </div></div></div>
</div>
<div class="section level3">
<h3 id="normalisation">
<strong>Normalisation</strong><a class="anchor" aria-label="anchor" href="#normalisation"></a>
</h3>
<p style="text-align: justify;">
Depending on the nature of the data, it might be beneficial to normalise
the data before fitting a classifier. This is widely done in machine
learning but needs thought in each case.
</p>
<p style="text-align: justify;">
Normalisation can be done in various ways. One common way to normalise
data is to require that they have mean 0 and variance 1. This is used
for example, when calculating the Pearson correlation coefficient.
Another popular way in machine learning is to normalise data to
Euclidean norm 1. For a data point in an m-dimensional feature space (m
is the number of features), the Euclidean norm of a single point (one
sample or row) is normalised such that the distance of the point from
the origin is 1.
</p>
<p>Let us first see an example: some data points are spread between 1
and 4.</p>
<div class="codewrapper sourceCode" id="cb16">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> Normalizer</span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a>some_data <span class="op">=</span> array([[<span class="dv">1</span>, <span class="dv">4</span>], [<span class="dv">3</span>, <span class="dv">1</span>], [<span class="dv">4</span>, <span class="dv">4</span>], [<span class="dv">2</span>, <span class="dv">3</span>]])</span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a>norm_skl         <span class="op">=</span> Normalizer()</span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a>some_data_normed <span class="op">=</span> norm_skl.fit_transform(some_data)</span>
<span id="cb16-7"><a href="#cb16-7" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Normalised data:'</span>, <span class="st">'</span><span class="ch">\n</span><span class="st">'</span>, some_data_normed)</span>
<span id="cb16-9"><a href="#cb16-9" tabindex="-1"></a></span>
<span id="cb16-10"><a href="#cb16-10" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> amax</span>
<span id="cb16-11"><a href="#cb16-11" tabindex="-1"></a></span>
<span id="cb16-12"><a href="#cb16-12" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots(nrows<span class="op">=</span><span class="dv">1</span>, ncols<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb16-13"><a href="#cb16-13" tabindex="-1"></a></span>
<span id="cb16-14"><a href="#cb16-14" tabindex="-1"></a>scaling <span class="op">=</span> amax(some_data)<span class="op">*</span><span class="fl">1.1</span></span>
<span id="cb16-15"><a href="#cb16-15" tabindex="-1"></a></span>
<span id="cb16-16"><a href="#cb16-16" tabindex="-1"></a>ax[<span class="dv">0</span>].scatter(some_data[:, <span class="dv">0</span>], some_data[:, <span class="dv">1</span>])</span>
<span id="cb16-17"><a href="#cb16-17" tabindex="-1"></a>ax[<span class="dv">0</span>].set_xlim(<span class="dv">0</span>, scaling)</span>
<span id="cb16-18"><a href="#cb16-18" tabindex="-1"></a>ax[<span class="dv">0</span>].set_ylim(<span class="dv">0</span>, scaling)</span>
<span id="cb16-19"><a href="#cb16-19" tabindex="-1"></a>ax[<span class="dv">0</span>].set_xlabel(<span class="st">'Some data'</span>)</span>
<span id="cb16-20"><a href="#cb16-20" tabindex="-1"></a></span>
<span id="cb16-21"><a href="#cb16-21" tabindex="-1"></a>ax[<span class="dv">1</span>].scatter(some_data_normed[:, <span class="dv">0</span>], some_data_normed[:, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'r'</span>)</span>
<span id="cb16-22"><a href="#cb16-22" tabindex="-1"></a>ax[<span class="dv">1</span>].set_xlim(<span class="dv">0</span>, scaling)</span>
<span id="cb16-23"><a href="#cb16-23" tabindex="-1"></a>ax[<span class="dv">1</span>].set_ylim(<span class="dv">0</span>, scaling)<span class="op">;</span></span>
<span id="cb16-24"><a href="#cb16-24" tabindex="-1"></a>ax[<span class="dv">1</span>].set_xlabel(<span class="st">'Normalised data'</span>)</span>
<span id="cb16-25"><a href="#cb16-25" tabindex="-1"></a></span>
<span id="cb16-26"><a href="#cb16-26" tabindex="-1"></a>show()</span></code></pre>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Normalised data:
 [[0.24253563 0.9701425 ]
 [0.9486833  0.31622777]
 [0.70710678 0.70710678]
 [0.5547002  0.83205029]]
(0.0, 4.4)
(0.0, 4.4)
(0.0, 4.4)</code></pre>
</div>
<figure><img src="fig/03-refinement-rendered-unnamed-chunk-13-17.png" width="672" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p style="text-align: justify;">
Effectively, all normalised data are positioned on a circle around the
origin with radius 1. Depending on correlations existing between the
features this leads to different distortions of the original data.
</p>
<p>Let us now apply this normalisation to our artificial data set.</p>
<div class="codewrapper sourceCode" id="cb18">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a>norm <span class="op">=</span> Normalizer()</span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a>X_normed <span class="op">=</span> norm.fit_transform(X)</span>
<span id="cb18-4"><a href="#cb18-4" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" tabindex="-1"></a>fig, ax <span class="op">=</span> subplots(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">8</span>), subplot_kw<span class="op">=</span><span class="bu">dict</span>(projection<span class="op">=</span><span class="st">'3d'</span>))</span>
<span id="cb18-6"><a href="#cb18-6" tabindex="-1"></a></span>
<span id="cb18-7"><a href="#cb18-7" tabindex="-1"></a>ax.scatter(X_normed[:, <span class="dv">0</span>], X_normed[:, <span class="dv">1</span>], X_normed[:, <span class="dv">2</span>], c<span class="op">=</span>y, s<span class="op">=</span><span class="dv">5</span>, cmap<span class="op">=</span><span class="st">'bwr'</span>)<span class="op">;</span></span>
<span id="cb18-8"><a href="#cb18-8" tabindex="-1"></a>ax.view_init(<span class="dv">30</span>, <span class="dv">50</span>)<span class="op">;</span></span>
<span id="cb18-9"><a href="#cb18-9" tabindex="-1"></a>show()</span></code></pre>
</div>
<figure><img src="fig/03-refinement-rendered-unnamed-chunk-14-19.png" width="768" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><div class="codewrapper sourceCode" id="cb19">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a>fig, axes <span class="op">=</span> subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">3</span>), ncols<span class="op">=</span><span class="dv">3</span>, sharex<span class="op">=</span><span class="va">True</span>, sharey<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" tabindex="-1"></a>axes[<span class="dv">0</span>].scatter(X_normed[:, <span class="dv">0</span>], X_normed[:, <span class="dv">1</span>], c<span class="op">=</span>y, s<span class="op">=</span><span class="dv">2</span>, cmap<span class="op">=</span><span class="st">'bwr'</span>)</span>
<span id="cb19-4"><a href="#cb19-4" tabindex="-1"></a>axes[<span class="dv">1</span>].scatter(X_normed[:, <span class="dv">0</span>], X_normed[:, <span class="dv">2</span>], c<span class="op">=</span>y, s<span class="op">=</span><span class="dv">2</span>, cmap<span class="op">=</span><span class="st">'bwr'</span>)</span>
<span id="cb19-5"><a href="#cb19-5" tabindex="-1"></a>axes[<span class="dv">2</span>].scatter(X_normed[:, <span class="dv">1</span>], X_normed[:, <span class="dv">2</span>], c<span class="op">=</span>y, s<span class="op">=</span><span class="dv">2</span>, cmap<span class="op">=</span><span class="st">'bwr'</span>)<span class="op">;</span></span>
<span id="cb19-6"><a href="#cb19-6" tabindex="-1"></a></span>
<span id="cb19-7"><a href="#cb19-7" tabindex="-1"></a>show()</span></code></pre>
</div>
<figure><img src="fig/03-refinement-rendered-unnamed-chunk-14-20.png" width="960" style="display: block; margin: auto;" class="figure mx-auto d-block"></figure><p>The normalisation projects the data on the unit sphere. And now we
can do the training on the normalised data:</p>
<div class="codewrapper sourceCode" id="cb20">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X_normed, y, test_size<span class="op">=</span><span class="fl">.8</span>, random_state<span class="op">=</span>RANDOM_STATE, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" tabindex="-1"></a><span class="cf">for</span> name, clf <span class="kw">in</span> classifiers.items():</span>
<span id="cb20-4"><a href="#cb20-4" tabindex="-1"></a>    clf.fit(X_train, y_train)</span>
<span id="cb20-5"><a href="#cb20-5" tabindex="-1"></a>    score <span class="op">=</span> clf.score(X_test, y_test)</span>
<span id="cb20-6"><a href="#cb20-6" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'</span><span class="sc">{:&lt;30}</span><span class="st"> Score: </span><span class="sc">{:.2f}</span><span class="st">'</span>.<span class="bu">format</span>(name, score))</span></code></pre>
</div>
<style>#sk-container-id-2 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: #000;
  --sklearn-color-text-muted: #666;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-2 {
  color: var(--sklearn-color-text);
}

#sk-container-id-2 pre {
  padding: 0;
}

#sk-container-id-2 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-2 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-2 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-2 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-2 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-2 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-2 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-2 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-2 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-2 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-2 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-2 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-2 label.sk-toggleable__label {
  cursor: pointer;
  display: flex;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
  align-items: start;
  justify-content: space-between;
  gap: 0.5em;
}

#sk-container-id-2 label.sk-toggleable__label .caption {
  font-size: 0.6rem;
  font-weight: lighter;
  color: var(--sklearn-color-text-muted);
}

#sk-container-id-2 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-2 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-2 div.sk-label label.sk-toggleable__label,
#sk-container-id-2 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-2 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-2 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-2 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-2 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 0.5em;
  text-align: center;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-2 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-2 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-2 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-2 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style>
<div id="sk-container-id-2" class="sk-top-container">
<div class="sk-text-repr-fallback">
<pre>MLPClassifier(max_iter=5000, random_state=111)</pre>
<b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b>
</div>
<div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator fitted sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" checked><label for="sk-estimator-id-2" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>MLPClassifier</div></div>
<div>
<a class="external-link sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.neural_network.MLPClassifier.html">?<span>Documentation for MLPClassifier</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span>
</div></label><div class="sk-toggleable__content fitted"><pre>MLPClassifier(max_iter=5000, random_state=111)</pre></div> </div></div></div>
</div>
<p style="text-align: justify;">
Due to the homogeneous nature of the artificial data, the results here
are comparable for the data and their normalised version. But this may
change when using data with inconsistent distributions of the columns.
For an example, see the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer" class="external-link">breastcancer
data</a> used in the assignment.
</p>
</div>
<div class="section level3">
<h3 id="hyperparameter-tuning">
<strong>Hyperparameter Tuning</strong><a class="anchor" aria-label="anchor" href="#hyperparameter-tuning"></a>
</h3>
<p style="text-align: justify;">
Once we decide on what algorithm to use, we often start by training that
algorithm with its default settings and evaluate the results. If not
satisfied, we can go further and make adjustments to the
hyper-parameters of the algorithm to improve the results. As always in
machine learning, it is of great importance that we maintain the
generalisability of our model whilst improving its performance. We use
the data from the above classification problem with 3 features and 2
labels.
</p>
</div>
<div class="section level3">
<h3 id="progressive-adjustment">
<strong>Progressive Adjustment</strong><a class="anchor" aria-label="anchor" href="#progressive-adjustment"></a>
</h3>
<p style="text-align: justify;">
After we have compared original and normalised data and obtained their
scores, we now can try to progressively improve the performance of the
algorithms. Each classification algorithm uses a unique set of
hyper-parameters, the details of which are outlined in their respective
documentations on <code>Scikit-learn</code>. The optimum parameters are
those that produce the best fit whilst maintaining the generalisability
of a model. One way to obtain the optimum settings is to test different
parameters and compare the model scores over and over again. However, as
outlined before, by doing so we may risk <em>leaking</em> our test data,
and end up over-fitting the model to the test data. (We also learned
above that we can use different cross-validators to address this
problem.)
</p>
<p style="text-align: justify;">
<code>Scikit-learn</code> provides us with a tool entitled
<code>GridSearchCV</code> to define different values for different
parameters. It then applies different combinations of different
parameters to the model and evaluates the outcome using data that it
generates from a cross-validation algorithm. Once finished, it provides
us with the parameters that produce the best score for our data. This is
referred to as progressive adjustment.
</p>
<p style="text-align: justify;">
Note that this process can be lengthy, and may need to be refined
several times, so it is a good idea to set <code>n_jobs=-1</code> and
thereby take advantage of different CPU core on the computer. For
demonstration, we use SVC(rbf) as a classifier. With certain problems,
its training may lead to poor results with the default parameters.
</p>
<div class="codewrapper sourceCode" id="cb21">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a>clf <span class="op">=</span> SVC(kernel<span class="op">=</span><span class="st">'rbf'</span>, C<span class="op">=</span><span class="dv">1</span>, gamma<span class="op">=</span><span class="dv">100</span>, tol<span class="op">=</span><span class="fl">0.0001</span>)</span>
<span id="cb21-2"><a href="#cb21-2" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" tabindex="-1"></a>clf.fit(X_train, y_train)</span>
<span id="cb21-4"><a href="#cb21-4" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" tabindex="-1"></a>score <span class="op">=</span> clf.score(X_test, y_test)</span>
<span id="cb21-6"><a href="#cb21-6" tabindex="-1"></a></span>
<span id="cb21-7"><a href="#cb21-7" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'</span><span class="sc">{:&lt;30}</span><span class="st"> Score: </span><span class="sc">{:.2f}</span><span class="st">'</span>.<span class="bu">format</span>(<span class="st">'SVC (RBF)'</span>, score))</span></code></pre>
</div>
<style>#sk-container-id-3 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: #000;
  --sklearn-color-text-muted: #666;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-3 {
  color: var(--sklearn-color-text);
}

#sk-container-id-3 pre {
  padding: 0;
}

#sk-container-id-3 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-3 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-3 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-3 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-3 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-3 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-3 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-3 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-3 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-3 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-3 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-3 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-3 label.sk-toggleable__label {
  cursor: pointer;
  display: flex;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
  align-items: start;
  justify-content: space-between;
  gap: 0.5em;
}

#sk-container-id-3 label.sk-toggleable__label .caption {
  font-size: 0.6rem;
  font-weight: lighter;
  color: var(--sklearn-color-text-muted);
}

#sk-container-id-3 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-3 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-3 div.sk-label label.sk-toggleable__label,
#sk-container-id-3 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-3 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-3 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-3 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-3 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 0.5em;
  text-align: center;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-3 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-3 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-3 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-3 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style>
<div id="sk-container-id-3" class="sk-top-container">
<div class="sk-text-repr-fallback">
<pre>SVC(C=1, gamma=100, tol=0.0001)</pre>
<b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b>
</div>
<div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator fitted sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox" checked><label for="sk-estimator-id-3" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>SVC</div></div>
<div>
<a class="external-link sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.svm.SVC.html">?<span>Documentation for SVC</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span>
</div></label><div class="sk-toggleable__content fitted"><pre>SVC(C=1, gamma=100, tol=0.0001)</pre></div> </div></div></div>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>SVC (RBF)                      Score: 0.68</code></pre>
</div>
<p>Progressive adjustment of some of the parameters may lead to an
improved model.</p>
<p><a href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html" class="external-link">Check
the documentation</a> for the meaning and the default values of
regularisation parameters <code>C</code>, kernel coeffcient
<code>gamma</code>, and tolerance setting <code>tol</code>.</p>
<div class="codewrapper sourceCode" id="cb23">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> StratifiedShuffleSplit</span>
<span id="cb23-2"><a href="#cb23-2" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb23-3"><a href="#cb23-3" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" tabindex="-1"></a>param_grid <span class="op">=</span> <span class="bu">dict</span>(C<span class="op">=</span>[<span class="fl">1e-4</span>, <span class="fl">1e-3</span>, <span class="fl">1e-2</span>, <span class="fl">1e-1</span>, <span class="dv">1</span>, <span class="dv">10</span>],</span>
<span id="cb23-5"><a href="#cb23-5" tabindex="-1"></a>                  gamma<span class="op">=</span>[<span class="dv">100</span>, <span class="dv">1000</span>, <span class="dv">10000</span>, <span class="dv">100000</span>],</span>
<span id="cb23-6"><a href="#cb23-6" tabindex="-1"></a>                  tol<span class="op">=</span>[<span class="fl">1e-4</span>, <span class="fl">1e-3</span>, <span class="fl">1e-2</span>, <span class="fl">1e-1</span>])</span>
<span id="cb23-7"><a href="#cb23-7" tabindex="-1"></a></span>
<span id="cb23-8"><a href="#cb23-8" tabindex="-1"></a>cv <span class="op">=</span> StratifiedShuffleSplit(n_splits<span class="op">=</span><span class="dv">5</span>, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span>RANDOM_STATE)</span>
<span id="cb23-9"><a href="#cb23-9" tabindex="-1"></a>clf <span class="op">=</span> SVC(kernel<span class="op">=</span><span class="st">'rbf'</span>, random_state<span class="op">=</span>RANDOM_STATE)</span>
<span id="cb23-10"><a href="#cb23-10" tabindex="-1"></a></span>
<span id="cb23-11"><a href="#cb23-11" tabindex="-1"></a>grid <span class="op">=</span> GridSearchCV(clf, param_grid<span class="op">=</span>param_grid, cv<span class="op">=</span>cv, n_jobs<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb23-12"><a href="#cb23-12" tabindex="-1"></a></span>
<span id="cb23-13"><a href="#cb23-13" tabindex="-1"></a>grid.fit(X, y)</span>
<span id="cb23-14"><a href="#cb23-14" tabindex="-1"></a></span>
<span id="cb23-15"><a href="#cb23-15" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"ORIGINAL: Best parameters </span><span class="sc">{}</span><span class="st">   Score: </span><span class="sc">{:.2f}</span><span class="st">"</span>.<span class="bu">format</span>(grid.best_params_, grid.best_score_))</span>
<span id="cb23-16"><a href="#cb23-16" tabindex="-1"></a></span>
<span id="cb23-17"><a href="#cb23-17" tabindex="-1"></a>grid.fit(X_normed, y)</span>
<span id="cb23-18"><a href="#cb23-18" tabindex="-1"></a></span>
<span id="cb23-19"><a href="#cb23-19" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"NORMED:   Best parameters </span><span class="sc">{}</span><span class="st">    Score </span><span class="sc">{:.2f}</span><span class="st">"</span>.<span class="bu">format</span>(grid.best_params_, grid.best_score_))</span></code></pre>
</div>
<pre><code>ORIGINAL: Best parameters {'C': 0.0001, 'gamma': 1000, 'tol': 0.0001}   Score: 0.65

NORMED:   Best parameters {'C': 1, 'gamma': 100, 'tol': 0.0001}    Score 0.75</code></pre>
<p style="text-align: justify;">
In this case, while both optimised scores are better than the original
one, there is also a notable improvement when using the normalised data.
Let us similarly check the Random Forest classifier, first with default
settings.
</p>
<div class="codewrapper sourceCode" id="cb25">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" tabindex="-1"></a>clf <span class="op">=</span> RandomForestClassifier(random_state<span class="op">=</span>RANDOM_STATE)</span>
<span id="cb25-2"><a href="#cb25-2" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" tabindex="-1"></a>clf.fit(X_train, y_train)</span>
<span id="cb25-4"><a href="#cb25-4" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" tabindex="-1"></a>score <span class="op">=</span> clf.score(X_test, y_test)</span>
<span id="cb25-6"><a href="#cb25-6" tabindex="-1"></a></span>
<span id="cb25-7"><a href="#cb25-7" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'</span><span class="sc">{:&lt;30}</span><span class="st"> Score: </span><span class="sc">{:.2f}</span><span class="st">'</span>.<span class="bu">format</span>(<span class="st">'Random Forest'</span>, score))</span></code></pre>
</div>
<style>#sk-container-id-4 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: #000;
  --sklearn-color-text-muted: #666;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-4 {
  color: var(--sklearn-color-text);
}

#sk-container-id-4 pre {
  padding: 0;
}

#sk-container-id-4 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-4 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-4 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-4 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-4 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-4 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-4 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-4 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-4 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-4 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-4 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-4 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-4 label.sk-toggleable__label {
  cursor: pointer;
  display: flex;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
  align-items: start;
  justify-content: space-between;
  gap: 0.5em;
}

#sk-container-id-4 label.sk-toggleable__label .caption {
  font-size: 0.6rem;
  font-weight: lighter;
  color: var(--sklearn-color-text-muted);
}

#sk-container-id-4 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-4 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-4 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-4 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-4 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-4 div.sk-label label.sk-toggleable__label,
#sk-container-id-4 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-4 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-4 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-4 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-4 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-4 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-4 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 0.5em;
  text-align: center;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-4 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-4 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-4 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-4 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style>
<div id="sk-container-id-4" class="sk-top-container">
<div class="sk-text-repr-fallback">
<pre>RandomForestClassifier(random_state=111)</pre>
<b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b>
</div>
<div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator fitted sk-toggleable">
<input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-4" type="checkbox" checked><label for="sk-estimator-id-4" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>RandomForestClassifier</div></div>
<div>
<a class="external-link sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html">?<span>Documentation for RandomForestClassifier</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span>
</div></label><div class="sk-toggleable__content fitted"><pre>RandomForestClassifier(random_state=111)</pre></div> </div></div></div>
</div>
<div class="codewrapper">
<h3 class="code-label">OUTPUT<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="output" tabindex="0"><code>Random Forest                  Score: 0.77</code></pre>
</div>
<p>And now a grid over <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" class="external-link">some
of its parameters</a>.</p>
<div class="codewrapper sourceCode" id="cb27">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> StratifiedShuffleSplit</span>
<span id="cb27-2"><a href="#cb27-2" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb27-3"><a href="#cb27-3" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" tabindex="-1"></a>param_grid <span class="op">=</span> <span class="bu">dict</span>(</span>
<span id="cb27-5"><a href="#cb27-5" tabindex="-1"></a>    n_estimators<span class="op">=</span>[<span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">15</span>, <span class="dv">20</span>, <span class="dv">50</span>, <span class="dv">60</span>, <span class="dv">70</span>],</span>
<span id="cb27-6"><a href="#cb27-6" tabindex="-1"></a>    max_features<span class="op">=</span>[<span class="va">None</span>, <span class="st">'auto'</span>, <span class="st">'sqrt'</span>, <span class="st">'log2'</span>],</span>
<span id="cb27-7"><a href="#cb27-7" tabindex="-1"></a>    min_samples_split<span class="op">=</span>[<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>],</span>
<span id="cb27-8"><a href="#cb27-8" tabindex="-1"></a>    max_depth<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>]</span>
<span id="cb27-9"><a href="#cb27-9" tabindex="-1"></a>)</span>
<span id="cb27-10"><a href="#cb27-10" tabindex="-1"></a></span>
<span id="cb27-11"><a href="#cb27-11" tabindex="-1"></a>cv <span class="op">=</span> StratifiedShuffleSplit(n_splits<span class="op">=</span><span class="dv">5</span>, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span>RANDOM_STATE)</span>
<span id="cb27-12"><a href="#cb27-12" tabindex="-1"></a></span>
<span id="cb27-13"><a href="#cb27-13" tabindex="-1"></a>clf <span class="op">=</span> RandomForestClassifier(random_state<span class="op">=</span>RANDOM_STATE)</span>
<span id="cb27-14"><a href="#cb27-14" tabindex="-1"></a></span>
<span id="cb27-15"><a href="#cb27-15" tabindex="-1"></a>grid <span class="op">=</span> GridSearchCV(clf, param_grid<span class="op">=</span>param_grid, cv<span class="op">=</span>cv, n_jobs<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb27-16"><a href="#cb27-16" tabindex="-1"></a></span>
<span id="cb27-17"><a href="#cb27-17" tabindex="-1"></a>grid.fit(X, y)</span>
<span id="cb27-18"><a href="#cb27-18" tabindex="-1"></a></span>
<span id="cb27-19"><a href="#cb27-19" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"ORIGINAL: Best parameters </span><span class="sc">{}</span><span class="st">   Score: </span><span class="sc">{:.2f}</span><span class="st">"</span>.<span class="bu">format</span>(grid.best_params_, grid.best_score_))</span>
<span id="cb27-20"><a href="#cb27-20" tabindex="-1"></a></span>
<span id="cb27-21"><a href="#cb27-21" tabindex="-1"></a>grid.fit(X_normed, y)</span>
<span id="cb27-22"><a href="#cb27-22" tabindex="-1"></a></span>
<span id="cb27-23"><a href="#cb27-23" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"NORMED:   Best parameters </span><span class="sc">{}</span><span class="st">    Score </span><span class="sc">{:.2f}</span><span class="st">"</span>.<span class="bu">format</span>(grid.best_params_, grid.best_score_))</span></code></pre>
</div>
<pre><code>ORIGINAL: Best parameters {'max_depth': 4, 'max_features': None, 'min_samples_split': 2, 'n_estimators': 15}   Score: 0.84

NORMED:   Best parameters {'max_depth': 3, 'max_features': 'auto', 'min_samples_split': 4, 'n_estimators': 10}    Score 0.81
</code></pre>
<p>In this case, our (arbitrary) search did not lead to a substantial
improvement. This shows that the default settings are in fact a good
starting point.</p>
</div>
<div class="section level3">
<h3 id="leakage-in-progressive-adjustments">
<strong>Leakage in progressive adjustments</strong><a class="anchor" aria-label="anchor" href="#leakage-in-progressive-adjustments"></a>
</h3>
<p style="text-align: justify;">
We have already highlighted unequivocally the importance of not exposing
our test data to our model during the training process; but where does
training end? After deciding on an algorithm, we often attempt to
improve its performance by adjusting its hyper-parameters as done above.
We make these adjustments on our model repeatedly until we obtain
optimal results in a specific metric that scores the performances based
exclusively on our test data. In such cases, we risk <em>leaking</em>
our test data and thereby over-fit our model to the test data through
progressive adjustments. This means that the evaluation metrics on the
generalisability of our model are no longer reliable.
</p>
<p style="text-align: justify;">
One way to address this problem is to split our original data into 3
different datasets: training, test, and validation. Whilst this is a
valid approach that may be used in specific circumstances, it might also
introduce new problems, e.g. after splitting the available data into 3
subsets, there might just not be enough data to train the classifier
properly.
</p>
<p>See for example the discussion in part 2 of this <a href="https://www.brainstimjrnl.com/article/S1935-861X(21)00236-9/fulltext" class="external-link">paper
on predictive modelling for brain stimulation</a>. The above leaking is
there referred to as “snooping”.</p>
<p><br></p>
</div>
</section><section><h2 class="section-heading" id="exercises">Exercises<a class="anchor" aria-label="anchor" href="#exercises"></a>
</h2>
<hr class="half-width">
<div id="end-of-chapter-exercises" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="end-of-chapter-exercises" class="callout-inner">
<h3 class="callout-title">End of chapter Exercises</h3>
<div class="callout-content">
<p>This assignment makes use of the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer" class="external-link">breast
cancer dataset</a>.</p>
<p>The breast cancer data can be imported from the scikit-learn datasets
library.</p>
<ul>
<li>Both the dataset and the classifiers used in this assignment have
been filled out already.</li>
</ul>
<div class="codewrapper sourceCode" id="cb29">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_breast_cancer</span>
<span id="cb29-2"><a href="#cb29-2" tabindex="-1"></a></span>
<span id="cb29-3"><a href="#cb29-3" tabindex="-1"></a>data <span class="op">=</span> load_breast_cancer()</span>
<span id="cb29-4"><a href="#cb29-4" tabindex="-1"></a></span>
<span id="cb29-5"><a href="#cb29-5" tabindex="-1"></a>X, y <span class="op">=</span> data.data, data.target</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb30">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> mgrid, linspace, c_, arange, mean, array</span>
<span id="cb30-2"><a href="#cb30-2" tabindex="-1"></a><span class="im">from</span> numpy.random <span class="im">import</span> uniform, seed</span>
<span id="cb30-3"><a href="#cb30-3" tabindex="-1"></a><span class="im">from</span> matplotlib.ticker <span class="im">import</span> LinearLocator, FormatStrFormatter</span>
<span id="cb30-4"><a href="#cb30-4" tabindex="-1"></a><span class="im">from</span> mpl_toolkits <span class="im">import</span> mplot3d</span>
<span id="cb30-5"><a href="#cb30-5" tabindex="-1"></a><span class="im">from</span> matplotlib.pyplot <span class="im">import</span> subplots, axes, scatter, xticks, show</span>
<span id="cb30-6"><a href="#cb30-6" tabindex="-1"></a></span>
<span id="cb30-7"><a href="#cb30-7" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_breast_cancer</span>
<span id="cb30-8"><a href="#cb30-8" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_circles</span>
<span id="cb30-9"><a href="#cb30-9" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb30-10"><a href="#cb30-10" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> recall_score</span>
<span id="cb30-11"><a href="#cb30-11" tabindex="-1"></a></span>
<span id="cb30-12"><a href="#cb30-12" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier</span>
<span id="cb30-13"><a href="#cb30-13" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb30-14"><a href="#cb30-14" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC, LinearSVC</span>
<span id="cb30-15"><a href="#cb30-15" tabindex="-1"></a><span class="im">from</span> sklearn.neural_network <span class="im">import</span> MLPClassifier</span>
<span id="cb30-16"><a href="#cb30-16" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb30-17"><a href="#cb30-17" tabindex="-1"></a></span>
<span id="cb30-18"><a href="#cb30-18" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> permutation_test_score</span>
<span id="cb30-19"><a href="#cb30-19" tabindex="-1"></a></span>
<span id="cb30-20"><a href="#cb30-20" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> StratifiedShuffleSplit</span>
<span id="cb30-21"><a href="#cb30-21" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb30-22"><a href="#cb30-22" tabindex="-1"></a></span>
<span id="cb30-23"><a href="#cb30-23" tabindex="-1"></a>RANDOM_STATE <span class="op">=</span> <span class="dv">111</span></span>
<span id="cb30-24"><a href="#cb30-24" tabindex="-1"></a></span>
<span id="cb30-25"><a href="#cb30-25" tabindex="-1"></a>classifiers <span class="op">=</span> {</span>
<span id="cb30-26"><a href="#cb30-26" tabindex="-1"></a>    <span class="st">'Random Forest'</span>: RandomForestClassifier(random_state<span class="op">=</span>RANDOM_STATE),</span>
<span id="cb30-27"><a href="#cb30-27" tabindex="-1"></a>    <span class="st">'AdaBoost (Random Forest)'</span>: AdaBoostClassifier(RandomForestClassifier(random_state<span class="op">=</span>RANDOM_STATE)),</span>
<span id="cb30-28"><a href="#cb30-28" tabindex="-1"></a>    <span class="st">'Extra Trees'</span>: ExtraTreesClassifier(random_state<span class="op">=</span>RANDOM_STATE),</span>
<span id="cb30-29"><a href="#cb30-29" tabindex="-1"></a>    <span class="st">'AdaBoost (Extra Tree)'</span>: AdaBoostClassifier(ExtraTreesClassifier(random_state<span class="op">=</span>RANDOM_STATE)),</span>
<span id="cb30-30"><a href="#cb30-30" tabindex="-1"></a>    <span class="st">'Decision Tree'</span>: DecisionTreeClassifier(random_state<span class="op">=</span>RANDOM_STATE),</span>
<span id="cb30-31"><a href="#cb30-31" tabindex="-1"></a>    <span class="st">'SVC (RBF)'</span>: SVC(random_state<span class="op">=</span>RANDOM_STATE),</span>
<span id="cb30-32"><a href="#cb30-32" tabindex="-1"></a>    <span class="st">'SVC (Linear)'</span>: LinearSVC(random_state<span class="op">=</span>RANDOM_STATE, dual<span class="op">=</span><span class="va">False</span>),</span>
<span id="cb30-33"><a href="#cb30-33" tabindex="-1"></a>    <span class="st">'Multi-layer Perceptron'</span>: MLPClassifier(max_iter<span class="op">=</span><span class="dv">5000</span>, random_state<span class="op">=</span>RANDOM_STATE)</span>
<span id="cb30-34"><a href="#cb30-34" tabindex="-1"></a>    }</span></code></pre>
</div>
<p><strong>Note</strong>: The linear Support Vector classifier is
imported with the keyword argument dual=False. This is to reduce the
number of warnings that occur when the classifier struggles to find a
good solution. See the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html" class="external-link">documentation</a>
for more information.</p>
<ol style="list-style-type: decimal">
<li>Explore the dataset to get an understanding of the features:</li>
</ol>
<ul>
<li>Print the names of the features.</li>
<li>Create a summary boxplot plot of all the features to see their
medians and distributions.</li>
</ul>
<p><em>(Hint! Look back to the Data Handling lessons for a reminder of
how to do these).</em></p>
<ol start="2" style="list-style-type: decimal">
<li>Train the given classifiers and compare the results:</li>
</ol>
<ul>
<li>Split the dataset into train / test.
<ul>
<li>Use the test_train_split() method from sklearn.</li>
<li>Set the test dataset to 95% to make the classification task
difficult.</li>
</ul>
</li>
<li>Obtain the recall scores and print to screen formatted.</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>Generate confusion matrices for each classifier:</li>
</ol>
<ul>
<li>Copy the plot_confusion_matrix() function from the ML3 lesson
materials.</li>
<li>Use this function to create a multi-plot containing a confusion
matrix per classifier.</li>
</ul>
<ol start="4" style="list-style-type: decimal">
<li>Perform a permutation test for each classifier:</li>
</ol>
<ul>
<li>Use the permutation_test_score() function.
<ul>
<li>Set the scoring parameter to “accuracy”.</li>
<li>To increase the speed you can reduce n_permutations or you can set
n_jobs to -1 to increase CPU core usage (see lesson).</li>
</ul>
</li>
<li>Plot the permutation scores with addtional lines indicating chance
accuracy and the classifier score.</li>
</ul>
<ol start="5" style="list-style-type: decimal">
<li>Normalise the features and <em>repeat Questions 1 - 4</em>:</li>
</ol>
<ul>
<li>Use sklearn’s Normalizer to augment the dataset.</li>
<li>Repeat the training, confusion matrices and permutation test.</li>
<li>Observe any differences / improvements.</li>
</ul>
<ol start="6" style="list-style-type: decimal">
<li>Perform hyperparameter tuning with the Random Forest
classifier:</li>
</ol>
<ol style="list-style-type: upper-alpha"><li>
</li></ol>
<p>Generate a Random Forest Classifier and train it using the previously
used training split.</p>
<ul>
<li>Print the score.</li>
</ul>
<ol start="2" style="list-style-type: upper-alpha"><li>
</li></ol>
<p>Setup GridSearchCV to seach for the best parameters for the
classifier.</p>
<ul>
<li>Use StratifiedShuffleSplit for the cross-validation argument.</li>
<li>Include the parameters n_estimators, min_samples_split, max_depth,
and max_features in the grid search.</li>
<li>Give at least 3 different parameters for each one.</li>
<li>See the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" class="external-link">documentation</a>
for the default values / options.</li>
</ul>
<ol start="3" style="list-style-type: upper-alpha"><li>
</li></ol>
<p>Run the grid search with both the original dataset and the normalised
dataset</p>
<ul>
<li>Print the best parameters for both datasets.</li>
<li>Are there any differences between the datasets?</li>
</ul>
<p><strong>Optional Questions (Extra Practise):</strong></p>
<ol start="7" style="list-style-type: decimal">
<li>
<code>scikit-learn</code> has many pre-processing functions, each
with their specific use case, such as <a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html" class="external-link"><code>StandardScaler</code></a>,
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html" class="external-link"><code>MinMaxScaler</code></a>,
and <a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html" class="external-link"><code>RobustScaler</code></a>.</li>
</ol>
<ul>
<li>Read about their use cases in the linked documentation and try them
out on the dataset.</li>
<li>Plot the augmented data.</li>
<li>Run and compare the parameter grid search for each dataset</li>
</ul>
<p><em>Head to the Lecture_Resources folder to 01_scalers_demo.ipynb for
examples of the three aforementioned pre-processing functions.</em></p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1">
  Solutions are provided after assignments are marked.
  </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">

</div>
</div>
</div>
</div>
<p><br></p>
<div id="keypoints1" class="callout keypoints">
<div class="callout-square">
<i class="callout-icon" data-feather="key"></i>
</div>
<div class="callout-inner">
<h3 class="callout-title">Key Points</h3>
<div class="callout-content">
<ul>
<li>The function <code>permutation_test_score</code> evaluates the
significance of a cross-validated score with permutations.</li>
<li>Confusion matrix demonstrates the number of correctly predicted
labels against the incorrect ones.</li>
<li>Adjustment of hyper-parameters of the algorithms may improve the
results.</li>
<li>
<code>GridSearchCV</code> is a tool to simultaneously define
different values of different parameters for optimisation.</li>
<li>Progressive adjustments may lead to model over-fitting and require a
validation data set.</li>
</ul>
</div>
</div>
</div>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</section></section>
</div>
    </main>
</div>
<!-- END  : inst/pkgdown/templates/content-extra.html -->

      </div>
<!--/div.row-->
      		<footer class="row footer mx-md-3"><hr>
<div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>

        <a href="https://github.com/carpentries/workbench-template-md/edit/main/README.md" class="external-link">Edit on GitHub</a>

	
        | <a href="https://github.com/carpentries/workbench-template-md/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/carpentries/workbench-template-md/" class="external-link">Source</a></p>
				<p><a href="https://github.com/carpentries/workbench-template-md/blob/main/CITATION" class="external-link">Cite</a> | <a href="mailto:team@carpentries.org">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">

        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>

        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/69aaefee46a17928e2a1694825599e169b9793e3" class="external-link">sandpaper (0.16.10)</a>, <a href="https://github.com/carpentries/pegboard/tree/bad0be19a12f0c6545801b276ddf26c945f8bfd1" class="external-link">pegboard (0.7.7)</a>, and <a href="https://github.com/milanmlft/varnish/tree/milanmlft/sticky-sidebar" class="external-link">varnish (1.0.3.9000)</a></p>
			</div>
		</footer>
</div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "TrainingMaterial",
  "@id": "https://carpentries.github.io/workbench-template-md/aio.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/TrainingMaterial/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "software, data, lesson, The Carpentries",
  "name": "All in One View",
  "creativeWorkStatus": "active",
  "url": "https://carpentries.github.io/workbench-template-md/aio.html",
  "identifier": "https://carpentries.github.io/workbench-template-md/aio.html",
  "dateCreated": "2022-07-05",
  "dateModified": "2025-03-31",
  "datePublished": "2025-03-31"
}

  </script><script>
		feather.replace();
	</script>
</body>
</html><!-- END:   inst/pkgdown/templates/layout.html-->

